# cython: language_level = 3
# cython: embedsignature = True
# cython: binding = True

# Copyright (c) 2020-2023, Andrea Zoppi.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice,
#    this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

r"""Cython implementation.

Note:
    Wherever the Python implementation (i.e. ``bytesparse`` package) provides
    docstrings, no such docstrings are provided by the Cython implementation,
    which would result in duplicated docstrings, with maintenance efforts
    required.

    Cython compiles docstrings at compile time, making impossible to patch
    docstrings dynamically with those from the parent Python implementation.
    This is also one of the reasons why the ``cbytesparse.py`` module exists.

    Should you need actual documentation, instead of the stubs automatically
    generated by Sphinx, please refer to
    `the ``bytesparse`` documentation <https://bytesparse.readthedocs.io/>`_.
"""

cimport cython
from cpython.bytearray cimport PyByteArray_FromStringAndSize
from cpython.bytes cimport PyBytes_FromStringAndSize
from cpython.object cimport Py_EQ
from cpython.object cimport Py_GE
from cpython.object cimport Py_GT
from cpython.object cimport Py_LE
from cpython.object cimport Py_LT
from cpython.object cimport Py_NE

from itertools import count as _count
from itertools import islice as _islice
from itertools import repeat as _repeat
from itertools import zip_longest as _zip_longest
from typing import Any
from typing import ByteString
from typing import Iterable
from typing import Iterator
from typing import List
from typing import Mapping
from typing import Optional
from typing import Sequence
from typing import Tuple
from typing import Type
from typing import TypeVar
from typing import Union
from typing import cast as _cast

from bytesparse.base import STR_MAX_CONTENT_SIZE
from bytesparse.base import Address
from bytesparse.base import AddressValueMapping
from bytesparse.base import AnyBytes
from bytesparse.base import Block
from bytesparse.base import BlockIndex
from bytesparse.base import BlockIterable
from bytesparse.base import BlockList
from bytesparse.base import BlockSequence
from bytesparse.base import ClosedInterval
from bytesparse.base import EllipsisType
from bytesparse.base import ImmutableMemory
from bytesparse.base import MutableBytesparse
from bytesparse.base import MutableMemory
from bytesparse.base import OpenInterval
from bytesparse.base import Value

from .base import BytesLike

try:
    from typing import Self
except ImportError:  # pragma: no cover  # Python < 3.11
    Self = None  # dummy
    _MemorySelf = TypeVar('_MemorySelf', bound='Memory')
    _BytesparseSelf = TypeVar('_BytesparseSelf', bound='bytesparse')
else:  # pragma: no cover
    _MemorySelf = Self
    _BytesparseSelf = Self


cdef:
    # Allocate an empty block, so that an empty view can be returned statically
    Block_* _empty_block = Block_Acquire(Block_Alloc(0, 0, False))

    # Allocate an empty bytearray to use to export empty memoryviews
    bytearray _empty_bytearray = bytearray(b'')


cdef extern from *:
    r"""
    #define ASCII_0 ((byte_t)'0')
    #define ASCII_9 ((byte_t)'9')
    #define ASCII_A_UPPER ((byte_t)'A')
    #define ASCII_Z_UPPER ((byte_t)'Z')
    #define ASCII_A_LOWER ((byte_t)'a')
    #define ASCII_Z_LOWER ((byte_t)'z')
    #define ASCII_UNDERSCORE ((byte_t)'_')
    """

    byte_t ASCII_0
    byte_t ASCII_9
    byte_t ASCII_A_UPPER
    byte_t ASCII_Z_UPPER
    byte_t ASCII_A_LOWER
    byte_t ASCII_Z_LOWER
    byte_t ASCII_UNDERSCORE


# =====================================================================================================================

# FIXME: Not yet provided by the current Cython (0.29.x)
cdef void* PyMem_Calloc(size_t nelem, size_t elsize):
    cdef:
        void* ptr
        size_t total

    if CannotMulSizeU(nelem, elsize):
        return NULL  # overflow
    total = nelem * elsize

    ptr = PyMem_Malloc(total)
    if ptr:
        memset(ptr, 0, total)
    return ptr


# =====================================================================================================================

cdef size_t Downsize(size_t allocated, size_t requested) nogil:
    # Note: free margin will be either before and after allocated data
    cdef size_t resized

    if requested < allocated >> 1:
        # Major downsize; allocate as per request
        resized = requested

        # Align to next MARGIN; always gives some additional MARGIN
        with cython.cdivision(True):
            resized += (2 * MARGIN) - (resized % MARGIN)
    else:
        # Do not require reallocation
        resized = allocated

        # Align to next MARGIN; always gives some additional MARGIN
        if resized < 2 * MARGIN:
            resized = 2 * MARGIN

    return resized


cdef size_t Upsize(size_t allocated, size_t requested) nogil:
    # Note: free margin will be either before and after allocated data
    cdef size_t resized = requested

    # Moderate upsize; overallocate proportionally
    if resized <= allocated + (allocated >> 3):
        resized += resized >> 3

    # Align to next MARGIN; always gives some additional MARGIN
    with cython.cdivision(True):
        resized += (2 * MARGIN) - (resized % MARGIN)
    return resized


# ---------------------------------------------------------------------------------------------------------------------

cdef const void* memrchr(const void *ptr, int ch, size_t count) nogil:
    cdef:
        const byte_t* data_ptr = <const byte_t*>ptr
        const byte_t* cur_ptr = &data_ptr[count]
        const byte_t* end_ptr = &data_ptr[0]
        byte_t b = <byte_t>ch

    while cur_ptr != end_ptr:
        cur_ptr -= 1
        if cur_ptr[0] == b:
            return cur_ptr
    return NULL


cdef void Reverse(byte_t* buffer, size_t start, size_t endin) nogil:
    cdef:
        byte_t t

    while start < endin:
        t = buffer[start]
        buffer[start] = buffer[endin]
        buffer[endin] = t
        start += 1
        endin -= 1


cdef bint IsSequence(object obj) except -1:
    try:
        len(obj)
        obj[0:0]
        return True
    except TypeError:
        return False


# =====================================================================================================================

cdef bint CannotAddSizeU(size_t a, size_t b) nogil:
    return SIZE_MAX - a < b


cdef vint CheckAddSizeU(size_t a, size_t b) except -1:
    if CannotAddSizeU(a, b):
        raise OverflowError()


cdef size_t AddSizeU(size_t a, size_t b) except? 0xDEAD:
    CheckAddSizeU(a, b)
    return a + b


cdef bint CannotSubSizeU(size_t a, size_t b) nogil:
    return a < b


cdef vint CheckSubSizeU(size_t a, size_t b) except -1:
    if CannotSubSizeU(a, b):
        raise OverflowError()


cdef size_t SubSizeU(size_t a, size_t b) except? 0xDEAD:
    CheckSubSizeU(a, b)
    return a - b


cdef bint CannotMulSizeU(size_t a, size_t b) nogil:
    cdef:
        size_t r = a * b
    return a and b and (r < a or r < b)


cdef vint CheckMulSizeU(size_t a, size_t b) except -1:
    if CannotMulSizeU(a, b):
        raise OverflowError()


cdef size_t MulSizeU(size_t a, size_t b) except? 0xDEAD:
    CheckMulSizeU(a, b)
    return a * b


# ---------------------------------------------------------------------------------------------------------------------

cdef bint CannotAddSizeS(ssize_t a, ssize_t b) nogil:
    return ((b > 0 and a > SSIZE_MAX - b) or
            (b < 0 and a < SSIZE_MIN - b))


cdef vint CheckAddSizeS(ssize_t a, ssize_t b) except -1:
    if CannotAddSizeS(a, b):
        raise OverflowError()


cdef ssize_t AddSizeS(ssize_t a, ssize_t b) except? 0xDEAD:
    CheckAddSizeS(a, b)
    return a + b


cdef bint CannotSubSizeS(ssize_t a, ssize_t b) nogil:
    return ((b > 0 and a < SSIZE_MIN + b) or
            (b < 0 and a > SSIZE_MAX + b))


cdef vint CheckSubSizeS(ssize_t a, ssize_t b) except -1:
    if CannotSubSizeS(a, b):
        raise OverflowError()


cdef ssize_t SubSizeS(ssize_t a, ssize_t b) except? 0xDEAD:
    CheckSubSizeS(a, b)
    return a - b


cdef bint CannotMulSizeS(ssize_t a, ssize_t b) nogil:
    with cython.cdivision(True):
        if a > 0:
            if b > 0:
                return a > (SSIZE_MAX // b)
            else:
                return b < (SSIZE_MIN // a)
        else:
            if b > 0:
                return a < (SSIZE_MIN // b)
            else:
                return a and b < (SSIZE_MAX // a)


cdef vint CheckMulSizeS(ssize_t a, ssize_t b) except -1:
    if CannotMulSizeS(a, b):
        raise OverflowError()


cdef ssize_t MulSizeS(ssize_t a, ssize_t b) except? 0xDEAD:
    CheckMulSizeS(a, b)
    return a * b


# =====================================================================================================================

cdef bint CannotAddAddrU(addr_t a, addr_t b) nogil:
    return ADDR_MAX - a < b


cdef vint CheckAddAddrU(addr_t a, addr_t b) except -1:
    if CannotAddAddrU(a, b):
        raise OverflowError()


cdef addr_t AddAddrU(addr_t a, addr_t b) except? 0xDEAD:
    CheckAddAddrU(a, b)
    return a + b


cdef bint CannotSubAddrU(addr_t a, addr_t b) nogil:
    return a < b


cdef vint CheckSubAddrU(addr_t a, addr_t b) except -1:
    if CannotSubAddrU(a, b):
        raise OverflowError()


cdef addr_t SubAddrU(addr_t a, addr_t b) except? 0xDEAD:
    CheckSubAddrU(a, b)
    return a - b


cdef bint CannotMulAddrU(addr_t a, addr_t b) nogil:
    cdef:
        addr_t r = a * b
    return a and b and (r < a or r < b)


cdef vint CheckMulAddrU(addr_t a, addr_t b) except -1:
    if CannotMulAddrU(a, b):
        raise OverflowError()


cdef addr_t MulAddrU(addr_t a, addr_t b) except? 0xDEAD:
    CheckMulAddrU(a, b)
    return a * b


cdef bint CannotAddrToSizeU(addr_t a) nogil:
    return a > <addr_t>SIZE_MAX


cdef vint CheckAddrToSizeU(addr_t a) except -1:
    if CannotAddrToSizeU(a):
        raise OverflowError()


cdef size_t AddrToSizeU(addr_t a) except? 0xDEAD:
    CheckAddrToSizeU(a)
    return <size_t>a


# ---------------------------------------------------------------------------------------------------------------------

cdef bint CannotAddAddrS(saddr_t a, saddr_t b) nogil:
    return ((b > 0 and a > SADDR_MAX - b) or
            (b < 0 and a < SADDR_MIN - b))


cdef vint CheckAddAddrS(saddr_t a, saddr_t b) except -1:
    if CannotAddAddrS(a, b):
        raise OverflowError()


cdef saddr_t AddAddrS(saddr_t a, saddr_t b) except? 0xDEAD:
    CheckAddAddrS(a, b)
    return a + b


cdef bint CannotSubAddrS(saddr_t a, saddr_t b) nogil:
    return ((b > 0 and a < SADDR_MIN + b) or
            (b < 0 and a > SADDR_MAX + b))


cdef vint CheckSubAddrS(saddr_t a, saddr_t b) except -1:
    if CannotSubAddrS(a, b):
        raise OverflowError()


cdef saddr_t SubAddrS(saddr_t a, saddr_t b) except? 0xDEAD:
    CheckSubAddrS(a, b)
    return a - b


cdef bint CannotMulAddrS(saddr_t a, saddr_t b) nogil:
    with cython.cdivision(True):
        if a > 0:
            if b > 0:
                return a > (SADDR_MAX // b)
            else:
                return b < (SADDR_MIN // a)
        else:
            if b > 0:
                return a < (SADDR_MIN // b)
            else:
                return a and b < (SADDR_MAX // a)


cdef vint CheckMulAddrS(saddr_t a, saddr_t b) except -1:
    if CannotMulAddrS(a, b):
        raise OverflowError()


cdef saddr_t MulAddrS(saddr_t a, saddr_t b) except? 0xDEAD:
    CheckMulAddrS(a, b)
    return a * b


cdef bint CannotAddrToSizeS(saddr_t a) nogil:
    return a < <saddr_t>SSIZE_MIN or a > <saddr_t>SSIZE_MAX


cdef vint CheckAddrToSizeS(saddr_t a) except -1:
    if CannotAddrToSizeS(a):
        raise OverflowError()


cdef ssize_t AddrToSizeS(saddr_t a) except? 0xDEAD:
    CheckAddrToSizeS(a)
    return <ssize_t>a


# =====================================================================================================================

cdef bint Buffer_RichCmp_(const byte_t* data_ptr, size_t data_size,
                          const byte_t* token_ptr, size_t token_size,
                          int op) nogil:

    if op == Py_EQ:
        if data_size != token_size:
            return False
        return memcmp(data_ptr, token_ptr, data_size) == 0

    if op == Py_NE:
        if data_size != token_size:
            return True
        return memcmp(data_ptr, token_ptr, data_size) != 0

    if op == Py_LT:
        if data_size > token_size:
            return False
        elif data_size == token_size:
            return memcmp(data_ptr, token_ptr, data_size) < 0
        else:
            return memcmp(data_ptr, token_ptr, data_size) <= 0

    if op == Py_LE:
        if data_size > token_size:
            return False
        else:
            return memcmp(data_ptr, token_ptr, data_size) <= 0

    if op == Py_GE:
        if data_size < token_size:
            return False
        else:
            return memcmp(data_ptr, token_ptr, token_size) >= 0

    if op == Py_GT:
        if data_size < token_size:
            return False
        elif data_size == token_size:
            return memcmp(data_ptr, token_ptr, token_size) > 0
        else:
            return memcmp(data_ptr, token_ptr, token_size) >= 0

    return False


cdef bint Buffer_RichCmp(const byte_t[:] data_view,
                         const byte_t[:] token_view,
                         int op) nogil:

    with cython.boundscheck(False):
        return Buffer_RichCmp_(&data_view[0], len(data_view),
                               &token_view[0], len(token_view),
                               op)


cdef size_t Buffer_Count_(const byte_t* data_ptr, size_t data_size,
                          const byte_t* token_ptr, size_t token_size,
                          size_t data_start, size_t data_endex) nogil:
    cdef:
        size_t count = 0

    if data_endex > data_size: data_endex = data_size
    if data_endex < data_start: return 0
    if token_size == 0: return data_endex - data_start + 1
    if token_size > data_endex - data_start: return 0
    data_endex -= token_size

    while data_start <= data_endex:
        if data_ptr[data_start] != token_ptr[0]:  # early pruning
            data_start += 1
        elif memcmp(&data_ptr[data_start], token_ptr, token_size):
            data_start += 1
        else:
            count += 1
            if CannotAddSizeU(data_start, token_size): break
            data_start += token_size
    return count


cdef size_t Buffer_Count(const byte_t[:] data_view,
                         const byte_t[:] token_view,
                         size_t data_start, size_t data_endex) nogil:

    with cython.boundscheck(False):
        return Buffer_Count_(&data_view[0], len(data_view),
                             &token_view[0], len(token_view),
                             data_start, data_endex)


cdef bint Buffer_StartsWith_(const byte_t* data_ptr, size_t data_size,
                             const byte_t* token_ptr, size_t token_size) nogil:

    if token_size == 0: return True
    if data_size < token_size: return False
    return memcmp(&data_ptr[0], token_ptr, token_size) == 0


cdef bint Buffer_StartsWith(const byte_t[:] data_view,
                            const byte_t[:] token_view) nogil:

    with cython.boundscheck(False):
        return Buffer_StartsWith_(&data_view[0], len(data_view),
                                  &token_view[0], len(token_view))


cdef bint Buffer_EndsWith_(const byte_t* data_ptr, size_t data_size,
                           const byte_t* token_ptr, size_t token_size) nogil:

    if token_size == 0: return True
    if data_size < token_size: return False
    return memcmp(&data_ptr[data_size - token_size], token_ptr, token_size) == 0


cdef bint Buffer_EndsWith(const byte_t[:] data_view,
                          const byte_t[:] token_view) nogil:

    with cython.boundscheck(False):
        return Buffer_EndsWith_(&data_view[0], len(data_view),
                                &token_view[0], len(token_view))


cdef bint Buffer_Contains_(const byte_t* data_ptr, size_t data_size,
                           const byte_t* token_ptr, size_t token_size,
                           size_t data_start, size_t data_endex) nogil:

    return Buffer_Find_(data_ptr, data_size,
                        token_ptr, token_size,
                        data_start, data_endex) >= 0


cdef bint Buffer_Contains(const byte_t[:] data_view,
                          const byte_t[:] token_view,
                          size_t data_start, size_t data_endex) nogil:

    with cython.boundscheck(False):
        return Buffer_Contains_(&data_view[0], len(data_view),
                                &token_view[0], len(token_view),
                                data_start, data_endex)


cdef ssize_t Buffer_Find_(const byte_t* data_ptr, size_t data_size,
                          const byte_t* token_ptr, size_t token_size,
                          size_t data_start, size_t data_endex) nogil:
    cdef:
        const byte_t* data_cur
        const byte_t* data_end

    if data_endex > data_size: data_endex = data_size
    if data_endex < data_start: return -1
    if token_size == 0: return data_start
    if token_size > data_endex - data_start: return -1
    data_cur = &data_ptr[data_start]
    data_end = &data_ptr[data_endex]

    while True:
        data_size = <size_t>(<uintptr_t>data_end - <uintptr_t>data_cur)
        data_cur = <const byte_t*>memchr(data_cur, token_ptr[0], data_size)
        if data_cur == NULL: return -1
        if memcmp(data_cur, token_ptr, token_size) == 0:
            return <ssize_t><size_t>(<uintptr_t>data_cur - <uintptr_t>data_ptr)
        data_cur += 1


cdef ssize_t Buffer_Find(const byte_t[:] data_view,
                         const byte_t[:] token_view,
                         size_t data_start, size_t data_endex) nogil:

    with cython.boundscheck(False):
        return Buffer_Find_(&data_view[0], len(data_view),
                            &token_view[0], len(token_view),
                            data_start, data_endex)


cdef ssize_t Buffer_RevFind_(const byte_t* data_ptr, size_t data_size,
                             const byte_t* token_ptr, size_t token_size,
                             size_t data_start, size_t data_endex) nogil:
    cdef:
        const byte_t* data_cur
        const byte_t* data_end

    if data_endex > data_size: data_endex = data_size
    if data_endex < data_start: return -1
    if token_size == 0: return data_endex
    if token_size > data_endex - data_start: return -1
    data_endex -= token_size - 1
    data_cur = &data_ptr[data_endex]
    data_end = &data_ptr[data_start]

    while True:
        data_size = <size_t>(<uintptr_t>data_cur - <uintptr_t>data_end)
        data_cur = <const byte_t*>memrchr(data_end, token_ptr[0], data_size)
        if data_cur == NULL: return -1
        if memcmp(data_cur, token_ptr, token_size) == 0:
            return <ssize_t><size_t>(<uintptr_t>data_cur - <uintptr_t>data_ptr)


cdef ssize_t Buffer_RevFind(const byte_t[:] data_view,
                            const byte_t[:] token_view,
                            size_t data_start, size_t data_endex) nogil:

    with cython.boundscheck(False):
        return Buffer_RevFind_(&data_view[0], len(data_view),
                               &token_view[0], len(token_view),
                               data_start, data_endex)


cdef ssize_t Buffer_Index_(const byte_t* data_ptr, size_t data_size,
                           const byte_t* token_ptr, size_t token_size,
                           size_t data_start, size_t data_endex) except -1:
    cdef:
        ssize_t index = Buffer_Find_(data_ptr, data_size,
                                     token_ptr, token_size,
                                     data_start, data_endex)

    if index < 0:
        raise ValueError('subsection not found')
    return index


cdef ssize_t Buffer_Index(const byte_t[:] data_view,
                          const byte_t[:] token_view,
                          size_t data_start, size_t data_endex) except -1:

    with cython.boundscheck(False):
        return Buffer_Index_(&data_view[0], len(data_view),
                             &token_view[0], len(token_view),
                             data_start, data_endex)


cdef ssize_t Buffer_RevIndex_(const byte_t* data_ptr, size_t data_size,
                              const byte_t* token_ptr, size_t token_size,
                              size_t data_start, size_t data_endex) except -1:
    cdef:
        ssize_t index = Buffer_RevFind_(data_ptr, data_size,
                                        token_ptr, token_size,
                                        data_start, data_endex)

    if index < 0:
        raise ValueError('subsection not found')
    return index


cdef ssize_t Buffer_RevIndex(const byte_t[:] data_view,
                             const byte_t[:] token_view,
                             size_t data_start, size_t data_endex) except -1:

    with cython.boundscheck(False):
        return Buffer_RevIndex_(&data_view[0], len(data_view),
                                &token_view[0], len(token_view),
                                data_start, data_endex)


cdef size_t Buffer_Replace_(byte_t* data_ptr, size_t data_size,
                            const byte_t* old_ptr, size_t old_size,
                            const byte_t* new_ptr,
                            size_t count,
                            size_t data_start, size_t data_endex) nogil:
    cdef:
        ssize_t index
        size_t times = 0

    if old_size == 0:
        count = 0  # early pruning

    while times < count:
        index = Buffer_Find_(data_ptr, data_size,
                             old_ptr, old_size,
                             data_start, data_endex)
        if index < 0: break
        memcpy(&data_ptr[<size_t>index], new_ptr, old_size)
        data_start = <size_t>index + old_size
        times += 1

    return times


cdef size_t Buffer_Replace(byte_t[:] data_view,
                           const byte_t[:] old_view,
                           const byte_t[:] new_view,
                           size_t count,
                           size_t data_start, size_t data_endex) except? -1:

    if len(old_view) != len(new_view):
        raise ValueError('different sizes')

    with cython.boundscheck(False):
        return Buffer_Replace_(&data_view[0], len(data_view),
                               &old_view[0], len(old_view),
                               &new_view[0],
                               count,
                               data_start, data_endex)


cdef size_t Buffer_RevReplace_(byte_t* data_ptr, size_t data_size,
                               const byte_t* old_ptr, size_t old_size,
                               const byte_t* new_ptr,
                               size_t count,
                               size_t data_start, size_t data_endex) nogil:
    cdef:
        ssize_t index
        size_t times = 0

    if old_size == 0:
        count = 0  # early pruning

    while times < count:
        index = Buffer_RevFind_(data_ptr, data_size,
                                old_ptr, old_size,
                                data_start, data_endex)
        if index < 0: break
        memcpy(&data_ptr[<size_t>index], new_ptr, old_size)
        data_endex = <size_t>index
        times += 1

    return times


cdef size_t Buffer_RevReplace(byte_t[:] data_view,
                              const byte_t[:] old_view,
                              const byte_t[:] new_view,
                              size_t count,
                              size_t data_start, size_t data_endex) except? -1:

    if len(old_view) != len(new_view):
        raise ValueError('different sizes')

    with cython.boundscheck(False):
        return Buffer_RevReplace_(&data_view[0], len(data_view),
                                  &old_view[0], len(old_view),
                                  &new_view[0],
                                  count,
                                  data_start, data_endex)


cdef bint Buffer_IsAlNum_(const byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    if data_size:
        for i in range(data_size):
            c = data_ptr[i]
            if ASCII_0 <= c <= ASCII_9: continue
            if ASCII_A_UPPER <= c <= ASCII_Z_UPPER: continue
            if ASCII_A_LOWER <= c <= ASCII_Z_LOWER: continue
            return False
        return True
    else:
        return False


cdef bint Buffer_IsAlNum(const byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        return Buffer_IsAlNum_(&data_view[0], len(data_view))


cdef bint Buffer_IsAlpha_(const byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    if data_size:
        for i in range(data_size):
            c = data_ptr[i]
            if ASCII_A_UPPER <= c <= ASCII_Z_UPPER: continue
            if ASCII_A_LOWER <= c <= ASCII_Z_LOWER: continue
            return False
        return True
    else:
        return False


cdef bint Buffer_IsAlpha(const byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        return Buffer_IsAlpha_(&data_view[0], len(data_view))


cdef bint Buffer_IsASCII_(const byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    for i in range(data_size):
        c = data_ptr[i]
        if c < 128: continue
        return False
    return True


cdef bint Buffer_IsASCII(const byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        return Buffer_IsASCII_(&data_view[0], len(data_view))


cdef bint Buffer_IsDigit_(const byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    if data_size:
        for i in range(data_size):
            c = data_ptr[i]
            if ASCII_0 <= c <= ASCII_9: continue
            return False
        return True
    else:
        return False


cdef bint Buffer_IsDigit(const byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        return Buffer_IsDigit_(&data_view[0], len(data_view))


cdef bint Buffer_IsIdentifier_(const byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    if data_size:
        for i in range(1):
            c = data_ptr[i]
            if ASCII_A_UPPER <= c <= ASCII_Z_UPPER: continue
            if ASCII_A_LOWER <= c <= ASCII_Z_LOWER: continue
            if c == ASCII_UNDERSCORE: continue
            return False

        for i in range(1, data_size):
            c = data_ptr[i]
            if ASCII_0 <= c <= ASCII_9: continue
            if ASCII_A_UPPER <= c <= ASCII_Z_UPPER: continue
            if ASCII_A_LOWER <= c <= ASCII_Z_LOWER: continue
            if c == ASCII_UNDERSCORE: continue
            return False

        return True
    else:
        return False


cdef bint Buffer_IsIdentifier(const byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        return Buffer_IsIdentifier_(&data_view[0], len(data_view))


cdef bint Buffer_IsLower_(const byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c
        bint cased = False

    for i in range(data_size):
        c = data_ptr[i]
        if ASCII_A_UPPER <= c <= ASCII_Z_UPPER:
            return False
        if not cased:
            if ASCII_A_LOWER <= c <= ASCII_Z_LOWER:
                cased = True
    return cased


cdef bint Buffer_IsLower(const byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        return Buffer_IsLower_(&data_view[0], len(data_view))


cdef bint Buffer_IsUpper_(const byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c
        bint cased = False

    for i in range(data_size):
        c = data_ptr[i]
        if ASCII_A_LOWER <= c <= ASCII_Z_LOWER:
            return False
        if not cased:
            if ASCII_A_UPPER <= c <= ASCII_Z_UPPER:
                cased = True
    return cased


cdef bint Buffer_IsUpper(const byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        return Buffer_IsUpper_(&data_view[0], len(data_view))


cdef bint Buffer_IsPrintable_(const byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    if data_size:
        for i in range(data_size):
            c = data_ptr[i]
            if 0x20 <= c <= 0x7E: continue
            return False
        return True
    else:
        return False


cdef bint Buffer_IsPrintable(const byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        return Buffer_IsPrintable_(&data_view[0], len(data_view))


cdef bint Buffer_IsSpace_(const byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    if data_size:
        for i in range(data_size):
            c = data_ptr[i]
            if 0x09 <= c <= 0x0D: continue
            if c == 0x20: continue
            return False
        return True
    else:
        return False


cdef bint Buffer_IsSpace(const byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        return Buffer_IsSpace_(&data_view[0], len(data_view))


cdef bint Buffer_IsTitle_(byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c
        bint inside = False

    if data_size:
        for i in range(data_size):
            c = data_ptr[i]

            if ASCII_A_LOWER <= c <= ASCII_Z_LOWER:
                if not inside:
                    return False
                inside = True

            elif ASCII_A_UPPER <= c <= ASCII_Z_UPPER:
                if inside:
                    return False
                inside = True

            else:
                inside = False

        return True
    else:
        return False


cdef bint Buffer_IsTitle(byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        return Buffer_IsTitle_(&data_view[0], len(data_view))


cdef void Buffer_Lower_(byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    for i in range(data_size):
        c = data_ptr[i]
        if ASCII_A_UPPER <= c <= ASCII_Z_UPPER:
            data_ptr[i] += ASCII_A_LOWER - ASCII_A_UPPER


cdef void Buffer_Lower(byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        Buffer_Lower_(&data_view[0], len(data_view))


cdef void Buffer_Upper_(byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    for i in range(data_size):
        c = data_ptr[i]
        if ASCII_A_LOWER <= c <= ASCII_Z_LOWER:
            data_ptr[i] -= ASCII_A_LOWER - ASCII_A_UPPER


cdef void Buffer_Upper(byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        Buffer_Upper_(&data_view[0], len(data_view))


cdef void Buffer_SwapCase_(byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    for i in range(data_size):
        c = data_ptr[i]

        if ASCII_A_UPPER <= c <= ASCII_Z_UPPER:
            data_ptr[i] += ASCII_A_LOWER - ASCII_A_UPPER

        elif ASCII_A_LOWER <= c <= ASCII_Z_LOWER:
            data_ptr[i] -= ASCII_A_LOWER - ASCII_A_UPPER


cdef void Buffer_SwapCase(byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        Buffer_SwapCase_(&data_view[0], len(data_view))


cdef void Buffer_Capitalize_(byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c

    if data_size:
        c = data_ptr[0]
        if ASCII_A_LOWER <= c <= ASCII_Z_LOWER:
            data_ptr[0] -= ASCII_A_LOWER - ASCII_A_UPPER

    for i in range(1, data_size):
        c = data_ptr[i]
        if ASCII_A_UPPER <= c <= ASCII_Z_UPPER:
            data_ptr[i] += ASCII_A_LOWER - ASCII_A_UPPER


cdef void Buffer_Capitalize(byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        Buffer_Capitalize_(&data_view[0], len(data_view))


cdef void Buffer_Title_(byte_t* data_ptr, size_t data_size) nogil:
    cdef:
        size_t i
        byte_t c
        bint inside = False

    for i in range(data_size):
        c = data_ptr[i]

        if ASCII_A_LOWER <= c <= ASCII_Z_LOWER:
            if not inside:
                data_ptr[i] -= ASCII_A_LOWER - ASCII_A_UPPER
            inside = True

        elif ASCII_A_UPPER <= c <= ASCII_Z_UPPER:
            if inside:
                data_ptr[i] += ASCII_A_LOWER - ASCII_A_UPPER
            inside = True

        else:
            inside = False


cdef void Buffer_Title(byte_t[:] data_view) nogil:

    with cython.boundscheck(False):
        Buffer_Title_(&data_view[0], len(data_view))


cdef bytes Buffer_MakeTrans_(const byte_t* in_ptr, size_t in_size, const byte_t* out_ptr):
    cdef:
        bytearray table = bytearray(range(256))
        size_t i

    for i in range(in_size):
        table[in_ptr[i]] = out_ptr[i]

    return bytes(table)


cdef bytes Buffer_MakeTrans(const byte_t[:] in_view,
                            const byte_t[:] out_view):

    if len(in_view) != len(out_view):
        raise ValueError('maketrans arguments must have same length')

    with cython.boundscheck(False):
        return Buffer_MakeTrans_(&in_view[0], len(in_view), &out_view[0])


cdef void Buffer_Translate_(byte_t* data_ptr, size_t data_size, const byte_t* table_ptr) nogil:
    cdef:
        size_t i

    for i in range(data_size):
        data_ptr[i] = table_ptr[data_ptr[i]]


cdef vint Buffer_Translate(byte_t[:] data_view,
                           const byte_t[:] table_view) except -1:

    if len(table_view) != 256:
        raise ValueError('translation table must be 256 characters long')

    with cython.boundscheck(False):
        Buffer_Translate_(&data_view[0], len(data_view), &table_view[0])


# ---------------------------------------------------------------------------------------------------------------------

cdef class BytesMethods:

    cdef vint check_obj_(BytesMethods self) except -1:
        if self._obj is None:
            raise ValueError('operation forbidden on released memoryview object')

    cdef vint check_readonly_(BytesMethods self) except -1:
        if self._readonly:
            raise TypeError('wrapped object does not support item assignment')

    cdef vint update_readonly_(BytesMethods self) except -1:
        self._readonly = True  # ensure

    def __bool__(
        self: BytesMethods,
    ) -> bool:

        return bool(self._obj)

    def __bytes__(
        self,
    ) -> bytes:
        cdef:
            const byte_t[:] view
            bytes exported

        self.check_obj_()
        view = self._obj
        return bytes(view)

    def __contains__(
        self: BytesMethods,
        token not None: ByteString,
    ) -> bool:

        self.check_obj_()
        return Buffer_Contains(self._obj, token, 0, SIZE_MAX)

    def __delitem__(
        self: BytesMethods,
        key: Any,
    ) -> None:

        raise TypeError("readonly object doesn't support item deletion")

    def __getitem__(
        self: BytesMethods,
        key: Any,
    ) -> Any:

        return self._obj[key]

    def __init__(
        self: BytesMethods,
        wrapped: ByteString,
    ):
        cdef:
            const byte_t[:] layout_test

        if wrapped is not None:
            try:
                layout_test = wrapped
            except ValueError:
                wrapped = memoryview(wrapped).cast('B')

        self._obj = wrapped
        self.update_readonly_()

    def __iter__(
        self: BytesMethods,
    ) -> Iterable[int]:

        yield from self._obj

    def __len__(
        self: BytesMethods,
    ) -> int:

        return len(self._obj)

    def __reversed__(
        self: BytesMethods,
    ) -> Iterable[int]:

        yield from reversed(self._obj)

    def __richcmp__(
        self: BytesMethods,
        other: ByteString,
        op: int,
    ) -> bool:

        obj = self._obj

        if op == Py_EQ:
            if (obj is None) and (other is None):
                return True
            if (obj is None) != (other is None):
                return False

        elif op == Py_NE:
            if (obj is None) and (other is None):
                return False
            if (obj is None) != (other is None):
                return True

        else:
            if (obj is None) or (other is None):
                raise TypeError("operation not supported against instances of 'NoneType'")

        return Buffer_RichCmp(self._obj, other, op)

    def __setitem__(
        self: BytesMethods,
        key: Any,
        value: Any,
    ) -> None:

        self.check_readonly_()  # should fail

    def __sizeof__(
        self: BytesMethods,
    ) -> int:

        return sizeof(BytesMethods)

    @property
    def c_contiguous(
        self: BytesMethods,
    ) -> bool:

        return True

    def capitalize(
        self: BytesMethods,
    ) -> ByteString:

        self.check_obj_()
        obj = bytearray(self._obj)
        Buffer_Capitalize(obj)
        return obj

    def contains(
        self: BytesMethods,
        token not None: ByteString,
        start: Optional[int] = None,
        endex: Optional[int] = None,
    ) -> int:
        cdef:
            size_t start_ = SIZE_MIN if start is None else <size_t>start
            size_t endex_ = SIZE_MAX if endex is None else <size_t>endex

        self.check_obj_()
        return Buffer_Contains(self._obj, token, start_, endex_)

    @property
    def contiguous(
        self: BytesMethods,
    ) -> bool:

        return True

    def count(
        self: BytesMethods,
        token not None: ByteString,
        start: Optional[int] = None,
        endex: Optional[int] = None,
    ) -> int:
        cdef:
            size_t start_ = SIZE_MIN if start is None else <size_t>start
            size_t endex_ = SIZE_MAX if endex is None else <size_t>endex

        self.check_obj_()
        return Buffer_Count(self._obj, token, start_, endex_)

    def endswith(
        self: BytesMethods,
        token not None: ByteString,
    ) -> bool:

        self.check_obj_()
        return Buffer_EndsWith(self._obj, token)

    @property
    def f_contiguous(
        self: BytesMethods,
    ) -> bool:

        return True

    def find(
        self: BytesMethods,
        token not None: ByteString,
        start: Optional[int] = None,
        endex: Optional[int] = None,
    ) -> int:
        cdef:
            size_t start_ = SIZE_MIN if start is None else <size_t>start
            size_t endex_ = SIZE_MAX if endex is None else <size_t>endex

        self.check_obj_()
        return Buffer_Find(self._obj, token, start_, endex_)

    @property
    def format(
        self: BytesMethods,
    ) -> str:

        return 'B'

    def index(
        self: BytesMethods,
        token not None: ByteString,
        start: Optional[int] = None,
        endex: Optional[int] = None,
    ) -> int:
        cdef:
            size_t start_ = SIZE_MIN if start is None else <size_t>start
            size_t endex_ = SIZE_MAX if endex is None else <size_t>endex

        self.check_obj_()
        return Buffer_Index(self._obj, token, start_, endex_)

    def isalnum(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsAlNum(self._obj)

    def isalpha(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsAlpha(self._obj)

    def isascii(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsASCII(self._obj)

    def isdecimal(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsDigit(self._obj)

    def isdigit(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsDigit(self._obj)

    def isidentifier(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsIdentifier(self._obj)

    def islower(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsLower(self._obj)

    def isnumeric(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return self.isdigit()

    def isprintable(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsPrintable(self._obj)

    def isspace(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsSpace(self._obj)

    def istitle(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsTitle(self._obj)

    def isupper(
        self: BytesMethods,
    ) -> bool:

        self.check_obj_()
        return Buffer_IsUpper(self._obj)

    @property
    def itemsize(
        self: BytesMethods,
    ) -> int:

        return 1

    def lower(
        self: BytesMethods,
    ) -> ByteString:

        self.check_obj_()
        obj = bytearray(self._obj)
        Buffer_Lower(obj)
        return obj

    @staticmethod
    def maketrans(
        chars_from not None: ByteString,
        chars_to not None: ByteString,
    ) -> bytes:

        return Buffer_MakeTrans(chars_from, chars_to)

    @property
    def nbytes(
        self: BytesMethods,
    ) -> int:

        self.check_obj_()
        return len(self._obj)

    @property
    def ndim(
        self: BytesMethods,
    ) -> int:

        return 1

    @property
    def obj(
        self: BytesMethods,
    ) -> Optional[ByteString]:

        self.check_obj_()
        return self._obj

    @property
    def readonly(
        self: BytesMethods,
    ) -> bool:

        return self._readonly

    def release(
        self: BytesMethods,
    ) -> None:

        self.check_obj_()
        self._obj = None
        self.update_readonly_()

    def replace(
        self: BytesMethods,
        old not None: ByteString,
        new not None: ByteString,
        count: Optional[int] = None,
        start: Optional[int] = None,
        endex: Optional[int] = None,
    ) -> ByteString:
        cdef:
            size_t count_ = SIZE_MAX if count is None else <size_t>count
            size_t start_ = SIZE_MIN if start is None else <size_t>start
            size_t endex_ = SIZE_MAX if endex is None else <size_t>endex

        self.check_obj_()
        obj = bytearray(self._obj)
        Buffer_Replace(obj, old, new, count_, start_, endex_)
        return obj

    def rfind(
        self: BytesMethods,
        token not None: ByteString,
        start: Optional[int] = None,
        endex: Optional[int] = None,
    ) -> int:
        cdef:
            size_t start_ = SIZE_MIN if start is None else <size_t>start
            size_t endex_ = SIZE_MAX if endex is None else <size_t>endex

        self.check_obj_()
        return Buffer_RevFind(self._obj, token, start_, endex_)

    def rindex(
        self: BytesMethods,
        token not None: ByteString,
        start: Optional[int] = None,
        endex: Optional[int] = None,
    ) -> int:
        cdef:
            size_t start_ = SIZE_MIN if start is None else <size_t>start
            size_t endex_ = SIZE_MAX if endex is None else <size_t>endex

        self.check_obj_()
        return Buffer_RevIndex(self._obj, token, start_, endex_)

    @property
    def shape(
        self: BytesMethods,
    ) -> Tuple[int]:

        self.check_obj_()
        return (len(self._obj),)

    def startswith(
        self: BytesMethods,
        token not None: ByteString,
    ) -> bool:

        self.check_obj_()
        return Buffer_StartsWith(self._obj, token)

    @property
    def strides(
        self: BytesMethods,
    ) -> Tuple[int]:

        return (1,)

    @property
    def suboffsets(
        self: BytesMethods,
    ) -> Tuple:

        return ()

    def swapcase(
        self: BytesMethods,
    ) -> ByteString:

        self.check_obj_()
        obj = bytearray(self._obj)
        Buffer_SwapCase(obj)
        return obj

    def title(
        self: BytesMethods,
    ) -> ByteString:

        self.check_obj_()
        obj = bytearray(self._obj)
        Buffer_Title(obj)
        return obj

    def tobytes(
        self: BytesMethods,
    ) -> bytes:

        self.check_obj_()
        return bytes(self._obj)

    def tolist(
        self: BytesMethods,
    ) -> List[int]:

        self.check_obj_()
        return list(self._obj)

    def translate(
        self: BytesMethods,
        table not None: ByteString,
    ) -> ByteString:

        self.check_obj_()
        obj = bytearray(self._obj)
        Buffer_Translate(obj, table)
        return obj

    def upper(
        self: BytesMethods,
    ) -> ByteString:

        self.check_obj_()
        obj = bytearray(self._obj)
        Buffer_Upper(obj)
        return obj


ByteString.register(BytesMethods)


# ---------------------------------------------------------------------------------------------------------------------

cdef class InplaceView(BytesMethods):

    cdef vint update_readonly_(InplaceView self) except -1:
        cdef:
            byte_t[:] writable

        if self._obj is None:
            self._readonly = True  # failsafe
        else:
            try:
                writable = self._obj
            except BufferError as exc:
                self._readonly = True
            else:
                self._readonly = False

    def __setitem__(
        self: InplaceView,
        key: Any,
        value: Any,
    ) -> None:

        self.check_readonly_()

        if isinstance(key, slice):
            start = key.start
            endex = key.stop
            step = key.step
            value_size = len(value)
            wrapped_size = len(self._obj)

            start = 0 if start is None else start.__index__()
            if start < 0:
                start = wrapped_size
                if start < 0:
                    raise IndexError('index out of range')

            endex = wrapped_size if endex is None else endex.__index__()
            if endex < 0:
                endex = wrapped_size
                if endex < 0:
                    raise IndexError('index out of range')

            step = 1 if step is None else step.__index__()
            if step <= 1:
                slice_size = endex - start
            else:
                slice_size = (endex - start) // step

            if slice_size != value_size:
                raise IndexError('cannot resize view')

        self._obj[key] = value

    def capitalize(
        self: InplaceView,
    ) -> InplaceView:

        self.check_obj_()
        self.check_readonly_()
        Buffer_Capitalize(self._obj)
        return self

    def lower(
        self: InplaceView,
    ) -> InplaceView:

        self.check_obj_()
        self.check_readonly_()
        Buffer_Lower(self._obj)
        return self

    def replace(
        self: InplaceView,
        old not None: ByteString,
        new not None: ByteString,
        count: Optional[int] = None,
        start: Optional[int] = None,
        endex: Optional[int] = None,
    ) -> InplaceView:
        cdef:
            size_t count_ = SIZE_MAX if count is None else <size_t>count
            size_t start_ = SIZE_MIN if start is None else <size_t>start
            size_t endex_ = SIZE_MAX if endex is None else <size_t>endex

        self.check_obj_()
        self.check_readonly_()
        Buffer_Replace(self._obj, old, new, count_, start_, endex_)
        return self

    def swapcase(
        self: InplaceView,
    ) -> InplaceView:

        self.check_obj_()
        self.check_readonly_()
        Buffer_SwapCase(self._obj)
        return self

    def title(
        self: InplaceView,
    ) -> InplaceView:

        self.check_obj_()
        self.check_readonly_()
        Buffer_Title(self._obj)
        return self

    def toreadonly(
        self: InplaceView,
    ) -> InplaceView:
        cdef:
            InplaceView readonly

        self.check_obj_()
        readonly = InplaceView(self._obj)
        readonly._readonly = True
        return readonly

    def translate(
        self: InplaceView,
        table not None: ByteString,
    ) -> InplaceView:

        self.check_obj_()
        self.check_readonly_()
        Buffer_Translate(self._obj, table)
        return self

    def upper(
        self: InplaceView,
    ) -> InplaceView:

        self.check_obj_()
        self.check_readonly_()
        Buffer_Upper(self._obj)
        return self


# =====================================================================================================================

cdef Block_* Block_Alloc(addr_t address, size_t size, bint zero) except NULL:
    cdef:
        Block_* that = NULL
        size_t allocated
        size_t actual

    if size > SIZE_HMAX:
        raise OverflowError('size overflow')

    # Allocate as per request
    allocated = Upsize(0, size)
    if allocated > SIZE_HMAX:
        raise MemoryError()

    actual = Block_HEADING + (allocated * sizeof(byte_t))
    if zero:
        that = <Block_*>PyMem_Calloc(actual, 1)
    else:
        that = <Block_*>PyMem_Malloc(actual)
    if that == NULL:
        raise MemoryError()

    that.address = address
    that.references = 1  # acquired by default
    that.allocated = allocated
    that.start = MARGIN  # leave some initial room
    that.endex = that.start + size
    return that


cdef Block_* Block_Free(Block_* that):
    if that:
        PyMem_Free(that)
    return NULL


cdef size_t Block_Sizeof(const Block_* that):
    if that:
        return Block_HEADING + (that.allocated * sizeof(byte_t))
    return 0


cdef Block_* Block_Create(addr_t address, size_t size, const byte_t* buffer) except NULL:
    if not size or buffer:
        that = Block_Alloc(address, size, False)
        memcpy(&that.data[that.start], buffer, size * sizeof(byte_t))
        return that
    else:
        raise ValueError('null pointer')


cdef Block_* Block_Copy(const Block_* that) except NULL:
    cdef:
        Block_* ptr
        size_t size

    if that:
        size = Block_HEADING + (that.allocated * sizeof(byte_t))
        ptr = <Block_*>PyMem_Malloc(size)
        if ptr == NULL:
            raise MemoryError()

        memcpy(ptr, that, size)
        ptr.references = 1  # acquired by default
        return ptr
    else:
        raise ValueError('null pointer')


cdef Block_* Block_FromObject(addr_t address, object obj, bint nonnull) except NULL:
    cdef:
        byte_t value
        const byte_t[:] view
        size_t size
        const byte_t* ptr

    if isinstance(obj, int):
        value = <byte_t>obj
        return Block_Create(address, 1, &value)
    else:
        try:
            view = obj
        except TypeError:
            view = bytes(obj)
        size = len(view)
        if size:
            with cython.boundscheck(False):
                ptr = &view[0]
            return Block_Create(address, size, ptr)
        else:
            if nonnull:
                raise ValueError('invalid block data size')
            else:
                return Block_Alloc(address, 0, False)


cdef void Block_Reverse(Block_* that) nogil:
    cdef:
        size_t start = that.start
        size_t endex = that.endex
        size_t endin
        byte_t temp

    while start < endex:
        endin = endex - 1
        temp = that.data[start]
        that.data[start] = that.data[endin]
        that.data[endin] = temp
        endex = endin
        start += 1


cdef Block_* Block_Acquire(Block_* that) except NULL:
    if that:
        if that.references < SIZE_MAX:
            that.references += 1
            return that
        else:
            raise OverflowError()
    else:
        raise RuntimeError('null pointer')


cdef Block_* Block_Release_(Block_* that):
    if that:
        if that.references:
            that.references -= 1

        if that.references:
            return that
        else:
            PyMem_Free(that)

    return NULL


cdef Block_* Block_Release(Block_* that):
    if that:
        if that.references:
            that.references -= 1

        if not that.references:
            PyMem_Free(that)

    return NULL


cdef bint Block_Bool(const Block_* that) nogil:
    return that.start < that.endex


cdef size_t Block_Length(const Block_* that) nogil:
    return that.endex - that.start


cdef addr_t Block_Start(const Block_* that) nogil:
    return that.address


cdef addr_t Block_Endex(const Block_* that) nogil:
    return that.address + (that.endex - that.start)


cdef addr_t Block_Endin(const Block_* that) nogil:
    return that.address + (that.endex - that.start) - 1


cdef addr_t Block_BoundAddress(const Block_* that, addr_t address) nogil:
    cdef:
        addr_t block_start = that.address
        addr_t block_endex = block_start + that.endex - that.start

    if address < block_start:
        address = block_start  # bound to start
    elif address > block_endex:
        address = block_endex  # bound to end
    return address


cdef size_t Block_BoundAddressToOffset(const Block_* that, addr_t address) nogil:
    cdef:
        addr_t block_start = that.address
        addr_t block_endex = block_start + that.endex - that.start

    if address < block_start:
        address = block_start  # bound to start
    elif address > block_endex:
        address = block_endex  # bound to end
    return <size_t>(address - block_start)


cdef size_t Block_BoundOffset(const Block_* that, size_t offset) nogil:
    cdef:
        size_t size = that.endex - that.start

    if offset > size:
        offset = size  # bound to end
    return offset


cdef (addr_t, addr_t) Block_BoundAddressSlice(const Block_* that, addr_t start, addr_t endex) nogil:
    cdef:
        addr_t block_start = that.address
        addr_t block_endex = block_start + (that.endex - that.start)

    if start < block_start:
        start = block_start  # bound to start
    elif start > block_endex:
        start = block_endex  # bound to end

    if endex < block_start:
        endex = block_start  # bound to start
    elif endex > block_endex:
        endex = block_endex  # bound to end

    if endex < start:
        endex = start  # clamp negative length

    return start, endex


cdef (size_t, size_t) Block_BoundAddressSliceToOffset(const Block_* that, addr_t start, addr_t endex) nogil:
    cdef:
        addr_t block_start = that.address
        addr_t block_endex = block_start + (that.endex - that.start)

    if start < block_start:
        start = block_start  # bound to start
    elif start > block_endex:
        start = block_endex  # bound to end

    if endex < block_start:
        endex = block_start  # bound to start
    elif endex > block_endex:
        endex = block_endex  # bound to end

    if endex < start:
        endex = start  # clamp negative length

    return <size_t>(start - block_start), <size_t>(endex - block_start)


cdef (size_t, size_t) Block_BoundOffsetSlice(const Block_* that, size_t start, size_t endex) nogil:
    cdef:
        size_t size = that.endex - that.start

    if start > size:
        start = size  # bound to end

    if endex > size:
        endex = size  # bound to end

    if endex < start:
        endex = start  # clamp negative length

    return start, endex


cdef vint Block_CheckMutable(const Block_* that) except -1:
    if that.references > 1:
        raise RuntimeError('Existing exports of data: object cannot be re-sized')


cdef bint Block_Eq_(const Block_* that, size_t size, const byte_t* buffer) nogil:
    if size != that.endex - that.start:
        return False

    if size:
        if memcmp(&that.data[that.start], buffer, size):
            return False

    return True


cdef bint Block_Eq(const Block_* that, const Block_* other) nogil:
    # if that.address != other.address:
    #     return False

    return Block_Eq_(that, other.endex - other.start, &other.data[other.start])


cdef int Block_Cmp_(const Block_* that, size_t size, const byte_t* buffer) nogil:
    cdef:
        size_t size2 = that.endex - that.start
        size_t minsize = size2 if size2 < size else size
        const byte_t* buffer2 = &that.data[that.start]
        int sign = memcmp(buffer2, buffer, minsize)

    if size2 == size:
        return sign
    elif sign:
        return sign
    else:
        return -1 if size2 < size else +1


cdef int Block_Cmp(const Block_* that, const Block_* other) nogil:
    # if that.address != other.address:
    #     return -1 if that.address < other.address else +1

    return Block_Cmp_(that, other.endex - other.start, &other.data[other.start])


cdef ssize_t Block_Find__(const Block_* that, size_t start, size_t endex, byte_t value) nogil:
    cdef:
        size_t size = that.endex - that.start
        const byte_t* ptr
        const byte_t* end

    if start > size:
        start = size  # bound to end
    if endex > size:
        endex = size  # bound to end
    if endex < start:
        endex = start  # clamp negative length

    ptr = &that.data[that.start + start]
    end = &that.data[that.start + endex]

    while ptr != end:
        if ptr[0] == value:
            return <ssize_t>(<ptrdiff_t>ptr - <ptrdiff_t>&that.data[that.start])
        ptr += 1
    return -1


cdef ssize_t Block_Find_(const Block_* that, size_t start, size_t endex,
                         size_t size, const byte_t* buffer) nogil:
    cdef:
        size_t size2
        const byte_t* ptr
        const byte_t* end

    if size == 1:  # faster code for single byte
        return Block_Find__(that, start, endex, buffer[0])

    elif size:
        size2 = that.endex - that.start

        if start > size2:
            start = size2  # bound to end
        if endex > size2:
            endex = size2  # bound to end
        if endex < start:
            endex = start  # clamp negative length

        if size <= size2 and size <= endex - start:
            size2 = endex - size + 1

            if start > size2:
                start = size2  # bound to end
            if endex > size2:
                endex = size2  # bound to end

            ptr = &that.data[that.start + start]
            end = &that.data[that.start + endex]

            while ptr != end:
                if ptr[0] == buffer[0]:  # faster pruning
                    if not memcmp(ptr, buffer, size):
                        return <ssize_t>(<ptrdiff_t>ptr - <ptrdiff_t>&that.data[that.start])
                ptr += 1
    return -1


cdef ssize_t Block_Find(const Block_* that, ssize_t start, ssize_t endex,
                        size_t size, const byte_t* buffer) nogil:
    cdef:
        ssize_t ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
        if start < 0:
            start = 0  # bound to start

    if endex < 0:
        endex += ssize  # anchor to end
        if endex < 0:
            endex = 0  # bound to start

    return Block_Find_(that, <size_t>start, <size_t>endex, size, buffer)


cdef ssize_t Block_ReverseFind__(const Block_* that, size_t start, size_t endex, byte_t value) nogil:
    cdef:
        size_t size = that.endex - that.start
        const byte_t* ptr
        const byte_t* end

    if size:
        if start > size:
            start = size  # bound to end
        if endex > size:
            endex = size  # bound to end
        if endex < start:
            endex = start  # clamp negative length

        end = &that.data[that.start + start]
        ptr = &that.data[that.start + endex]

        while ptr != end:
            ptr -= 1
            if ptr[0] == value:
                return <ssize_t>(<ptrdiff_t>ptr - <ptrdiff_t>&that.data[that.start])
    return -1


cdef ssize_t Block_ReverseFind_(const Block_* that, size_t start, size_t endex,
                                size_t size, const byte_t* buffer) nogil:
    cdef:
        size_t size2
        const byte_t* ptr
        const byte_t* end

    if size == 1:  # faster code for single byte
        return Block_ReverseFind__(that, start, endex, buffer[0])

    elif size:
        size2 = that.endex - that.start

        if start > size2:
            start = size2  # bound to end
        if endex > size2:
            endex = size2  # bound to end
        if endex < start:
            endex = start  # clamp negative length

        if size <= size2 and size <= endex - start:
            size2 = endex - size + 1

            if start > size2:
                start = size2  # bound to end
            if endex > size2:
                endex = size2  # bound to end

            end = &that.data[that.start + start]
            ptr = &that.data[that.start + endex]

            while ptr != end:
                ptr -= 1
                if ptr[0] == buffer[0]:  # faster pruning
                    if not memcmp(ptr, buffer, size):
                        return <ssize_t>(<ptrdiff_t>ptr - <ptrdiff_t>&that.data[that.start])
    return -1


cdef ssize_t Block_ReverseFind(const Block_* that, ssize_t start, ssize_t endex,
                               size_t size, const byte_t* buffer) nogil:
    cdef:
        ssize_t ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
        if start < 0:
            start = 0  # bound to start

    if endex < 0:
        endex += ssize  # anchor to end
        if endex < 0:
            endex = 0  # bound to start

    return Block_ReverseFind_(that, <size_t>start, <size_t>endex, size, buffer)


cdef size_t Block_Count__(const Block_* that, size_t start, size_t endex, byte_t value) nogil:
    cdef:
        size_t count = 0
        size_t size = that.endex - that.start
        const byte_t* ptr
        const byte_t* end

    if start > size:
        start = size  # bound to end
    if endex > size:
        endex = size  # bound to end
    if endex < start:
        endex = start  # clamp negative length

    ptr = &that.data[that.start + start]
    end = &that.data[that.start + endex]

    while ptr != end:
        if ptr[0] == value:
            count += 1
        ptr += 1
    return count


cdef size_t Block_Count_(const Block_* that, size_t start, size_t endex,
                         size_t size, const byte_t* buffer) nogil:
    cdef:
        size_t count = 0
        size_t size2
        const byte_t* ptr
        const byte_t* end

    if size == 1:  # faster code for single byte
        return Block_Count__(that, start, endex, buffer[0])

    elif size:
        size2 = that.endex - that.start

        if start > size2:
            start = size2  # bound to end
        if endex > size2:
            endex = size2  # bound to end
        if endex < start:
            endex = start  # clamp negative length

        if size <= size2 and size <= endex - start:
            size2 = endex - size + 1

            if start > size2:
                start = size2  # bound to end
            if endex > size2:
                endex = size2  # bound to end

            ptr = &that.data[that.start + start]
            end = &that.data[that.start + endex]

            while ptr < end:
                if ptr[0] == buffer[0]:  # faster pruning
                    if not memcmp(ptr, buffer, size):
                        ptr += size - 1
                        count += 1
                ptr += 1
    return count


cdef size_t Block_Count(const Block_* that, ssize_t start, ssize_t endex,
                        size_t size, const byte_t* buffer) nogil:
    cdef:
        ssize_t ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
        if start < 0:
            start = 0  # bound to start

    if endex < 0:
        endex += ssize  # anchor to end
        if endex < 0:
            endex = 0  # bound to start

    return Block_Count_(that, <size_t>start, <size_t>endex, size, buffer)


cdef Block_* Block_Reserve_(Block_* that, size_t offset, size_t size, bint zero) except NULL:
    cdef:
        size_t actual
        size_t used
        size_t margin
        size_t allocated
        Block_* ptr

    Block_CheckMutable(that)

    if size:
        if ((size > SIZE_HMAX or
             CannotAddSizeU(that.endex, size) or
             that.endex + size > SIZE_HMAX)):
            raise OverflowError('size overflow')

        used = that.endex - that.start
        if offset > used:
            raise IndexError('index out of range')

        # Prefer the side where there is less data to shift, which also favors the extremes
        if offset >= (used >> 1):
            if size > that.allocated - that.endex:
                # Calculate the upsized allocation
                allocated = Upsize(that.allocated, that.allocated + size)
                if allocated > SIZE_HMAX:
                    raise MemoryError()

                # Reallocate, including the header
                ptr = <Block_*>PyMem_Realloc(that, Block_HEADING + (allocated * sizeof(byte_t)))
                if ptr == NULL:
                    raise MemoryError()

                # Reassign to that
                that = ptr
                that.allocated = allocated  # update

            # Shift elements to make room for reservation at the requested offset
            CheckAddSizeU(offset, that.start)
            offset += that.start
            used = that.endex - offset
            if used:
                memmove(&that.data[offset + size],
                        &that.data[offset],
                        used * sizeof(byte_t))
            if zero:
                memset(&that.data[offset], 0, size * sizeof(byte_t))  # pad with zeros
            that.endex += size

        else:
            if size <= that.start:
                # Shift elements to make room for reservation at the requested offset
                that.start -= size
                if offset:
                    memmove(&that.data[that.start],
                            &that.data[that.start + size],
                            offset * sizeof(byte_t))
                if zero:
                    memset(&that.data[that.start + offset], 0, size * sizeof(byte_t))  # pad with zeros

            else:
                # Calculate the upsized allocation
                CheckAddSizeU(that.allocated, size)
                allocated = Upsize(that.allocated, that.allocated + size)
                if allocated > SIZE_HMAX:
                    raise MemoryError()

                # Allocate a new chunk, including the header
                actual = Block_HEADING + (allocated * sizeof(byte_t))
                if zero:
                    ptr = <Block_*>PyMem_Calloc(actual, 1)
                else:
                    ptr = <Block_*>PyMem_Malloc(actual)
                if ptr == NULL:
                    raise MemoryError()

                # Prepare the new chunk aligning towards the end
                ptr.address = that.address
                ptr.references = that.references  # transfer ownership
                ptr.allocated = allocated
                ptr.endex = ptr.allocated - MARGIN  # leave some room
                ptr.start = ptr.endex - used - size

                # Shift/copy elements to make room for reservation at the requested offset
                if offset:
                    used -= offset  # prepare for later
                    memcpy(&ptr.data[ptr.start],
                           &that.data[that.start],
                           offset * sizeof(byte_t))
                if used:
                    memcpy(&ptr.data[ptr.start + offset + size],
                           &that.data[that.start + offset],
                           used * sizeof(byte_t))

                # Reassign to that
                PyMem_Free(that)
                that = ptr

    return that


cdef Block_* Block_Delete_(Block_* that, size_t offset, size_t size) except NULL:
    cdef:
        size_t allocated
        Block_* ptr

    Block_CheckMutable(that)

    if size:
        if ((size > SIZE_HMAX or
             CannotAddSizeU(offset, size) or
             offset + size > SIZE_HMAX or
             CannotAddSizeU(offset, that.start) or
             that.start > SIZE_HMAX)):
            raise OverflowError('size overflow')

        if that.endex < that.start + offset + size:
            raise IndexError('index out of range')

        # Calculate the downsized allocation
        allocated = Downsize(that.allocated, that.allocated - size)
        if allocated > SIZE_HMAX:
            raise MemoryError()

        if offset == 0:
            if allocated == that.allocated:
                # Just skip initial if not reallocated and no offset
                that.start += size
            else:
                # Shift elements to make for the deleted gap at the beginning
                offset += that.start
                memmove(&that.data[MARGIN],  # realign to initial MARGIN
                        &that.data[offset + size],
                        (that.endex - (offset + size)) * sizeof(byte_t))
                size = that.endex - that.start - size
                that.start = MARGIN
                that.endex = MARGIN + size
        else:
            # Shift elements to make for the deleted gap at the requested offset
            offset += that.start
            memmove(&that.data[offset],
                    &that.data[offset + size],
                    (that.endex - (offset + size)) * sizeof(byte_t))
            that.endex -= size

        if allocated != that.allocated:
            # Reallocate, including the header
            ptr = <Block_*>PyMem_Realloc(that, Block_HEADING + (allocated * sizeof(byte_t)))
            if ptr == NULL:
                raise MemoryError()

            # Reassign to that
            that = ptr
            that.allocated = allocated

    return that


cdef Block_* Block_Clear(Block_* that) except NULL:
    return Block_Delete_(that, 0, that.endex - that.start)


cdef byte_t* Block_At_(Block_* that, size_t offset) nogil:
    return &that.data[that.start + offset]


cdef const byte_t* Block_At__(const Block_* that, size_t offset) nogil:
    return &that.data[that.start + offset]


cdef byte_t Block_Get__(const Block_* that, size_t offset) nogil:
    return that.data[that.start + offset]


cdef int Block_Get_(const Block_* that, size_t offset) except -1:
    CheckAddSizeU(that.start, offset)
    offset += that.start

    if offset < that.endex:
        return <int><unsigned>that.data[offset]
    else:
        raise IndexError('index out of range')


cdef int Block_Get(const Block_* that, ssize_t offset) except -1:
    if offset < 0:
        offset += <ssize_t>(that.endex - that.start)  # anchor to end
        if offset < 0:
            raise IndexError('index out of range')

    return Block_Get_(that, <size_t>offset)


cdef byte_t Block_Set__(Block_* that, size_t offset, byte_t value) nogil:
    cdef:
        byte_t backup

    offset += that.start
    backup = that.data[offset]
    that.data[offset] = value
    return backup


cdef int Block_Set_(Block_* that, size_t offset, byte_t value) except -1:
    cdef:
        int backup

    # Block_CheckMutable(that)
    CheckAddSizeU(that.start, offset)
    offset += that.start

    if offset < that.endex:
        backup = <int><unsigned>that.data[offset]
        that.data[offset] = value
        return backup
    else:
        raise IndexError('index out of range')


cdef int Block_Set(Block_* that, ssize_t offset, byte_t value) except -1:
    if offset < 0:
        offset += <ssize_t>(that.endex - that.start)  # anchor to end
        if offset < 0:
            raise IndexError('index out of range')

    return Block_Set_(that, <size_t>offset, value)


cdef Block_* Block_Pop__(Block_* that, byte_t* value) except NULL:
    # Block_CheckMutable(that)

    if that.start < that.endex:
        if value:
            value[0] = that.data[that.endex - 1]  # backup

        return Block_Delete_(that, that.endex - that.start - 1, 1)
    else:
        raise IndexError('pop index out of range')


cdef Block_* Block_Pop_(Block_* that, size_t offset, byte_t* value) except NULL:
    # Block_CheckMutable(that)
    CheckAddSizeU(that.start, offset)

    if that.start + offset < that.endex:
        if value:
            value[0] = that.data[that.start + offset]  # backup

        return Block_Delete_(that, offset, 1)
    else:
        raise IndexError('pop index out of range')


cdef Block_* Block_Pop(Block_* that, ssize_t offset, byte_t* value) except NULL:
    if offset < 0:
        offset += <ssize_t>(that.endex - that.start)  # anchor to end
        if offset < 0:
            raise IndexError('pop index out of range')

    return Block_Pop_(that, <size_t>offset, value)


cdef Block_* Block_PopLeft(Block_* that, byte_t* value) except NULL:
    return Block_Pop_(that, 0, value)


cdef Block_* Block_Insert_(Block_* that, size_t offset, byte_t value) except NULL:
    # Insert the value at the requested offset
    that = Block_Reserve_(that, offset, 1, False)
    that.data[that.start + offset] = value
    return that


cdef Block_* Block_Insert(Block_* that, ssize_t offset, byte_t value) except NULL:
    cdef:
        ssize_t size = <ssize_t>(that.endex - that.start)

    if offset < 0:
        offset += size  # anchor to end
        if offset < 0:
            # raise IndexError('index out of range')
            offset = 0  # as per bytearray.insert

    elif offset > size:
        # raise IndexError('index out of range')
        offset = size  # as per bytearray.insert

    return Block_Insert_(that, <size_t>offset, value)


cdef Block_* Block_Append(Block_* that, byte_t value) except NULL:
    # Insert the value after the end
    that = Block_Reserve_(that, that.endex - that.start, 1, False)
    that.data[that.endex - 1] = value
    return that


cdef Block_* Block_AppendLeft(Block_* that, byte_t value) except NULL:
    # Insert the value after the end
    that = Block_Reserve_(that, 0, 1, False)
    that.data[that.start] = value
    return that


cdef Block_* Block_Extend_(Block_* that, size_t size, const byte_t* buffer) except NULL:
    if size:
        that = Block_Reserve_(that, that.endex - that.start, size, False)
        memmove(&that.data[that.endex - size], buffer, size * sizeof(byte_t))
    return that


cdef Block_* Block_Extend(Block_* that, const Block_* more) except NULL:
    that = Block_Extend_(that, Block_Length(more), Block_At__(more, 0))
    return that


cdef Block_* Block_ExtendLeft_(Block_* that, size_t size, const byte_t* buffer) except NULL:
    if size:
        that = Block_Reserve_(that, 0, size, False)
        memmove(&that.data[that.start], buffer, size * sizeof(byte_t))
    return that


cdef Block_* Block_ExtendLeft(Block_* that, const Block_* more) except NULL:
    that = Block_ExtendLeft_(that, Block_Length(more), Block_At__(more, 0))
    return that


cdef void Block_RotateLeft__(Block_* that, size_t offset) nogil:
    cdef:
        size_t size = that.endex - that.start
        byte_t* data = &that.data[that.start]
        byte_t first

    if size:
        if offset == 1:
            first = data[0]
            size -= 1
            while size:
                data[0] = data[1]
                data += 1
                size -= 1
            data[0] = first

        elif offset:
            Reverse(data, 0, offset - 1)
            Reverse(data, offset, size - 1)
            Reverse(data, 0, size - 1)


cdef void Block_RotateLeft_(Block_* that, size_t offset) nogil:
    cdef:
        size_t size = that.endex - that.start

    if size:
        if offset >= size:
            with cython.cdivision(True):
                offset = offset % size  # no "%=" to avoid zero check

        Block_RotateLeft__(that, offset)


cdef void Block_RotateRight__(Block_* that, size_t offset) nogil:
    cdef:
        size_t size = that.endex - that.start
        byte_t* data = &that.data[that.start]
        byte_t last

    if size:
        if offset == 1:
            size -= 1
            if size:
                data += size
                last = data[0]
                while size:
                    size -= 1
                    data -= 1
                    data[1] = data[0]
                data[0] = last

        elif offset:
            offset = size - offset
            Reverse(data, 0, offset - 1)
            Reverse(data, offset, size - 1)
            Reverse(data, 0, size - 1)


cdef void Block_RotateRight_(Block_* that, size_t offset) nogil:
    cdef:
        size_t size = that.endex - that.start

    if size:
        if offset >= size:
            with cython.cdivision(True):
                offset = offset % size  # no "%=" to avoid zero check

        Block_RotateRight__(that, offset)


cdef void Block_Rotate(Block_* that, ssize_t offset) nogil:
    if offset < 0:
        Block_RotateLeft_(that, <size_t>-offset)
    else:
        Block_RotateRight_(that, <size_t>offset)


cdef Block_* Block_Repeat(Block_* that, size_t times) except NULL:
    cdef:
        size_t size
        byte_t* src
        byte_t* dst

    if times == 1:
        return that

    elif times < 1:
        return Block_Clear(that)

    else:
        size = that.endex - that.start
        with cython.cdivision(True):
            if size > SIZE_HMAX // times:
                raise OverflowError()

        times -= 1
        that = Block_Reserve_(that, size, size * times, False)
        src = &that.data[that.start]
        dst = src

        while times:
            times -= 1
            dst += size
            memcpy(dst, src, size)  # whole repetition

        return that


cdef Block_* Block_RepeatToSize(Block_* that, size_t size) except NULL:
    cdef:
        size_t size2
        size_t times
        byte_t* src
        byte_t* dst

    size2 = that.endex - that.start

    if size2 == 0:
        raise RuntimeError('empty')

    if size == size2:
        return that

    elif size < size2:
        return Block_DelSlice_(that, size, size2)

    else:  # size > size2
        that = Block_Reserve_(that, size2, size - size2, False)

        if that.start + 1 == that.endex:  # single byte
            dst = &that.data[that.start]
            memset(dst, dst[0], size)

        else:  # multiple bytes
            with cython.cdivision(True):
                times = size // size2

            # Copy the final partial chunk
            src = &that.data[that.start]
            dst = &that.data[that.start + (size2 * times)]
            memcpy(dst, src, size - (size2 * times))

            # Copy the multiple times, skipping the first one
            dst = src + size2
            times -= 1
            while times:
                memcpy(dst, src, size2)
                dst += size2
                times -= 1

        return that


cdef vint Block_Read_(const Block_* that, size_t offset, size_t size, byte_t* buffer) except -1:
    if size:
        if size > SIZE_HMAX:
            raise OverflowError('size overflow')

        CheckAddSizeU(offset, that.start)
        offset += that.start

        CheckAddSizeU(offset, size)
        if that.endex < offset + size:
            raise IndexError('index out of range')

        memmove(buffer, &that.data[offset], size * sizeof(byte_t))


cdef Block_* Block_Write_(Block_* that, size_t offset, size_t size, const byte_t* buffer) except NULL:
    # Block_CheckMutable(that)

    if size:
        CheckAddSizeU(that.start, offset)
        offset += that.start

        CheckAddSizeU(offset, size)
        if that.endex < offset + size:
            that = Block_Reserve_(that, that.endex - that.start, (offset + size) - that.endex, False)

        memmove(&that.data[offset], buffer, size * sizeof(byte_t))
    return that


cdef vint Block_ReadSlice_(const Block_* that, size_t start, size_t endex,
                           size_t* size_, byte_t* buffer) except -1:
    cdef:
        size_t size = that.endex - that.start

    size_[0] = 0

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound source start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex < start:
        endex = start  # clamp negative source length
    elif endex > size:
        endex = size  # bound source end

    size = endex - start
    Block_Read_(that, start, size, buffer)
    size_[0] = size


cdef vint Block_ReadSlice(const Block_* that, ssize_t start, ssize_t endex,
                          size_t* size_, byte_t* buffer) except -1:
    cdef:
        ssize_t ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
    if start < 0:
        start = 0  # bound source start

    if endex < 0:
        endex += ssize  # anchor to end
    if endex < start:
        endex = start  # clamp negative source length

    Block_ReadSlice_(that, <size_t>start, <size_t>endex, size_, buffer)


cdef Block_* Block_GetSlice_(const Block_* that, size_t start, size_t endex) except NULL:
    cdef:
        size_t size = that.endex - that.start

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound source start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex < start:
        endex = start  # clamp negative source length
    elif endex > size:
        endex = size  # bound source end

    return Block_Create(that.address + start, endex - start, &that.data[that.start + start])


cdef Block_* Block_GetSlice(const Block_* that, ssize_t start, ssize_t endex) except NULL:
    cdef:
        ssize_t ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
    if start < 0:
        start = 0  # bound source start

    if endex < 0:
        endex += ssize  # anchor to end
    if endex < start:
        endex = start  # clamp negative source length

    return Block_GetSlice_(that, <size_t>start, <size_t>endex)


cdef Block_* Block_WriteSlice_(Block_* that, size_t start, size_t endex,
                               size_t size, const byte_t* buffer) except NULL:
    cdef:
        size_t size2   # source size

    size2 = size
    size = that.endex - that.start

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound target start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex > size:
        endex = size  # bound target end

    if endex < start:
        endex = start  # clamp negative target length
    size = endex - start

    if size2 > size:  # enlarge target at range end
        that = Block_Reserve_(that, endex, size2 - size, False)

    elif size > size2:  # shrink target at range end
        endex -= size - size2
        that = Block_Delete_(that, endex, size - size2)

    that = Block_Write_(that, start, size2, buffer)
    return that


cdef Block_* Block_WriteSlice(Block_* that, ssize_t start, ssize_t endex,
                              size_t size, const byte_t* buffer) except NULL:
    cdef:
        ssize_t ssize   # target size
        ssize_t ssize2  # source size
        ssize_t start2  # source start
        ssize_t endex2  # source end

    start2 = 0
    endex2 = <ssize_t>size

    ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
    if start < 0:
        # start2 -= start  # skip initial source data  # as per bytearray
        start = 0  # bound target start
    if start2 > endex2:
        start2 = endex2  # clamp source start

    if endex < 0:
        endex += ssize  # anchor to end
    if endex < start:
        endex = start  # clamp negative target length

    if endex2 < start2:
        endex2 = start2  # clamp negative source length
    ssize2 = endex2 - start2

    that = Block_WriteSlice_(that, <size_t>start, <size_t>endex, <size_t>ssize2, &buffer[start2])
    return that


cdef Block_* Block_SetSlice_(Block_* that, size_t start, size_t endex,
                             const Block_* src, size_t start2, size_t endex2) except NULL:
    cdef:
        size_t size    # target size
        size_t size2   # source size

    size2 = src.endex - src.start

    if start2 > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start2 > size2:
        start2 = size2  # bound source start

    if endex2 > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex2 > size2:
        endex2 = size2  # bound source end

    if endex2 < start2:
        endex2 = start2  # clamp negative source length
    size2 = endex2 - start2

    size = that.endex - that.start

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound target start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex > size:
        endex = size  # bound target end

    if endex < start:
        endex = start  # clamp negative target length
    size = endex - start

    if size2 > size:  # enlarge target at range end
        that = Block_Reserve_(that, endex, size2 - size, False)

    elif size > size2:  # shrink target at range end
        endex -= size - size2
        that = Block_Delete_(that, endex, size - size2)

    that = Block_Write_(that, start, size2, &src.data[src.start + start2])
    return that


cdef Block_* Block_SetSlice(Block_* that, ssize_t start, ssize_t endex,
                            const Block_* src, ssize_t start2, ssize_t endex2) except NULL:
    cdef:
        ssize_t ssize   # target size
        ssize_t ssize2  # source size

    ssize = <ssize_t>(that.endex - that.start)
    ssize2 = <ssize_t>(src.endex - src.start)

    if start < 0:
        start += ssize  # anchor to target end
    if start < 0:
        # start2 -= start  # skip initial source data  # as per bytearray
        start = 0  # bound target start

    if endex < 0:
        endex += ssize  # anchor to target end
    if endex < start:
        endex = start  # clamp negative target length

    if start2 < 0:
        start2 += ssize2  # anchor to source end
    if start2 < 0:
        start2 = 0  # bound source start

    if endex2 < 0:
        endex2 += ssize2  # anchor to source end
    if endex2 < start2:
        endex2 = start2  # clamp negative source length

    that = Block_SetSlice_(that, <size_t>start, <size_t>endex, src, <size_t>start2, <size_t>endex2)
    return that


cdef Block_* Block_DelSlice_(Block_* that, size_t start, size_t endex) except NULL:
    cdef:
        size_t size

    size = that.endex - that.start

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex < start:
        endex = start  # clamp negative length
    elif endex > size:
        endex = size  # bound end

    that = Block_Delete_(that, start, (endex - start))
    return that


cdef Block_* Block_DelSlice(Block_* that, ssize_t start, ssize_t endex) except NULL:
    cdef:
        ssize_t ssize

    ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
    if start < 0:
        start = 0  # bound start

    if endex < 0:
        endex += ssize  # anchor to end
    if endex < start:
        endex = start  # clamp negative length

    that = Block_DelSlice_(that, <size_t>start, <size_t>endex)
    return that


cdef bytes Block_Bytes(const Block_* that):
    cdef:
        char* ptr = <char*><void*>&that.data[that.start]
        ssize_t size = <ssize_t>(that.endex - that.start)

    return PyBytes_FromStringAndSize(ptr, size)


cdef bytearray Block_Bytearray(const Block_* that):
    cdef:
        char* ptr = <char*><void*>&that.data[that.start]
        ssize_t size = <ssize_t>(that.endex - that.start)

    return PyByteArray_FromStringAndSize(ptr, size)


cdef BlockView Block_View(Block_* that):
    return BlockView.from_block(that, that.start, that.endex)


cdef BlockView Block_ViewSlice_(Block_* that, size_t start, size_t endex):
    cdef:
        size_t size = that.endex - that.start

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound source start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex < start:
        endex = start  # clamp negative source length
    elif endex > size:
        endex = size  # bound source end

    return BlockView.from_block(that, that.start + start, that.start + endex)


cdef BlockView Block_ViewSlice(Block_* that, ssize_t start, ssize_t endex):
    cdef:
        ssize_t ssize

    ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
    if start < 0:
        start = 0  # bound source start

    if endex < 0:
        endex += ssize  # anchor to end
    if endex < start:
        endex = start  # clamp negative source length

    return Block_ViewSlice_(that, <size_t>start, <size_t>endex)


# ---------------------------------------------------------------------------------------------------------------------

cdef class BlockView(InplaceView):
    r"""Block viewer.

    Memory view around an underlying block slice, implementing Python's `buffer`
    protocol API.
    """

    @staticmethod
    cdef BlockView from_block(Block_* block, size_t start, size_t endex):
        cdef:
            BlockView view

        if block == NULL:
            raise ValueError('no block')
        if not block.start <= start <= block.endex:
            raise ValueError('start outside range')
        if not block.start <= endex <= block.endex:
            raise ValueError('endex outside range')
        if endex < start:
            endex = start

        view = BlockView()
        view._block = Block_Acquire(block)
        view._start = start
        view._endex = endex
        view._obj = view._memoryview
        view.update_readonly_()
        return view

    cdef vint check_block_(BlockView self) except -1:
        cdef:
            Block_* block = self._block

        if block:
            if self._endex > block.allocated:
                 raise RuntimeError('exceeding allocated size')
        else:
            raise RuntimeError('null internal data pointer')

    cdef vint release_(BlockView self) except -1:
        # InplaceView.release()

        if self._memoryview_object is not None:
            # self._memoryview_object.release()
            # self._memoryview_object = None
            self._block = Block_Release_(self._block)

        self._block = Block_Release(self._block)

    def __bool__(
        self: BlockView,
    ) -> bool:
        r"""Has any data.

        Returns:
            bool: Non-null slice length.
        """

        self.check_block_()
        return self._start < self._endex

    def __bytes__(
        self: BlockView,
    ) -> bytes:
        r"""Converts into bytes.

        Returns:
            bytes: :class:`bytes` clone of the viewed slice.
        """
        cdef:
            char* ptr
            ssize_t size
            Block_* block = self._block

        self.check_block_()
        ptr = <char*><void*>&block.data[self._start]
        size = <ssize_t>(self._endex - self._start)
        return PyBytes_FromStringAndSize(ptr, size)

    def __cinit__(
        self: BlockView,
    ):

        self._block = NULL

    def __dealloc__(
        self: BlockView,
    ):

        self.release_()

    def __eq__(
        self: BlockView,
        other: Any,
    ) -> bool:

        self.check_block_()
        if other is None:
            return False

        if isinstance(other, BlockView):
            return Block_Eq(self._block, (<BlockView>other)._block)
        else:
            return self._memoryview == other

    def __getattr__(
        self: BlockView,
        attr: str,
    ) -> Any:

        self.check_block_()
        return getattr(self._memoryview, attr)

    def __getbuffer__(
        self: BlockView,
        Py_buffer* buffer,
        int flags,
    ):
        cdef:
            int CONTIGUOUS = PyBUF_C_CONTIGUOUS | PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS

        # if flags & PyBUF_WRITABLE:
        #     raise ValueError('read only access')

        self.check_block_()
        self._block = Block_Acquire(self._block)

        buffer.buf = &self._block.data[self._start]
        buffer.obj = self
        buffer.len = self._endex - self._start
        buffer.itemsize = 1
        buffer.readonly = False  # not (flags & PyBUF_WRITABLE)
        buffer.ndim = 1
        buffer.format = <char*>'B' if flags & (PyBUF_FORMAT | CONTIGUOUS) else NULL
        buffer.shape = &buffer.len if flags & (PyBUF_ND | CONTIGUOUS) else NULL
        buffer.strides = &buffer.itemsize if flags & (PyBUF_STRIDES | CONTIGUOUS) else NULL
        buffer.suboffsets = NULL
        buffer.internal = NULL

    def __getitem__(
        self: BlockView,
        key: Union[Address, slice],
    ) -> Any:

        self.check_block_()
        return self._memoryview[key]

    def __init__(
        self: BlockView,
    ):

        InplaceView.__init__(self, None)

    def __len__(
        self: BlockView,
    ) -> Address:
        r"""int: Slice length."""

        self.check_block_()
        return self._endex - self._start

    def __releasebuffer__(
        self: BlockView,
         Py_buffer* buffer,
    ):

        if self._block:
            self._block = Block_Release_(self._block)

    def __repr__(
        self: BlockView,
    ) -> str:

        return repr(self.__str__())

    def __setitem__(
        self: BlockView,
        key: Union[Address, slice],
        value: Optional[Union[AnyBytes, Value, ImmutableMemory]],
    ) -> None:

        self.check_block_()
        self._memoryview[key] = value

    def __sizeof__(
        self: BlockView,
    ) -> int:
        r"""int: Allocated byte size."""

        return sizeof(BlockView)

    def __str__(
        self: BlockView,
    ) -> str:
        cdef:
            const Block_* block = self._block
            size_t size = self._endex - self._start
            addr_t start
            addr_t endex

        self.check_block_()

        if size > STR_MAX_CONTENT_SIZE:
            start = block.address
            CheckAddAddrU(start, size)
            endex = start + size
            r = '' if block else 'released '
            return f'<{r}{type(self).__name__}[0x{start:X}:0x{endex:X}]@0x{<uintptr_t><void*>self:X}>'
        else:
            return self.__bytes__().decode('ascii')

    @property
    def acquired(
        self: BlockView,
    ) -> bool:
        r"""bool: Underlying block currently acquired."""

        return self._block != NULL

    def check(
        self: BlockView,
    ) -> None:
        r"""Checks for data consistency."""

        self.check_block_()
        self.check_obj_()

    def release(
        self: BlockView,
    ) -> None:
        r"""Forces object disposal.

        Useful to make sure that any memory blocks are unreferenced before automatic
        garbage collection.

        Any access to the object after calling this function could raise exceptions.
        """

        InplaceView.release(self)
        self.release_()

    @property
    def endex(
        self: BlockView,
    ) -> Address:
        r"""int: Slice exclusive end address."""

        self.check_block_()
        return self._block.address + self._endex - self._start

    @property
    def endin(
        self: BlockView,
    ) -> Address:
        r"""int: Slice inclusive end address."""

        return self.endex - 1

    @property
    def _memoryview(
        self: BlockView,
    ) -> memoryview:
        r"""memoryview: Python :class:`memoryview` wrapper."""
        cdef:
            byte_t* data
            size_t size
            byte_t[:] view

        self.check_block_()

        if self._memoryview_object is None:
            self._block = Block_Acquire(self._block)
            data = &self._block.data[self._start]
            size = self._endex - self._start

            if size:
                view = <byte_t[:size]>data
            else:
                view = _empty_bytearray

            self._memoryview_object = memoryview(view)

        return self._memoryview_object

    @property
    def start(
        self: BlockView,
    ) -> Address:
        r"""int: Slice inclusive start address."""

        self.check_block_()
        return self._block.address

    def toreadonly(
        self: BlockView,
    ) -> memoryview:

        return self._memoryview  # still writable though...


# =====================================================================================================================

cdef Rack_* Rack_Alloc(size_t size) except NULL:
    cdef:
        Rack_* that = NULL
        size_t allocated
        size_t actual

    if size > SIZE_HMAX:
        raise OverflowError('size overflow')

    # Allocate as per request
    allocated = Upsize(0, size)
    if allocated > SIZE_HMAX:
        raise MemoryError()

    actual = Rack_HEADING + (allocated * sizeof(Block_*))
    that = <Rack_*>PyMem_Calloc(actual, 1)
    if that == NULL:
        raise MemoryError()

    that.allocated = allocated
    that.start = MARGIN  # leave some initial room
    that.endex = that.start + size
    return that


cdef Rack_* Rack_Free(Rack_* that):
    cdef:
        size_t index

    if that:
        # Decrement data referencing
        for index in range(that.start, that.endex):
            that.blocks[index] = Block_Release(that.blocks[index])
        PyMem_Free(that)
    return NULL


cdef size_t Rack_Sizeof(const Rack_* that):
    cdef:
        size_t index
        size_t size

    if that:
        size = Rack_HEADING
        for index in range(that.start, that.endex):
            size += Block_Sizeof(that.blocks[index])
        return size
    return 0


cdef Rack_* Rack_ShallowCopy(const Rack_* other) except NULL:
    cdef:
        Rack_* that = Rack_Alloc(other.endex - other.start)
        size_t start1 = that.start
        size_t start2 = other.start
        size_t offset

    try:
        for offset in range(that.endex - that.start):
            that.blocks[start1 + offset] = Block_Acquire(other.blocks[start2 + offset])
    except:
        that = Rack_Free(that)
        raise
    return that


cdef Rack_* Rack_Copy(const Rack_* other) except NULL:
    cdef:
        Rack_* that = Rack_Alloc(other.endex - other.start)
        size_t start1 = that.start
        size_t start2 = other.start
        size_t offset

    try:
        for offset in range(that.endex - that.start):
            that.blocks[start1 + offset] = Block_Copy(other.blocks[start2 + offset])
    except:
        that = Rack_Free(that)
        raise
    return that


cdef Rack_* Rack_FromObject(object obj, saddr_t offset) except NULL:
    cdef:
        Rack_* that = NULL
        size_t size
        size_t index
        addr_t address

    try:
        try:
            size = len(obj)
        except TypeError:
            that = Rack_Alloc(0)
            for address, data in obj:
                if offset < 0:
                    CheckSubAddrU(address, <addr_t>-offset)
                    address -= <addr_t>-offset
                elif offset > 0:
                    CheckAddAddrU(address, <addr_t>offset)
                    address += <addr_t>offset
                that = Rack_Append(that, Block_FromObject(address, data, True))
        else:
            that = Rack_Alloc(size)
            index = that.start
            for address, data in obj:
                if offset < 0:
                    CheckSubAddrU(address, <addr_t>-offset)
                    address -= <addr_t>-offset
                elif offset > 0:
                    CheckAddAddrU(address, <addr_t>offset)
                    address += <addr_t>offset
                that.blocks[index] = Block_FromObject(address, data, True)
                index += 1
        return that

    except:
        that = Rack_Free(that)
        raise


cdef void Rack_Reverse(Rack_* that) nogil:
    cdef:
        size_t index_start = that.start
        size_t index_endex = that.endex
        size_t index_endin
        Block_* block

    while index_start < index_endex:
        index_endin = index_endex - 1
        block = that.blocks[index_start]
        that.blocks[index_start] = that.blocks[index_endin]
        that.blocks[index_endin] = block
        index_endex = index_endin
        index_start += 1


cdef bint Rack_Bool(const Rack_* that) nogil:
    return that.start < that.endex


cdef size_t Rack_Length(const Rack_* that) nogil:
    return that.endex - that.start


cdef (addr_t, addr_t) Rack_BoundSlice(const Rack_* that, addr_t start, addr_t endex) nogil:
    cdef:
        const Block_* block
        addr_t block_start
        addr_t block_endex

    if that.start < that.endex:
        block = that.blocks[that.start]
        block_start = Block_Start(block)
        if start < block_start:
            start = block_start
        if endex < start:
            endex = start

        block = that.blocks[that.endex - 1]
        block_endex = Block_Endex(block)
        if endex > block_endex:
            endex = block_endex
        if start > endex:
            start = endex
    else:
        start = 0
        endex = 0

    return start, endex


cdef Rack_* Rack_Shift_(Rack_* that, addr_t offset) except NULL:
    cdef:
        size_t index
        Block_* block

    if offset:
        if that.start < that.endex:
            block = that.blocks[that.endex - 1]
            CheckAddAddrU(block.address, offset)

            for index in range(that.start, that.endex):
                block = that.blocks[index]
                block.address += offset
    return that


cdef Rack_* Rack_Shift(Rack_* that, saddr_t offset) except NULL:
    cdef:
        size_t index
        Block_* block
        addr_t offset_

    if offset:
        if that.start < that.endex:
            if offset < 0:
                block = that.blocks[that.start]
                offset_ = <addr_t>-offset
                CheckSubAddrU(block.address, offset_)

                for index in range(that.start, that.endex):
                    block = that.blocks[index]
                    block.address -= offset_
            else:
                block = that.blocks[that.endex - 1]
                offset_ = <addr_t>offset
                CheckAddAddrU(block.address, offset_)

                for index in range(that.start, that.endex):
                    block = that.blocks[index]
                    block.address += offset_
    return that


cdef bint Rack_Eq(const Rack_* that, const Rack_* other) except -1:
    cdef:
        size_t block_count = that.endex - that.start
        size_t block_index
        const Block_* block1
        const Block_* block2

    if block_count != other.endex - other.start:
        return False

    for block_index in range(block_count):
        block1 = Rack_Get__(that, block_index)
        block2 = Rack_Get__(other, block_index)

        if block1.address != block2.address:
            return False

        if not Block_Eq(block1, block2):
            return False

    return True


cdef Rack_* Rack_Reserve_(Rack_* that, size_t offset, size_t size) except NULL:
    cdef:
        size_t actual
        size_t used
        size_t margin
        size_t allocated
        Rack_* ptr
        size_t index
        Block_* node

    if size:
        if ((size > SIZE_HMAX or
             CannotAddSizeU(that.endex, size) or
             that.endex + size > SIZE_HMAX)):
            raise OverflowError('size overflow')

        used = that.endex - that.start
        if offset > used:
            raise IndexError('index out of range')

        # Prefer the side where there is less data to shift, which also favors the extremes
        if offset >= (used >> 1):
            if size > that.allocated - that.endex:
                # Calculate the upsized allocation
                allocated = Upsize(that.allocated, that.allocated + size)
                if allocated > SIZE_HMAX:
                    raise MemoryError()

                # Reallocate, including the header
                ptr = <Rack_*>PyMem_Realloc(that, Rack_HEADING + (allocated * sizeof(Block_*)))
                if ptr == NULL:
                    raise MemoryError()

                # Reassign to that
                that = ptr
                that.allocated = allocated  # update

            # Shift elements to make room for reservation at the requested offset
            CheckAddSizeU(offset, that.start)
            offset += that.start
            used = that.endex - offset
            if used:
                memmove(&that.blocks[offset + size],
                        &that.blocks[offset],
                        used * sizeof(Block_*))

            memset(&that.blocks[offset], 0, size * sizeof(Block_*))  # pad with zeros
            that.endex += size

        else:
            if size <= that.start:
                # Shift elements to make room for reservation at the requested offset
                that.start -= size
                if offset:
                    memmove(&that.blocks[that.start],
                            &that.blocks[that.start + size],
                            offset * sizeof(Block_*))

                memset(&that.blocks[that.start + offset], 0, size * sizeof(Block_*))  # pad with zeros

            else:
                # Calculate the upsized allocation
                CheckAddSizeU(that.allocated, size)
                allocated = Upsize(that.allocated, that.allocated + size)
                if allocated > SIZE_HMAX:
                    raise MemoryError()

                # Allocate a new chunk, including the header
                actual = Rack_HEADING + (allocated * sizeof(Block_*))
                ptr = <Rack_*>PyMem_Calloc(actual, 1)
                if ptr == NULL:
                    raise MemoryError()

                # Prepare the new chunk aligning towards the end
                ptr.allocated = allocated
                ptr.endex = ptr.allocated - MARGIN  # leave some room
                ptr.start = ptr.endex - used - size

                # Shift/copy elements to make room for reservation at the requested offset
                if offset:
                    used -= offset  # prepare for later
                    memcpy(&ptr.blocks[ptr.start],
                           &that.blocks[that.start],
                           offset * sizeof(Block_*))
                if used:
                    memcpy(&ptr.blocks[ptr.start + offset + size],
                           &that.blocks[that.start + offset],
                           used * sizeof(Block_*))

                # Reassign to that
                PyMem_Free(that)
                that = ptr

    return that


cdef Rack_* Rack_Delete_(Rack_* that, size_t offset, size_t size) except NULL:
    cdef:
        size_t allocated
        Rack_* ptr
        size_t index
        Block_* node

    if size:
        if ((size > SIZE_HMAX or
             CannotAddSizeU(offset, size) or
             offset + size > SIZE_HMAX or
             CannotAddSizeU(offset, that.start) or
             that.start > SIZE_HMAX)):
            raise OverflowError('size overflow')

        if that.endex < that.start + offset + size:
            raise IndexError('index out of range')

        # Calculate the downsized allocation
        allocated = Downsize(that.allocated, that.allocated - size)
        if allocated > SIZE_HMAX:
            raise MemoryError()

        # Release blocks within the deleted range
        offset += that.start
        for index in range(offset, offset + size):
            that.blocks[index] = Block_Release(that.blocks[index])

        if offset == 0:
            if allocated == that.allocated:
                # Just skip initial if not reallocated and no offset
                memset(&that.blocks[that.start], 0, size * sizeof(Block_*))  # cleanup margin
                that.start += size
            else:
                # Shift elements to make for the deleted gap at the beginning
                offset += that.start
                memmove(&that.blocks[MARGIN],  # realign to initial MARGIN
                        &that.blocks[offset + size],
                        (that.endex - (offset + size)) * sizeof(Block_*))
                size = that.endex - that.start - size
                that.start = MARGIN
                that.endex = MARGIN + size

                # Cleanup margins
                memset(&that.blocks[0], 0, that.start * sizeof(Block_*))
                memset(&that.blocks[that.endex], 0, (that.allocated - that.endex) * sizeof(Block_*))
        else:
            # Shift elements to make for the deleted gap at the requested offset
            memmove(&that.blocks[offset],
                    &that.blocks[offset + size],
                    (that.endex - (offset + size)) * sizeof(Block_*))
            that.endex -= size
            memset(&that.blocks[that.endex], 0, size * sizeof(Block_*))  # cleanup margin

        if allocated != that.allocated:
            # Reallocate, including the header
            ptr = <Rack_*>PyMem_Realloc(that, Rack_HEADING + (allocated * sizeof(Block_*)))
            if ptr == NULL:
                raise MemoryError()

            # Reassign to that
            that = ptr
            that.allocated = allocated

    return that


cdef Rack_* Rack_Clear(Rack_* that) except NULL:
    return Rack_Delete_(that, 0, that.endex - that.start)


cdef Rack_* Rack_Consolidate(Rack_* that) except NULL:
    cdef:
        size_t offset
        Block_* block

    for offset in range(that.start, that.endex):
        block = that.blocks[offset]
        if block.references > 1:
            that.blocks[offset] = Block_Copy(block)
            block = Block_Release(block)
    return that


cdef Block_** Rack_At_(Rack_* that, size_t offset) nogil:
    return &that.blocks[that.start + offset]


cdef const Block_** Rack_At__(const Rack_* that, size_t offset) nogil:
    return <const Block_**>&that.blocks[that.start + offset]


cdef Block_* Rack_First_(Rack_* that) nogil:
    return that.blocks[that.start]


cdef const Block_* Rack_First__(const Rack_* that) nogil:
    return that.blocks[that.start]


cdef Block_* Rack_Last_(Rack_* that) nogil:
    return that.blocks[that.endex - 1]


cdef const Block_* Rack_Last__(const Rack_* that) nogil:
    return that.blocks[that.endex - 1]


cdef Block_* Rack_Get__(const Rack_* that, size_t offset) nogil:
    return that.blocks[that.start + offset]


cdef Block_* Rack_Get_(const Rack_* that, size_t offset) except? NULL:
    CheckAddSizeU(that.start, offset)
    offset += that.start

    if offset < that.endex:
        return that.blocks[offset]
    else:
        raise IndexError('index out of range')


cdef Block_* Rack_Get(const Rack_* that, ssize_t offset) except? NULL:
    if offset < 0:
        offset += <ssize_t>(that.endex - that.start)  # anchor to end
        if offset < 0:
            raise IndexError('index out of range')

    return Rack_Get_(that, <size_t>offset)


cdef Block_* Rack_Set__(Rack_* that, size_t offset, Block_* value) nogil:
    cdef:
        Block_* backup

    offset += that.start
    backup = that.blocks[offset]
    that.blocks[offset] = value
    return backup


cdef vint Rack_Set_(Rack_* that, size_t offset, Block_* value, Block_** backup) except -1:
    CheckAddSizeU(that.start, offset)
    offset += that.start

    if offset < that.endex:
        if backup:
            backup[0] = that.blocks[offset]
        else:
            that.blocks[offset] = Block_Release(that.blocks[offset])
        that.blocks[offset] = value
    else:
        if backup:
            backup[0] = NULL
        raise IndexError('index out of range')


cdef vint Rack_Set(Rack_* that, ssize_t offset, Block_* value, Block_** backup) except -1:
    if offset < 0:
        offset += <ssize_t>(that.endex - that.start)  # anchor to end
        if offset < 0:
            raise IndexError('index out of range')

    Rack_Set_(that, <size_t>offset, value, backup)


cdef Rack_* Rack_Pop__(Rack_* that, Block_** value) except NULL:
    if that.start < that.endex:
        if value:
            value[0] = Block_Acquire(that.blocks[that.endex - 1])  # backup

        return Rack_Delete_(that, that.endex - that.start - 1, 1)
    else:
        if value:
            value[0] = NULL
        raise IndexError('pop index out of range')


cdef Rack_* Rack_Pop_(Rack_* that, size_t offset, Block_** value) except NULL:
    CheckAddSizeU(that.start, offset)

    if that.start + offset < that.endex:
        if value:
            value[0] = Block_Acquire(that.blocks[that.start + offset])  # backup

        return Rack_Delete_(that, offset, 1)
    else:
        if value:
            value[0] = NULL
        raise IndexError('pop index out of range')


cdef Rack_* Rack_Pop(Rack_* that, ssize_t offset, Block_** value) except NULL:
    if offset < 0:
        offset += <ssize_t>(that.endex - that.start)  # anchor to end
        if offset < 0:
            raise IndexError('pop index out of range')

    return Rack_Pop_(that, <size_t>offset, value)


cdef Rack_* Rack_PopLeft(Rack_* that, Block_** value) except NULL:
    return Rack_Pop_(that, 0, value)


cdef Rack_* Rack_Insert_(Rack_* that, size_t offset, Block_* value) except NULL:
    # Insert the value at the requested offset
    that = Rack_Reserve_(that, offset, 1)
    that.blocks[that.start + offset] = value
    return that


cdef Rack_* Rack_Insert(Rack_* that, ssize_t offset, Block_* value) except NULL:
    cdef:
        ssize_t size = <ssize_t>(that.endex - that.start)

    if offset < 0:
        offset += size  # anchor to end
        if offset < 0:
            # raise IndexError('index out of range')
            offset = 0  # as per bytearray.insert

    elif offset > size:
        # raise IndexError('index out of range')
        offset = size  # as per bytearray.insert

    return Rack_Insert_(that, <size_t>offset, value)


cdef Rack_* Rack_Append(Rack_* that, Block_* value) except NULL:
    # Insert the value after the end
    that = Rack_Reserve_(that, that.endex - that.start, 1)
    that.blocks[that.endex - 1] = value
    return that


cdef Rack_* Rack_AppendLeft(Rack_* that, Block_* value) except NULL:
    # Insert the value after the end
    that = Rack_Reserve_(that, 0, 1)
    that.blocks[that.start] = value
    return that


cdef Rack_* Rack_Extend_(Rack_* that, size_t size, Block_** buffer, bint direct) except NULL:
    cdef:
        size_t start
        size_t offset

    if size:
        that = Rack_Reserve_(that, that.endex - that.start, size)
        if direct:
            memmove(&that.blocks[that.endex - size], buffer, size * sizeof(Block_*))
        else:
            start = that.endex - size
            for offset in range(size):
                that.blocks[start + offset] = Block_Acquire(buffer[offset])
    return that


cdef Rack_* Rack_Extend(Rack_* that, Rack_* more) except NULL:
    that = Rack_Extend_(that, more.endex - more.start, &more.blocks[more.start], False)
    return that


cdef Rack_* Rack_ExtendLeft_(Rack_* that, size_t size, Block_** buffer, bint direct) except NULL:
    cdef:
        size_t start
        size_t offset

    if size:
        that = Rack_Reserve_(that, 0, size)
        if direct:
            memmove(&that.blocks[that.endex - size], buffer, size * sizeof(Block_*))
        else:
            start = that.start
            for offset in range(size):
                that.blocks[start + offset] = Block_Acquire(buffer[offset])
    return that


cdef Rack_* Rack_ExtendLeft(Rack_* that, Rack_* more) except NULL:
    that = Rack_ExtendLeft_(that, more.endex - more.start, &more.blocks[more.start], False)
    return that


cdef vint Rack_Read_(const Rack_* that, size_t offset,
                     size_t size, Block_** buffer, bint direct) except -1:
    if size:
        if size > SIZE_HMAX:
            raise OverflowError('size overflow')

        CheckAddSizeU(that.start, offset)
        offset += that.start

        CheckAddSizeU(offset, size)
        if that.endex <= offset + size:
            raise IndexError('index out of range')

        if direct:
            memmove(buffer, &that.blocks[offset], size * sizeof(Block_*))
        else:
            for offset in range(offset, offset + size):
                buffer[offset - that.start] = Block_Acquire(buffer[offset])


cdef Rack_* Rack_Write_(Rack_* that, size_t offset,
                        size_t size, Block_** buffer, bint direct) except NULL:
    if size:
        CheckAddSizeU(that.start, offset)
        offset += that.start

        CheckAddSizeU(offset, size)
        if that.endex < offset + size:
            that = Rack_Reserve_(that, that.endex - that.start, (offset + size) - that.endex)

        if direct:
            memmove(&that.blocks[offset], buffer, size * sizeof(Block_*))
        else:
            for offset in range(offset, offset + size):
                that.blocks[offset] = Block_Release(that.blocks[offset])
                that.blocks[offset] = Block_Acquire(buffer[offset - that.start])

    return that


cdef vint Rack_ReadSlice_(const Rack_* that, size_t start, size_t endex,
                          size_t* size_, Block_** buffer, bint direct) except -1:
    cdef:
        size_t size = that.endex - that.start

    size_[0] = 0

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound source start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex < start:
        endex = start  # clamp negative source length
    elif endex > size:
        endex = size  # bound source end

    size = endex - start
    Rack_Read_(that, start, size, buffer, direct)
    size_[0] = size


cdef vint Rack_ReadSlice(const Rack_* that, ssize_t start, ssize_t endex,
                         size_t* size_, Block_** buffer, bint direct) except -1:
    cdef:
        ssize_t ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
    if start < 0:
        start = 0  # bound source start

    if endex < 0:
        endex += ssize  # anchor to end
    if endex < start:
        endex = start  # clamp negative source length

    Rack_ReadSlice_(that, <size_t>start, <size_t>endex, size_, buffer, direct)


cdef Rack_* Rack_GetSlice_(const Rack_* that, size_t start, size_t endex) except NULL:
    cdef:
        Rack_* other = NULL
        size_t size = that.endex - that.start
        size_t offset
        size_t offset2

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound source start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex < start:
        endex = start  # clamp negative source length
    elif endex > size:
        endex = size  # bound source end

    try:
        size = endex - start
        other = Rack_Alloc(size)
        CheckAddSizeU(other.start, size)
        offset2 = that.start + start

        for offset in range(other.start, other.start + size):
            other.blocks[offset] = Block_Acquire(that.blocks[offset2])
            offset2 += 1

        return other
    except:
        other = Rack_Free(other)
        raise


cdef Rack_* Rack_GetSlice(const Rack_* that, ssize_t start, ssize_t endex) except NULL:
    cdef:
        ssize_t ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
    if start < 0:
        start = 0  # bound source start

    if endex < 0:
        endex += ssize  # anchor to end
    if endex < start:
        endex = start  # clamp negative source length

    return Rack_GetSlice_(that, <size_t>start, <size_t>endex)


cdef Rack_* Rack_WriteSlice_(Rack_* that, size_t start, size_t endex,
                             size_t size, Block_** buffer, bint direct) except NULL:
    cdef:
        size_t size2   # source size

    size2 = size
    size = that.endex - that.start

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound target start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex > size:
        endex = size  # bound target end

    if endex < start:
        endex = start  # clamp negative target length
    size = endex - start

    if size2 > size:  # enlarge target at range end
        that = Rack_Reserve_(that, endex, size2 - size)

    elif size > size2:  # shrink target at range end
        endex -= size - size2
        that = Rack_Delete_(that, endex, size - size2)

    that = Rack_Write_(that, start, size2, buffer, direct)
    return that


cdef Rack_* Rack_WriteSlice(Rack_* that, ssize_t start, ssize_t endex,
                            size_t size, Block_** buffer, bint direct) except NULL:
    cdef:
        ssize_t ssize   # target size
        ssize_t ssize2  # source size
        ssize_t start2  # source start
        ssize_t endex2  # source end

    start2 = 0
    endex2 = <ssize_t>size

    ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
    if start < 0:
        # start2 -= start  # skip initial source data  # as per bytearray
        start = 0  # bound target start
    if start2 > endex2:
        start2 = endex2  # clamp source start

    if endex < 0:
        endex += ssize  # anchor to end
    if endex < start:
        endex = start  # clamp negative target length

    if endex2 < start2:
        endex2 = start2  # clamp negative source length
    ssize2 = endex2 - start2

    that = Rack_WriteSlice_(that, <size_t>start, <size_t>endex, <size_t>ssize2, &buffer[start2], direct)
    return that


cdef Rack_* Rack_SetSlice_(Rack_* that, size_t start, size_t endex,
                           Rack_* src, size_t start2, size_t endex2) except NULL:
    cdef:
        size_t size   # target size
        size_t size2  # source size

    size2 = src.endex - src.start

    if start2 > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start2 > size2:
        start2 = size2  # bound source start

    if endex2 > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex2 > size2:
        endex2 = size2  # bound source end

    if endex2 < start2:
        endex2 = start2  # clamp negative source length
    size2 = endex2 - start2

    size = that.endex - that.start

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound target start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex > size:
        endex = size  # bound target end

    if endex < start:
        endex = start  # clamp negative target length
    size = endex - start

    if size2 > size:  # enlarge target at range end
        that = Rack_Reserve_(that, endex, size2 - size)

    elif size > size2:  # shrink target at range end
        endex -= size - size2
        that = Rack_Delete_(that, endex, size - size2)

    that = Rack_Write_(that, start, size2, &src.blocks[src.start + start2], False)
    return that


cdef Rack_* Rack_SetSlice(Rack_* that, ssize_t start, ssize_t endex,
                          Rack_* src, ssize_t start2, ssize_t endex2) except NULL:
    cdef:
        ssize_t ssize   # target size
        ssize_t ssize2  # source size

    ssize = <ssize_t>(that.endex - that.start)
    ssize2 = <ssize_t>(src.endex - src.start)

    if start < 0:
        start += ssize  # anchor to target end
    if start < 0:
        # start2 -= start  # skip initial source data  # as per bytearray
        start = 0  # bound target start

    if endex < 0:
        endex += ssize  # anchor to target end
    if endex < start:
        endex = start  # clamp negative target length

    if start2 < 0:
        start2 += ssize2  # anchor to source end
    if start2 < 0:
        start2 = 0  # bound source start

    if endex2 < 0:
        endex2 += ssize2  # anchor to source end
    if endex2 < start2:
        endex2 = start2  # clamp negative source length

    that = Rack_SetSlice_(that, <size_t>start, <size_t>endex, src, <size_t>start2, <size_t>endex2)
    return that


cdef Rack_* Rack_DelSlice_(Rack_* that, size_t start, size_t endex) except NULL:
    cdef:
        size_t size

    size = that.endex - that.start

    if start > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif start > size:
        start = size  # bound start

    if endex > SIZE_HMAX:
        raise OverflowError('size overflow')
    elif endex < start:
        endex = start  # clamp negative length
    elif endex > size:
        endex = size  # bound end

    that = Rack_Delete_(that, start, (endex - start))
    return that


cdef Rack_* Rack_DelSlice(Rack_* that, ssize_t start, ssize_t endex) except NULL:
    cdef:
        ssize_t ssize

    ssize = <ssize_t>(that.endex - that.start)

    if start < 0:
        start += ssize  # anchor to end
    if start < 0:
        start = 0  # bound start

    if endex < 0:
        endex += ssize  # anchor to end
    if endex < start:
        endex = start  # clamp negative length

    that = Rack_DelSlice_(that, <size_t>start, <size_t>endex)
    return that


cdef addr_t Rack_Start(const Rack_* that) nogil:
    return Block_Start(Rack_First__(that)) if Rack_Bool(that) else 0


cdef addr_t Rack_Endex(const Rack_* that) nogil:
    return Block_Endex(Rack_Last__(that)) if Rack_Bool(that) else 0


cdef ssize_t Rack_IndexAt(const Rack_* that, addr_t address) nogil:
    cdef:
        ssize_t left = 0
        ssize_t right = <ssize_t>(that.endex - that.start)
        ssize_t center
        const Block_* block

    if right:
        block = that.blocks[that.start]
        if address < Block_Start(block):
            return -1

        block = that.blocks[that.endex - 1]
        if Block_Endex(block) <= address:
            return -1
    else:
        return -1

    while left <= right:
        center = (left + right) >> 1
        block = that.blocks[that.start + center]

        if Block_Endex(block) <= address:
            left = center + 1
        elif address < Block_Start(block):
            right = center - 1
        else:
            return center
    else:
        return -1


cdef ssize_t Rack_IndexStart(const Rack_* that, addr_t address) nogil:
    cdef:
        ssize_t left = 0
        ssize_t right = <ssize_t>(that.endex - that.start)
        ssize_t center
        const Block_* block

    if right:
        block = that.blocks[that.start]
        if address <= Block_Start(block):
            return 0

        block = that.blocks[that.endex - 1]
        if Block_Endex(block) <= address:
            return right
    else:
        return 0

    while left <= right:
        center = (left + right) >> 1
        block = that.blocks[that.start + center]

        if Block_Endex(block) <= address:
            left = center + 1
        elif address < Block_Start(block):
            right = center - 1
        else:
            return center
    else:
        return left


cdef ssize_t Rack_IndexEndex(const Rack_* that, addr_t address) nogil:
    cdef:
        ssize_t left = 0
        ssize_t right = <ssize_t>(that.endex - that.start)
        ssize_t center
        const Block_* block

    if right:
        block = that.blocks[that.start]
        if address < Block_Start(block):
            return 0

        block = that.blocks[that.endex - 1]
        if Block_Endex(block) <= address:
            return right
    else:
        return 0

    while left <= right:
        center = (left + right) >> 1
        block = that.blocks[that.start + center]

        if Block_Endex(block) <= address:
            left = center + 1
        elif address < Block_Start(block):
            right = center - 1
        else:
            return center + 1
    else:
        return right + 1


# =====================================================================================================================

cdef Memory Memory_AsObject(Memory_* that):
    cdef:
        Memory memory = Memory()

    memory._ = Memory_Free(memory._)
    memory._ = that
    return memory


cdef Memory_* Memory_Alloc() except NULL:
    cdef:
        Rack_* blocks = Rack_Alloc(0)
        Memory_* that = NULL

    that = <Memory_*>PyMem_Calloc(Memory_HEADING, 1)
    if that == NULL:
        blocks = Rack_Free(blocks)
        raise MemoryError()

    that.blocks = blocks
    that.bound_start = 0
    that.bound_endex = ADDR_MAX
    that.bound_start_ = False
    that.bound_endex_ = False
    return that


cdef Memory_* Memory_Free(Memory_* that) except? NULL:
    if that:
        that.blocks = Rack_Free(that.blocks)
        PyMem_Free(that)
    return NULL


cdef size_t Memory_Sizeof(const Memory_* that):
    if that:
        return Memory_HEADING + Rack_Sizeof(that.blocks)
    return 0


cdef Memory_* Memory_Create(
    object start,
    object endex,
) except NULL:
    cdef:
        Memory_* that = <Memory_*>PyMem_Calloc(Memory_HEADING, 1)

    if that == NULL:
        raise MemoryError()
    try:
        if start is None:
            that.bound_start = ADDR_MIN
            that.bound_start_ = False
        else:
            that.bound_start = <addr_t>start
            that.bound_start_ = True

        if endex is None:
            that.bound_endex = ADDR_MAX
            that.bound_endex_ = False
        else:
            that.bound_endex = <addr_t>endex
            that.bound_endex_ = True

        if that.bound_endex < that.bound_start:
            that.bound_endex = that.bound_start

        that.blocks = Rack_Alloc(0)

    except:
        that = Memory_Free(that)
        raise

    return that


cdef Memory_* Memory_FromBlocks_(
    const Rack_* blocks,
    object offset,
    object start,
    object endex,
    bint validate,
) except NULL:
    cdef:
        Memory_* that = NULL
        Rack_* blocks_
        size_t block_index
        Block_* block
        addr_t offset_abs = 0
        bint offset_neg = offset < 0

    if blocks == NULL:
        raise ValueError('null blocks')

    if Rack_Bool(blocks):
        if offset_neg:
            offset_abs = <addr_t>-offset
            CheckSubAddrU(Block_Start(Rack_First__(that.blocks)), offset_abs)
        else:
            offset_abs = <addr_t>offset
            CheckAddAddrU(Block_Endex(Rack_Last__(that.blocks)), offset_abs)

    try:
        that = Memory_Create(start, endex)
        that.blocks = Rack_Free(that.blocks)
        that.blocks = Rack_Copy(blocks)
        blocks_ = that.blocks

        if offset_neg:
            for block_index in range(Rack_Length(blocks)):
                block = Rack_Get_(blocks, block_index)
                block.address -= offset_abs
        else:
            for block_index in range(Rack_Length(blocks)):
                block = Rack_Get_(blocks, block_index)
                block.address += offset_abs

        if validate:
            Memory_Validate(that)

    except:
        that = Memory_Free(that)
        raise

    return that


cdef Memory_* Memory_FromBlocks(
    object blocks,
    object offset,
    object start,
    object endex,
    bint validate,
) except NULL:
    cdef:
        bint offset_ = <bint>offset
        Memory_* that = Memory_Create(start, endex)
        addr_t delta
        const byte_t[:] block_view
        const byte_t* block_data
        size_t block_size
        addr_t block_start
        addr_t block_endex
        size_t block_offset
        Block_* block = NULL

    try:
        for block_start_, block_data_ in blocks:
            block_offset = 0
            block_start = <addr_t>(block_start_ + offset) if offset_ else <addr_t>block_start_
            if that.bound_endex <= block_start:
                break

            block_view = block_data_
            block_size = <size_t>len(block_view)
            CheckAddAddrU(block_start, block_size)
            block_endex = block_start + block_size
            if block_endex <= that.bound_start:
                continue

            # Bound before memory
            if block_start < that.bound_start:
                delta = that.bound_start - block_start
                CheckAddrToSizeU(delta)
                block_start += <size_t>delta
                block_size  -= <size_t>delta
                block_offset = <size_t>delta

            # Bound after memory
            if that.bound_endex < block_endex:
                delta = block_endex - that.bound_endex
                CheckAddrToSizeU(delta)
                block_endex -= <size_t>delta
                block_size  -= <size_t>delta

            if block_size:
                with cython.boundscheck(False):
                    block_data = &block_view[block_offset]
                block = Block_Create(block_start, block_size, block_data)
                that.blocks = Rack_Append(that.blocks, block)
                block = NULL
            else:
                if not that.bound_start_ and not that.bound_endex_:
                    raise ValueError('invalid block data size')

        if validate:
            Memory_Validate(that)

    except:
        block = Block_Release(block)
        that = Memory_Free(that)
        raise

    return that


cdef Memory_* Memory_FromBytes_(
    size_t data_size,
    const byte_t* data_ptr,
    object offset,
    object start,
    object endex,
) except NULL:
    cdef:
        bint offset_ = <bint>offset
        Memory_* that = Memory_Create(start, endex)
        addr_t delta
        const byte_t* block_data
        size_t block_size = data_size
        addr_t block_start = <addr_t>offset
        addr_t block_endex
        size_t block_offset = 0
        Block_* block = NULL

    try:
        if that.bound_endex <= block_start:
            return that

        CheckAddAddrU(block_start, block_size)
        block_endex = block_start + block_size
        if block_endex <= that.bound_start:
            return that

        # Bound before memory
        if block_start < that.bound_start:
            delta = that.bound_start - block_start
            CheckAddrToSizeU(delta)
            block_start += <size_t>delta
            block_size  -= <size_t>delta
            block_offset = <size_t>delta

        # Bound after memory
        if that.bound_endex < block_endex:
            delta = block_endex - that.bound_endex
            CheckAddrToSizeU(delta)
            block_endex -= <size_t>delta
            block_size  -= <size_t>delta

        if block_size:
            with cython.boundscheck(False):
                block_data = &data_ptr[block_offset]
            block = Block_Create(block_start, block_size, block_data)
            that.blocks = Rack_Append(that.blocks, block)
            block = NULL

    except:
        block = Block_Release(block)
        that = Memory_Free(that)
        raise

    return that


cdef Memory_* Memory_FromBytes(
    object data,
    object offset,
    object start,
    object endex,
) except NULL:
    cdef:
        const byte_t[:] data_view = data
        const byte_t* data_ptr
        size_t data_size

    with cython.boundscheck(False):
        data_ptr = &data_view[0]
        data_size = len(data_view)

    return Memory_FromBytes_(data_size, data_ptr, offset, start, endex)


cdef Memory_* Memory_FromItems(
    object items,
    object offset,
    object start,
    object endex,
    bint validate,
) except NULL:
    cdef:
        Memory_* that = Memory_Create(start, endex)

    try:
        if isinstance(items, Mapping):
            items = items.items()

        for address, value in items:
            Memory_Poke(that, address + offset, value)

        if validate:
            Memory_Validate(that)

    except:
        that = Memory_Free(that)
        raise

    return that


cdef Memory_* Memory_FromMemory_(
    const Memory_* memory,
    object offset,
    object start,
    object endex,
    bint validate,
) except NULL:
    cdef:
        Memory_* that = Memory_Copy(memory)

    try:
        that.bound_start = ADDR_MIN
        that.bound_endex = ADDR_MAX
        that.bound_start_ = False
        that.bound_endex_ = False

        Memory_Shift(that, offset)

        Memory_SetBoundStart(that, start)
        Memory_SetBoundEndex(that, endex)

        if validate:
            Memory_Validate(that)

    except:
        that = Memory_Free(that)
        raise

    return that


cdef Memory_* Memory_FromMemory(
    object memory,
    object offset,
    object start,
    object endex,
    bint validate,
) except NULL:

    if isinstance(memory, Memory):
        return Memory_FromMemory_((<Memory>memory)._, offset, start, endex, validate)
    else:
        return Memory_FromBlocks(memory.blocks(), offset, start, endex, validate)


cdef Memory_* Memory_FromValues(
    object values,
    object offset,
    object start,
    object endex,
    bint validate,
) except NULL:
    cdef:
        addr_t start_ = ADDR_MIN if start is None else <addr_t>start
        addr_t endex_ = ADDR_MAX if endex is None else <addr_t>endex
        Memory_* that = Memory_Create(start, endex)
        addr_t address = <addr_t>offset
        bint append = False
        byte_t value_

    if endex_ < start_:
        endex_ = start_

    try:
        for value in values:
            if endex_ <= address:
                break
            if start_ <= address:
                if value is not None:
                    value_ = <byte_t>value
                    if append:
                        Memory_Append_(that, value_)
                    else:
                        Memory_Poke_(that, address, value_)
                    append = True
                else:
                    append = False
            address += 1

        if validate:
            Memory_Validate(that)

    except:
        that = Memory_Free(that)
        raise

    return that


cdef bint Memory_EqSame_(const Memory_* that, const Memory_* other) except -1:
    return Rack_Eq(that.blocks, other.blocks)


cdef bint Memory_EqRaw_(const Memory_* that, size_t data_size, const byte_t* data_ptr) except -1:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_count
        const Block_* block
        size_t size

    block_count = Rack_Length(blocks)
    if block_count:
        if block_count != 1:
            return False

        block = Rack_First__(blocks)
        size = Block_Length(block)
        if data_size != size:
            return False

        if memcmp(Block_At__(block, 0), data_ptr, data_size):
            return False
        return True
    else:
        return not data_size


cdef bint Memory_EqView_(const Memory_* that, const byte_t[:] view) except -1:
    with cython.boundscheck(False):
        return Memory_EqRaw_(that, len(view), &view[0])


cdef bint Memory_EqIter_(const Memory_* that, object iterable) except -1:
    cdef:
        addr_t start = Memory_Start(that)
        addr_t endex = Memory_ContentEndex(that)
        Rover_* rover = Rover_Create(that, start, endex, 0, NULL, True, False)
        bint equal = True
        int item1_
        int item2_

    try:
        for item2 in iterable:
            item1_ = Rover_Next_(rover) if Rover_HasNext(rover) else -1
            item2_ = -1 if item2 is None else <int><unsigned><byte_t>item2

            if item1_ != item2_:
                equal = False
                break
        else:
            if Rover_HasNext(rover):
                equal = False
    finally:
        Rover_Free(rover)

    return equal


cdef bint Memory_EqMemory_(const Memory_* that, object memory) except -1:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_index = 0
        const Block_* block
        size_t block_size
        const byte_t[:] view

    if Memory_ContentParts(that) != memory.content_parts:
        return False

    for block_start, block_data in memory.blocks():
        block = Rack_Get__(blocks, block_index)

        if Block_Start(block) != block_start:
            return False

        with cython.boundscheck(False):
            view = block_data
            if not Block_Eq_(block, len(view), &view[0]):
                return False

        block_index += 1

    return True


cdef bint Memory_Eq(const Memory_* that, object other) except -1:
    cdef:
        const byte_t[:] view

    if isinstance(other, Memory):
        return Memory_EqSame_(that, (<Memory>other)._)

    elif isinstance(other, ImmutableMemory):
        return Memory_EqMemory_(that, other)

    else:
        try:
            view = other
        except TypeError:
            return Memory_EqIter_(that, other)
        else:
            return Memory_EqView_(that, view)


cdef Memory_* Memory_Add(const Memory_* that, object value) except NULL:
    cdef:
        Memory_* memory = Memory_Copy(that)
    try:
        Memory_Extend(memory, value, 0)
    except:
        memory = Memory_Free(memory)
        raise
    return memory


cdef Memory_* Memory_IAdd(Memory_* that, object value) except NULL:
    Memory_Extend(that, value, 0)
    return that


cdef Memory_* Memory_Mul(const Memory_* that, addr_t times) except NULL:
    cdef:
        Memory_* memory = NULL
        addr_t offset
        addr_t size
        addr_t time

    if times and Rack_Bool(that.blocks):
        start = Memory_Start(that)
        size = Memory_Endex(that) - start
        offset = size  # adjust first write
        memory = Memory_Copy(that)
        try:
            for time in range(times - 1):
                Memory_WriteSame_(memory, offset, that, False)
                offset += size
        except:
            memory = Memory_Free(memory)
            raise

        return memory
    else:
        return Memory_Alloc()


cdef Memory_* Memory_IMul(Memory_* that, addr_t times) except NULL:
    cdef:
        Memory_* memory = NULL
        addr_t offset

    times = int(times)
    if times < 0:
        times = 0

    if times and Rack_Bool(that.blocks):
        start = Memory_Start(that)
        size = Memory_Endex(that) - start
        offset = size
        memory = Memory_Copy(that)
        try:
            for time in range(times - 1):
                Memory_WriteSame_(that, offset, memory, False)
                offset += size
        finally:
            memory = Memory_Free(memory)
    else:
        that.blocks = Rack_Clear(that.blocks)
    return that


cdef bint Memory_Bool(const Memory_* that) nogil:
    return Rack_Bool(that.blocks)


cdef addr_t Memory_Length(const Memory_* that) nogil:
    return Memory_Endex(that) - Memory_Start(that)


cdef bint Memory_IsEmpty(const Memory_* that) nogil:
    return not Rack_Bool(that.blocks)


cdef addr_t Memory_FindUnbounded_(const Memory_* that, size_t size, const byte_t* buffer) except? -1:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_index
        const Block_* block
        ssize_t offset
        addr_t start_
        addr_t offset_

    if size:
        for block_index in range(Rack_Length(blocks)):
            block = Rack_Get__(blocks, block_index)
            offset = Block_Find_(block, 0, SIZE_MAX, size, buffer)
            if offset >= 0:
                start_ = Block_Start(block)
                offset_ = <addr_t><size_t>offset
                CheckAddAddrU(start_, offset_)
                return start_ + offset_
    return ADDR_MAX


cdef addr_t Memory_FindBounded_(const Memory_* that, size_t size, const byte_t* buffer,
                                addr_t start, addr_t endex) except? -1:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_index
        const Block_* block
        ssize_t offset
        size_t block_index_start
        size_t block_index_endex
        size_t slice_start
        size_t slice_endex
        addr_t start_
        addr_t offset_

    if size:
        if endex < start:
            endex = start
        block_index_start = Rack_IndexStart(blocks, start)
        block_index_endex = Rack_IndexEndex(blocks, endex)

        for block_index in range(block_index_start, block_index_endex):
            block = Rack_Get__(blocks, block_index)
            slice_start, slice_endex = Block_BoundAddressSliceToOffset(block, start, endex)
            offset = Block_Find_(block, slice_start, slice_endex, size, buffer)
            if offset >= 0:
                start_ = Block_Start(block)
                offset_ = <addr_t><size_t>offset
                CheckAddAddrU(start_, offset_)
                return start_ + offset_
    return ADDR_MAX


cdef object Memory_Find(const Memory_* that, object item, object start, object endex):
    cdef:
        addr_t start_
        addr_t endex_
        byte_t item_value
        const byte_t[:] item_view
        size_t item_size
        const byte_t* item_ptr
        addr_t address

    if isinstance(item, int):
        item_value = <byte_t>item
        item_size = 1
        item_ptr = &item_value
    else:
        item_view = item
        item_size = 1
        with cython.boundscheck(False):
            item_ptr = &item_view[0]

    # Faster code for unbounded slice
    if start is None and endex is None:
        address = Memory_FindUnbounded_(that, item_size, item_ptr)
        return -1 if address == ADDR_MAX else <object>address

    # Bounded slice
    start_, endex_ = Memory_Bound(that, start, endex)
    address = Memory_FindBounded_(that, item_size, item_ptr, start_, endex_)
    return -1 if address == ADDR_MAX else <object>address


cdef addr_t Memory_RevFindUnbounded_(const Memory_* that, size_t size, const byte_t* buffer) except? -1:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_index
        const Block_* block
        ssize_t offset
        addr_t start_
        addr_t offset_

    if size:
        for block_index in range(Rack_Length(blocks), 0, -1):
            block = Rack_Get__(blocks, block_index - 1)
            offset = Block_ReverseFind_(block, 0, SIZE_MAX, size, buffer)
            if offset >= 0:
                start_ = Block_Start(block)
                offset_ = <addr_t><size_t>offset
                CheckAddAddrU(start_, offset_)
                return start_ + offset_
    return ADDR_MAX


cdef addr_t Memory_RevFindBounded_(const Memory_* that, size_t size, const byte_t* buffer,
                                   addr_t start, addr_t endex) except? -1:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_index
        const Block_* block
        ssize_t offset
        size_t block_index_start
        size_t block_index_endex
        size_t slice_start
        size_t slice_endex
        addr_t start_
        addr_t offset_

    if size:
        if endex < start:
            endex = start
        block_index_start = Rack_IndexStart(blocks, start)
        block_index_endex = Rack_IndexEndex(blocks, endex)

        for block_index in range(block_index_endex, block_index_start, -1):
            block = Rack_Get__(blocks, block_index - 1)
            slice_start, slice_endex = Block_BoundAddressSliceToOffset(block, start, endex)
            offset = Block_ReverseFind_(block, slice_start, slice_endex, size, buffer)
            if offset >= 0:
                start_ = Block_Start(block)
                offset_ = <addr_t><size_t>offset
                CheckAddAddrU(start_, offset_)
                return start_ + offset_
    return ADDR_MAX


cdef object Memory_RevFind(const Memory_* that, object item, object start, object endex):
    cdef:
        addr_t start_
        addr_t endex_
        byte_t item_value
        const byte_t[:] item_view
        size_t item_size
        const byte_t* item_ptr
        addr_t address

    if isinstance(item, int):
        item_value = <byte_t>item
        item_size = 1
        item_ptr = &item_value
    else:
        item_view = item
        item_size = 1
        with cython.boundscheck(False):
            item_ptr = &item_view[0]

    # Faster code for unbounded slice
    if start is None and endex is None:
        address = Memory_RevFindUnbounded_(that, item_size, item_ptr)
        return -1 if address == ADDR_MAX else <object>address

    # Bounded slice
    start_, endex_ = Memory_Bound(that, start, endex)
    address = Memory_RevFindBounded_(that, item_size, item_ptr, start_, endex_)
    return -1 if address == ADDR_MAX else <object>address


cdef object Memory_Index(const Memory_* that, object item, object start, object endex):
    offset = Memory_Find(that, item, start, endex)
    if offset != -1:
        return offset
    else:
        raise ValueError('subsection not found')


cdef object Memory_RevIndex(const Memory_* that, object item, object start, object endex):
    offset = Memory_RevFind(that, item, start, endex)
    if offset != -1:
        return offset
    else:
        raise ValueError('subsection not found')


cdef bint Memory_Contains(const Memory_* that, object item) except -1:
    cdef:
        byte_t item_value
        const byte_t[:] item_view
        size_t item_size
        const byte_t* item_ptr
        addr_t address

    if isinstance(item, int):
        item_value = <byte_t>item
        item_size = 1
        item_ptr = &item_value
    else:
        item_view = item
        item_size = 1
        with cython.boundscheck(False):
            item_ptr = &item_view[0]

    address = Memory_FindUnbounded_(that, item_size, item_ptr)
    return address != ADDR_MAX


cdef addr_t Memory_CountUnbounded_(const Memory_* that, size_t size, const byte_t* buffer) except? -1:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_index
        const Block_* block
        addr_t count = 0

    if size:
        for block_index in range(Rack_Length(blocks)):
            block = Rack_Get__(blocks, block_index)
            count += Block_Count_(block, 0, SIZE_MAX, size, buffer)
    return count


cdef addr_t Memory_CountBounded_(const Memory_* that, size_t size, const byte_t* buffer,
                                 addr_t start, addr_t endex) except? -1:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_index
        const Block_* block
        addr_t count = 0
        size_t block_index_start
        size_t block_index_endex
        addr_t block_start
        addr_t block_endex
        size_t slice_start
        size_t slice_endex

    if size:
        if endex < start:
            endex = start
        block_index_start = Rack_IndexStart(blocks, start)
        block_index_endex = Rack_IndexEndex(blocks, endex)

        for block_index in range(block_index_start, block_index_endex):
            block = Rack_Get__(blocks, block_index)
            slice_start, slice_endex = Block_BoundAddressSliceToOffset(block, start, endex)
            count += Block_Count_(block, slice_start, slice_endex, size, buffer)
    return count


cdef addr_t Memory_Count(const Memory_* that, object item, object start, object endex) except? -1:
    cdef:
        addr_t start_
        addr_t endex_
        byte_t item_value
        const byte_t[:] item_view
        size_t item_size
        const byte_t* item_ptr

    if isinstance(item, int):
        item_value = <byte_t>item
        item_size = 1
        item_ptr = &item_value
    else:
        item_view = item
        item_size = 1
        with cython.boundscheck(False):
            item_ptr = &item_view[0]

    # Faster code for unbounded slice
    if start is None and endex is None:
        return Memory_CountUnbounded_(that, item_size, item_ptr)

    # Bounded slice
    start_, endex_ = Memory_Bound(that, start, endex)
    return Memory_CountBounded_(that, item_size, item_ptr, start_, endex_)


cdef object Memory_GetItem(const Memory_* that, object key):
    cdef:
        slice key_
        addr_t start
        addr_t endex
        Block_* pattern = NULL
        Memory memory
        int value

    if isinstance(key, slice):
        key_ = <slice>key
        key_start = key_.start
        key_endex = key_.stop
        start = Memory_Start(that) if key_start is None else <addr_t>key_start
        endex = Memory_Endex(that) if key_endex is None else <addr_t>key_endex
        key_step = key_.step

        if key_step is None or key_step is 1 or key_step == 1:
            return Memory_Extract_(that, start, endex, 0, NULL, 1, True)

        elif isinstance(key_step, int):
            if key_step > 1:
                return Memory_Extract_(that, start, endex, 0, NULL, <saddr_t>key_step, True)
            else:
                return Memory()  # empty

        else:
            pattern = Block_FromObject(0, key_step, True)
            try:
                memory = Memory_Extract_(that, start, endex, Block_Length(pattern), Block_At__(pattern, 0), 1, True)
            finally:
                Block_Free(pattern)  # orphan
            return memory
    else:
        value = Memory_Peek_(that, <addr_t>key)
        return None if value < 0 else value


cdef object Memory_SetItem(Memory_* that, object key, object value):
    cdef:
        slice key_
        addr_t start
        addr_t endex
        addr_t step = 0  # indefinite
        addr_t address
        addr_t slice_size
        Block_* value_ = NULL
        size_t value_size
        addr_t del_start
        addr_t del_endex
        size_t offset

    if isinstance(key, slice):
        key_ = <slice>key
        key_start = key_.start
        key_endex = key_.stop
        start = Memory_Start(that) if key_start is None else <addr_t>key_start
        endex = Memory_Endex(that) if key_endex is None else <addr_t>key_endex
        if endex < start:
            endex = start

        key_step = key_.step
        if isinstance(key_step, int):
            if key_step is None or key_step is 1 or key_step == 1:
                pass
            elif key_step > 1:
                step = <addr_t>key_step
            else:
                return  # empty range

        if value is None:
            # Clear range
            if not step:
                Memory_Erase__(that, start, endex, False)  # clear
            else:
                address = start
                while address < endex:
                    Memory_Erase__(that, address, address + 1, False)  # clear
                    if CannotAddAddrU(address, step):
                        break
                    address += step
            return  # nothing to write

        slice_size = endex - start
        if step:
            with cython.cdivision(True):
                slice_size = (slice_size + step - 1) // step
        CheckAddrToSizeU(slice_size)

        value_ = Block_FromObject(0, value, False)
        try:
            if isinstance(value, int):
                value_ = Block_Repeat(value_, <size_t>slice_size)
            value_size = Block_Length(value_)

            if value_size < slice_size:
                # Shrink: remove excess, overwrite existing
                if not step:
                    if CannotAddAddrU(start, value_size):
                        del_start = ADDR_MAX
                    else:
                        del_start = start + value_size
                    if CannotAddAddrU(del_start, (slice_size - value_size)):
                        del_endex = ADDR_MAX
                    else:
                        del_endex = del_start + (slice_size - value_size)
                    Memory_Erase__(that, del_start, del_endex, True)  # delete
                    if value_size:
                        Memory_WriteRaw_(that, start, value_size, Block_At__(value_, 0))
                else:
                    raise ValueError(f'attempt to assign bytes of size {value_size}'
                                     f' to extended slice of size {slice_size}')
            elif slice_size < value_size:
                # Enlarge: insert excess, overwrite existing
                if not step:
                    Memory_InsertRaw_(that, endex, value_size - slice_size, Block_At__(value_, slice_size))
                    Memory_WriteRaw_(that, start, slice_size, Block_At__(value_, 0))
                else:
                    raise ValueError(f'attempt to assign bytes of size {value_size}'
                                     f' to extended slice of size {slice_size}')
            else:
                # Same size: overwrite existing
                if not step:
                    Memory_WriteRaw_(that, start, value_size, Block_At__(value_, 0))
                else:
                    CheckMulAddrU(step, value_size)
                    CheckAddAddrU(start, step * value_size)
                    for offset in range(value_size):
                        Memory_Poke_(that, start + (step * offset), Block_Get__(value_, offset))
        finally:
            Block_Free(value_)  # orphan
    else:
        # below: self.poke(key, value)
        address = <addr_t>key
        if value is None:
            Memory_PokeNone_(that, address)
        else:
            if isinstance(value, int):
                Memory_Poke_(that, address, <byte_t>value)
            else:
                if len(value) != 1:
                    raise ValueError('expecting single item')
                Memory_Poke_(that, address, <byte_t>value[0])


cdef vint Memory_DelItem(Memory_* that, object key) except -1:
    cdef:
        slice key_
        addr_t start
        addr_t endex
        addr_t step
        addr_t address

    if Rack_Bool(that.blocks):
        if isinstance(key, slice):
            key_ = <slice>key
            key_start = key_.start
            key_endex = key_.stop
            start = Memory_Start(that) if key_start is None else <addr_t>key_start
            endex = Memory_Endex(that) if key_endex is None else <addr_t>key_endex

            if start < endex:
                key_step = key_.step
                if key_step is None or key_step is 1 or key_step == 1:
                    Memory_Erase__(that, start, endex, True)  # delete

                elif key_step > 1:
                    step = <addr_t>key_step - 1
                    address = start
                    while address < endex:
                        Memory_Erase__(that, address, address + 1, True)  # delete
                        address += step
                        endex -= 1
        else:
            address = <addr_t>key
            Memory_Erase__(that, address, address + 1, True)  # delete


cdef vint Memory_Append_(Memory_* that, byte_t value) except -1:
    cdef:
        Rack_* blocks = that.blocks
        size_t block_count
        Block_* block

    block_count = Rack_Length(blocks)
    if block_count:
        block = Block_Append(Rack_Last_(blocks), value)
        Rack_Set__(blocks, block_count - 1, block)  # update pointer
    else:
        block = Block_Create(0, 1, &value)
        try:
            that.blocks = blocks = Rack_Append(blocks, block)
        except:
            Block_Free(block)  # orphan
            raise


cdef vint Memory_Append(Memory_* that, object item) except -1:
    if isinstance(item, int):
        Memory_Append_(that, <byte_t>item)
    else:
        if len(item) != 1:
            raise ValueError('expecting single item')
        Memory_Append_(that, <byte_t>item[0])


cdef vint Memory_ExtendSame_(Memory_* that, const Memory_* items, addr_t offset) except -1:
    cdef:
        addr_t content_endex = Memory_ContentEndex(that)

    CheckAddAddrU(content_endex, offset)
    offset += content_endex
    Memory_WriteSame_(that, offset, items, False)


cdef vint Memory_ExtendRaw_(Memory_* that, size_t items_size, const byte_t* items_ptr, addr_t offset) except -1:
    cdef:
        addr_t content_endex = Memory_ContentEndex(that)

    CheckAddAddrU(content_endex, offset)
    offset += content_endex
    CheckAddAddrU(offset, items_size)
    Memory_WriteRaw_(that, offset, items_size, items_ptr)


cdef vint Memory_Extend(Memory_* that, object items, object offset) except -1:
    cdef:
        const byte_t[:] items_view
        byte_t items_value
        size_t items_size
        const byte_t* items_ptr

    if offset < 0:
        raise ValueError('negative extension offset')

    if isinstance(items, Memory):
        Memory_ExtendSame_(that, (<Memory>items)._, <addr_t>offset)

    elif isinstance(items, ImmutableMemory):
        Memory_Write(that, Memory_ContentEndex(that) + offset, items, True)

    else:
        if isinstance(items, int):
            items_value = <byte_t>items
            items_size = 1
            items_ptr = &items_value
        else:
            try:
                items_view = items
            except TypeError:
                items = bytes(items)
                items_view = items

            items_size = len(items_view)
            with cython.boundscheck(False):
                items_ptr = &items_view[0]

        Memory_ExtendRaw_(that, items_size, items_ptr, <addr_t>offset)


cdef int Memory_PopLast_(Memory_* that) except -2:
    cdef:
        Rack_* blocks = that.blocks
        size_t block_count = Rack_Length(blocks)
        Block_* block
        size_t length
        byte_t backup

    if block_count:
        block = Rack_Last_(blocks)
        length = Block_Length(block)
        if length > 1:
            block = Block_Pop__(block, &backup)
            Rack_Set__(blocks, block_count - 1, block)  # update pointer
        elif length == 1:
            backup = Block_Get__(block, 0)
            that.blocks = blocks = Rack_Pop__(blocks, NULL)  # update pointer
        else:
            raise RuntimeError('empty block')
        return backup
    else:
        return -1


cdef int Memory_PopAt_(Memory_* that, addr_t address) except -2:
    cdef:
        int backup

    backup = Memory_Peek_(that, address)
    Memory_Erase__(that, address, address + 1, True)  # delete
    return backup


cdef object Memory_Pop(Memory_* that, object address, object default):
    cdef:
        int value

    if address is None:
        value = Memory_PopLast_(that)
    else:
        value = Memory_PopAt_(that, <addr_t>address)
    return default if value < 0 else value


cdef (addr_t, int) Memory_PopItem(Memory_* that) except *:
    cdef:
        Rack_* blocks = that.blocks
        size_t block_count = Rack_Length(blocks)
        Block_* block
        size_t length
        addr_t address
        byte_t backup

    if block_count:
        block = Rack_Last_(blocks)
        length = Block_Length(block)
        address = Block_Start(block) + length - 1
        if length > 1:
            block = Block_Pop__(block, &backup)
            Rack_Set__(blocks, block_count - 1, block)  # update pointer
        elif length == 1:
            backup = Block_Get__(block, 0)
            that.blocks = blocks = Rack_Pop__(blocks, NULL)  # update pointer
        else:
            raise RuntimeError('empty block')
        return address, backup
    else:
        raise KeyError('empty')


cdef BlockView Memory_View_(const Memory_* that, addr_t start, addr_t endex):
    cdef:
        const Rack_* blocks
        Block_* block
        ssize_t block_index
        addr_t block_start
        addr_t block_endex

    if start < endex:
        blocks = that.blocks
        block_index = Rack_IndexAt(blocks, start)

        if block_index >= 0:
            block = Rack_Get__(blocks, <size_t>block_index)
            block_endex = Block_Endex(block)

            if endex <= block_endex:
                block_start = Block_Start(block)
                start -= block_start
                endex -= block_start
                return Block_ViewSlice_(block, <size_t>start, <size_t>endex)

        raise ValueError('non-contiguous data within range')
    else:
        return Block_ViewSlice_(_empty_block, 0, 0)


cdef BlockView Memory_View(const Memory_* that, object start, object endex):
    cdef:
        addr_t start_
        addr_t endex_

    start_, endex_ = Memory_Bound(that, start, endex)
    return Memory_View_(that, start_, endex_)


cdef BlockView Memory_Read_(const Memory_* that, addr_t address, size_t size):
    CheckAddAddrU(address, size)
    return Memory_View_(that, address, address + size)


cdef BlockView Memory_Read(const Memory_* that, object address, object size):
    return Memory_Read_(that, <addr_t>address, <size_t>size)


cdef Memory_* Memory_Copy(const Memory_* that) except NULL:
    cdef:
        Rack_* blocks = Rack_Copy(that.blocks)
        Memory_* memory = NULL

    memory = <Memory_*>PyMem_Calloc(Memory_HEADING, 1)
    if memory == NULL:
        blocks = Rack_Free(blocks)
        raise MemoryError()

    memory.blocks = blocks
    memory.bound_start = that.bound_start
    memory.bound_endex = that.bound_endex
    memory.bound_start_ = that.bound_start_
    memory.bound_endex_ = that.bound_endex_
    return memory


cdef Memory_* Memory_Cut_(Memory_* that, addr_t start, addr_t endex, bint bound) except NULL:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_count
        size_t block_index
        size_t block_index_start
        size_t block_index_endex
        Memory_* memory = Memory_Alloc()
        Rack_* memory_blocks
        Block_* block1
        Block_* block2
        addr_t block_start
        addr_t block_endex

    if endex < start:
        endex = start

    if start < endex and Rack_Bool(blocks):
        # Copy all the blocks except those completely outside selection
        block_index_start = Rack_IndexStart(blocks, start)
        block_index_endex = Rack_IndexEndex(blocks, endex)
        block_count = block_index_endex - block_index_start

        if block_count:
            memory_blocks = memory.blocks
            block_count = block_index_endex - block_index_start
            try:
                memory.blocks = memory_blocks = Rack_Reserve_(memory_blocks, 0, block_count)
            except:
                memory = Memory_Free(memory)  # orphan
                raise
            else:
                for block_index in range(block_count):
                    block1 = Rack_Get_(blocks, block_index_start + block_index)
                    block1 = Block_Acquire(block1)
                    Rack_Set__(memory_blocks, block_index, block1)
            try:
                # Bound cloned data before the selection start address
                block_index = 0
                block1 = Rack_Get_(memory_blocks, block_index)
                block_start = Block_Start(block1)
                if block_start < start:
                    try:
                        block2 = NULL
                        block2 = Block_Copy(block1)
                        block2 = Block_DelSlice_(block2, 0, <size_t>(start - block_start))
                        block2.address = start
                    except:
                        block2 = Block_Free(block2)  # orphan
                        raise
                    else:
                        Rack_Set__(memory_blocks, block_index, block2)
                        Block_Release(block1)

                # Bound cloned data after the selection end address
                block_index = block_count - 1
                block1 = Rack_Get_(memory_blocks, block_index)
                block_endex = Block_Endex(block1)
                if endex < block_endex:
                    block_start = Block_Start(block1)
                    if block_start < endex:
                        try:
                            block2 = NULL
                            block2 = Block_Copy(block1)
                            block2 = Block_DelSlice_(block2, <size_t>(endex - block_start), Block_Length(block2))
                            block2.address = block_start
                        except:
                            block2 = Block_Free(block2)  # orphan
                            raise
                        else:
                            Rack_Set__(memory_blocks, block_index, block2)
                            Block_Release(block1)
                    else:
                        memory.blocks = memory_blocks = Rack_Pop__(memory_blocks, &block2)
                        block2 = Block_Release(block2)  # orphan

                Memory_Erase__(that, start, endex, False)  # clear

            except:
                memory = Memory_Free(memory)  # orphan
                raise

    if bound:
        memory.bound_start = start
        memory.bound_endex = endex
        memory.bound_start_ = True
        memory.bound_endex_ = True

    return memory


cdef object Memory_Cut(Memory_* that, object start, object endex, bint bound):
    cdef:
        addr_t start_ = Memory_Start(that) if start is None else <addr_t>start
        addr_t endex_ = Memory_Endex(that) if endex is None else <addr_t>endex
        Memory_* memory = Memory_Cut_(that, start_, endex_, bound)

    return Memory_AsObject(memory)



cdef void Memory_Reverse(Memory_* that) nogil:
    cdef:
        Rack_* blocks = that.blocks
        size_t block_count = Rack_Length(blocks)
        size_t block_index
        Block_* block
        addr_t start
        addr_t endex

    if block_count:
        start = Memory_Start(that)
        endex = Memory_Endex(that)

        for block_index in range(block_count):
            block = Rack_Get__(blocks, block_index)
            Block_Reverse(block)
            block.address = endex - Block_Endex(block) + start

        Rack_Reverse(that.blocks)


cdef bint Memory_Contiguous(const Memory_* that) nogil:
    cdef:
        Rack_* blocks = that.blocks
        size_t block_count = Rack_Length(blocks)
        addr_t start
        addr_t endex

    if not block_count:
        start = that.bound_start
        endex = that.bound_endex
        if that.bound_start_ and that.bound_endex_ and start < endex:
            return False
        return True

    elif block_count == 1:
        start = that.bound_start
        if that.bound_start_:
            if start != Block_Start(Rack_First__(blocks)):
                return False
        endex = that.bound_endex
        if that.bound_endex_:
            if endex != Block_Endex(Rack_Last__(blocks)):
                return False
        return True

    return False


cdef object Memory_GetBoundStart(const Memory_* that):
    return that.bound_start if that.bound_start_ else None


cdef vint Memory_SetBoundStart(Memory_* that, object bound_start) except -1:
    cdef:
        addr_t bound_start_
        addr_t bound_endex_

    if bound_start is None:
        bound_start_ = ADDR_MIN
        that.bound_start_ = False
    else:
        bound_start_ = <addr_t>bound_start
        that.bound_start_ = True

    bound_endex_ = that.bound_endex
    if that.bound_start_ and that.bound_endex_ and bound_endex_ < bound_start_:
        that.bound_endex = bound_endex_ = bound_start_

    that.bound_start = bound_start_
    if that.bound_start_:
        Memory_Crop_(that, bound_start_, bound_endex_)


cdef object Memory_GetBoundEndex(const Memory_* that):
    return that.bound_endex if that.bound_endex_ else None


cdef vint Memory_SetBoundEndex(Memory_* that, object bound_endex) except -1:
    cdef:
        addr_t bound_start_
        addr_t bound_endex_

    if bound_endex is None:
        bound_endex_ = ADDR_MAX
        that.bound_endex_ = False
    else:
        bound_endex_ = <addr_t>bound_endex
        that.bound_endex_ = True

    bound_start_ = that.bound_start
    if that.bound_start_ and that.bound_endex_ and bound_endex_ < bound_start_:
        that.bound_start = bound_start_ = bound_endex_

    that.bound_endex = bound_endex_
    if that.bound_endex_:
        Memory_Crop_(that, bound_start_, bound_endex_)


cdef object Memory_GetBoundSpan(const Memory_* that):
    return (that.bound_start if that.bound_start_ else None,
            that.bound_endex if that.bound_endex_ else None)


cdef vint Memory_SetBoundSpan(Memory_* that, object bound_span) except -1:
    if bound_span is None:
        bound_start = None
        bound_endex = None
    else:
        bound_start, bound_endex = bound_span

    if bound_start is None:
        bound_start_ = 0
        that.bound_start_ = False
    else:
        bound_start_ = <addr_t>bound_start
        that.bound_start_ = True

    if bound_endex is None:
        bound_endex_ = ADDR_MAX
        that.bound_endex_ = False
    else:
        bound_endex_ = <addr_t>bound_endex
        that.bound_endex_ = True

    if that.bound_start_ and that.bound_endex_ and bound_endex_ < bound_start_:
        bound_endex_ = bound_start_

    that.bound_start = bound_start_
    that.bound_endex = bound_endex_
    if that.bound_start_ or that.bound_endex_:
        Memory_Crop_(that, bound_start_, bound_endex_)


cdef addr_t Memory_Start(const Memory_* that) nogil:
    cdef:
        const Rack_* blocks

    if not that.bound_start_:
        # Return actual
        blocks = that.blocks
        if Rack_Bool(blocks):
            return Block_Start(Rack_First__(blocks))
        else:
            return 0
    else:
        return that.bound_start


cdef addr_t Memory_Endex(const Memory_* that) nogil:
    cdef:
        const Rack_* blocks

    if not that.bound_endex_:
        # Return actual
        blocks = that.blocks
        if Rack_Bool(blocks):
            return Block_Endex(Rack_Last__(blocks))
        else:
            return Memory_Start(that)
    else:
        return that.bound_endex


cdef (addr_t, addr_t) Memory_Span(const Memory_* that) nogil:
    return Memory_Start(that), Memory_Endex(that)


cdef object Memory_Endin(const Memory_* that):
    cdef:
        const Rack_* blocks

    if not that.bound_endex_:
        # Return actual
        blocks = that.blocks
        if Rack_Bool(blocks):
            return <object>Block_Endex(Rack_Last__(blocks)) - 1
        else:
            return <object>Memory_Start(that) - 1
    else:
        return <object>that.bound_endex - 1


cdef addr_t Memory_ContentStart(const Memory_* that) nogil:
    cdef:
        const Rack_* blocks = that.blocks

    if Rack_Bool(blocks):
        return Block_Start(Rack_First__(blocks))
    elif not that.bound_start_:
        return 0
    else:
        return that.bound_start


cdef addr_t Memory_ContentEndex(const Memory_* that) nogil:
    cdef:
        const Rack_* blocks = that.blocks

    if Rack_Bool(blocks):
        return Block_Endex(Rack_Last__(blocks))
    elif not that.bound_start_:
        return 0  # default to start
    else:
        return that.bound_start  # default to start


cdef (addr_t, addr_t) Memory_ContentSpan(const Memory_* that) nogil:
    return Memory_ContentStart(that), Memory_ContentEndex(that)


cdef object Memory_ContentEndin(const Memory_* that):
    cdef:
        const Rack_* blocks = that.blocks

    if Rack_Bool(blocks):
        return <object>Block_Endex(Rack_Last__(blocks)) - 1
    elif not that.bound_start_:  # default to start-1
        return -1
    else:
        return <object>that.bound_start - 1  # default to start-1


cdef addr_t Memory_ContentSize(const Memory_* that) nogil:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_index
        const Block_* block
        addr_t content_size = 0

    for block_index in range(Rack_Length(blocks)):
        block = Rack_Get__(blocks, block_index)
        content_size += Block_Length(block)
    return content_size


cdef size_t Memory_ContentParts(const Memory_* that) nogil:
    return Rack_Length(that.blocks)


cdef vint Memory_Validate(const Memory_* that) except -1:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_count = Rack_Length(blocks)

        addr_t start
        addr_t endex
        addr_t previous_endex = 0

        size_t block_index
        const Block_* block
        addr_t block_start
        addr_t block_endex

    start, endex = Memory_Bound(that, None, None)
    block_count = Rack_Length(blocks)

    if block_count:
        if endex <= start:
            raise ValueError('invalid bounds')

        for block_index in range(block_count):
            block = Rack_Get__(blocks, block_index)
            block_start = Block_Start(block)
            block_endex = Block_Endex(block)

            if block_index:  # skip first
                if block_start <= previous_endex:
                    raise ValueError('invalid block interleaving')

            if block_endex <= block_start:
                raise ValueError('invalid block data size')

            if block_start < start or endex < block_endex:
                raise ValueError('invalid block bounds')

            previous_endex = block_endex

    else:
        if endex < start:
            raise ValueError('invalid bounds')


cdef (addr_t, addr_t) Memory_Bound_(const Memory_* that, addr_t start, addr_t endex,
                                    bint start_, bint endex_) nogil:
    cdef:
        addr_t bound_start
        addr_t bound_endex

    bound_start = that.bound_start
    bound_endex = that.bound_endex

    if not start_:
        if not that.bound_start_:
            if Rack_Bool(that.blocks):
                start = Block_Start(Rack_First__(that.blocks))
            else:
                start = 0
        else:
            start = bound_start
    else:
        if that.bound_start_:
            if start < bound_start:
                start = bound_start
        if endex_:
            if endex < start:
                endex = start

    if not endex_:
        if not that.bound_endex_:
            if Rack_Bool(that.blocks):
                endex = Block_Endex(Rack_Last__(that.blocks))
            else:
                endex = start
        else:
            endex = bound_endex
    else:
        if that.bound_endex_:
            if endex > bound_endex:
                endex = bound_endex
        if start > endex:
            start = endex

    return start, endex


cdef (addr_t, addr_t) Memory_Bound(const Memory_* that, object start, object endex) except *:
    cdef:
        bint start__ = start is not None
        bint endex__ = endex is not None
        addr_t start_ = <addr_t>start if start__ else 0
        addr_t endex_ = <addr_t>endex if endex__ else start_

    return Memory_Bound_(that, start_, endex_, start__, endex__)


cdef int Memory_Peek_(const Memory_* that, addr_t address) nogil:
    cdef:
        const Rack_* blocks = that.blocks
        ssize_t block_index
        const Block_* block

    block_index = Rack_IndexAt(blocks, address)
    if block_index < 0:
        return -1
    else:
        block = Rack_Get__(blocks, <size_t>block_index)
        return Block_Get__(block, address - Block_Start(block))


cdef object Memory_Peek(const Memory_* that, object address):
    cdef:
        int value

    value = Memory_Peek_(that, <addr_t>address)
    return None if value < 0 else value


cdef vint Memory_PokeNone_(Memory_* that, addr_t address) except -1:
    if address < that.bound_start:
        return 0
    if address >= that.bound_endex:
        return 0

    # Standard clear method
    Memory_Erase__(that, address, address + 1, False)  # clear
    return 0


cdef vint Memory_Poke_(Memory_* that, addr_t address, byte_t item) except -1:
    cdef:
        Rack_* blocks
        size_t block_count
        size_t block_index
        Block_* block
        addr_t block_start
        addr_t block_endex
        Block_* block2
        addr_t block_start2

    if address < that.bound_start:
        return 0
    if address >= that.bound_endex:
        return 0

    blocks = that.blocks
    block_index = Rack_IndexEndex(blocks, address) - 1
    block_count = Rack_Length(blocks)

    if block_index < block_count:
        block = Rack_Get__(blocks, block_index)
        block_start = Block_Start(block)
        block_endex = Block_Endex(block)

        if block_start <= address < block_endex:
            # Address within existing block, update directly
            address -= block_start
            Block_Set__(block, <size_t>address, item)
            return 0

        elif address == block_endex:
            # Address just after the end of the block, append
            block = Block_Append(block, item)
            Rack_Set__(blocks, block_index, block)  # update pointer

            block_index += 1
            if block_index < block_count:
                block2 = Rack_Get__(blocks, block_index)
                block_start2 = Block_Start(block2)

                if block_endex + 1 == block_start2:
                    # Merge with the following contiguous block
                    block = Block_Extend(block, block2)
                    Rack_Set__(blocks, block_index - 1, block)  # update pointer
                    that.blocks = blocks = Rack_Pop_(blocks, block_index, NULL)
            return 0

        else:
            block_index += 1
            if block_index < block_count:
                block = Rack_Get__(blocks, block_index)
                block_start = Block_Start(block)

                if address + 1 == block_start:
                    # Prepend to the next block
                    block = Block_AppendLeft(block, item)
                    Rack_Set__(blocks, block_index, block)  # update pointer
                    block.address -= 1  # update address
                    return 0

    # There is no faster way than the standard block writing method
    Memory_Erase__(that, address, address + 1, False)  # clear
    Memory_Place__(that, address, 1, &item, False)  # write

    Memory_Crop_(that, that.bound_start, that.bound_endex)
    return 0


cdef vint Memory_Poke(Memory_* that, object address, object item) except -1:
    cdef:
        addr_t address_ = <addr_t>address

    if item is None:
        Memory_PokeNone_(that, address_)
    else:
        if isinstance(item, int):
            Memory_Poke_(that, address_, <byte_t>item)
        else:
            if len(item) != 1:
                raise ValueError('expecting single item')
            Memory_Poke_(that, address_, <byte_t>item[0])


cdef Memory_* Memory_Extract__(const Memory_* that, addr_t start, addr_t endex,
                               size_t pattern_size, const byte_t* pattern_ptr,
                               saddr_t step, bint bound) except NULL:
    cdef:
        const Rack_* blocks = that.blocks
        size_t block_count
        size_t block_index
        size_t block_index_start
        size_t block_index_endex
        Memory_* memory = Memory_Alloc()
        Rack_* blocks2
        Block_* block2
        addr_t offset
        Block_* pattern = NULL
        int value
        saddr_t skip
        Rover_* rover = NULL

    if endex < start:
        endex = start

    if step == 1:
        if start < endex and Rack_Bool(blocks):
            # Copy all the blocks except those completely outside selection
            block_index_start = Rack_IndexStart(blocks, start)
            block_index_endex = Rack_IndexEndex(blocks, endex)
            block_count = block_index_endex - block_index_start

            if block_count:
                memory_blocks = memory.blocks
                block_count = block_index_endex - block_index_start
                try:
                    memory.blocks = memory_blocks = Rack_Reserve_(memory_blocks, 0, block_count)

                    for block_index in range(block_count):
                        block2 = Rack_Get_(blocks, block_index_start + block_index)
                        block2 = Block_Copy(block2)
                        Rack_Set__(memory_blocks, block_index, block2)  # update pointer

                    # Bound cloned data before the selection start address
                    block_index = 0
                    block2 = Rack_Get_(memory_blocks, block_index)
                    block_start = Block_Start(block2)
                    if block_start < start:
                        block2 = Block_DelSlice_(block2, 0, <size_t>(start - block_start))
                        block2.address = start
                        Rack_Set__(memory_blocks, block_index, block2)

                    # Bound cloned data after the selection end address
                    block_index = block_count - 1
                    block2 = Rack_Get_(memory_blocks, block_index)
                    block_endex = Block_Endex(block2)
                    if endex < block_endex:
                        block_start = Block_Start(block2)
                        if block_start < endex:
                            block2 = Block_DelSlice_(block2, <size_t>(endex - block_start), Block_Length(block2))
                            block2.address = block_start
                            Rack_Set__(memory_blocks, block_index, block2)  # update pointer
                        else:
                            memory.blocks = memory_blocks = Rack_Pop__(memory_blocks, &block2)
                            block2 = Block_Release(block2)  # orphan
                except:
                    memory = Memory_Free(memory)  # orphan
                    raise

            if pattern_size and pattern_ptr:
                pattern = Block_Create(0, pattern_size, pattern_ptr)
                try:
                    Memory_Flood_(memory, start, endex, &pattern)
                except:
                    Block_Free(pattern)  # orphan
                    memory = Memory_Free(memory)  # orphan
                    raise
    else:
        if step > 1:
            block2 = NULL
            offset = start
            rover = Rover_Create(that, start, endex, pattern_size, pattern_ptr, True, False)
            try:
                while True:
                    value = Rover_Next_(rover)
                    if value < 0:
                        if block2:
                            memory.blocks = Rack_Append(memory.blocks, block2)
                            block2 = NULL
                    else:
                        if not block2:
                            block2 = Block_Alloc(offset, 0, False)
                        block2 = Block_Append(block2, <byte_t>value)

                    offset += 1
                    for skip in range(step - 1):
                        Rover_Next_(rover)
            except StopIteration:
                if block2:
                    memory.blocks = Rack_Append(memory.blocks, block2)
                    block2 = NULL
            finally:
                block2 = Block_Free(block2)  # orphan
                rover = Rover_Free(rover)

            if bound:
                endex = offset
    if bound:
        memory.bound_start = start
        memory.bound_endex = endex
        memory.bound_start_ = True
        memory.bound_endex_ = True

    return memory


cdef object Memory_Extract_(const Memory_* that, addr_t start, addr_t endex,
                            size_t pattern_size, const byte_t* pattern_ptr,
                            saddr_t step, bint bound):
    cdef:
        Memory_* memory_ = Memory_Extract__(that, start, endex, pattern_size, pattern_ptr, step, bound)

    return Memory_AsObject(memory_)


cdef object Memory_Extract(const Memory_* that, object start, object endex,
                           object pattern, object step, bint bound):
    cdef:
        addr_t start_
        addr_t endex_
        const byte_t[:] pattern_view
        byte_t pattern_value
        size_t pattern_size
        const byte_t* pattern_ptr
        saddr_t step_ = <saddr_t>1 if step is None else <saddr_t>step

    if pattern is None:
        pattern_size = 0
        pattern_ptr = NULL

    elif isinstance(pattern, int):
        pattern_value = <byte_t>pattern
        pattern_size = 1
        pattern_ptr = &pattern_value

    else:
        pattern_view = pattern
        pattern_size = len(pattern_view)
        with cython.boundscheck(False):
            pattern_ptr = &pattern_view[0]

    start_ = Memory_Start(that) if start is None else <addr_t>start
    endex_ = Memory_Endex(that) if endex is None else <addr_t>endex

    return Memory_Extract_(that, start_, endex_, pattern_size, pattern_ptr, step_, bound)


cdef vint Memory_ShiftLeft_(Memory_* that, addr_t offset) except -1:
    cdef:
        Rack_* blocks = that.blocks
        size_t block_index
        Block_* block

    if offset and Rack_Bool(blocks):
        Memory_PreboundStart_(that, ADDR_MAX, offset)
        blocks = that.blocks

        for block_index in range(Rack_Length(blocks)):
            block = Rack_Get__(blocks, block_index)
            block.address -= offset


cdef vint Memory_ShiftRight_(Memory_* that, addr_t offset) except -1:
    cdef:
        Rack_* blocks = that.blocks
        size_t block_index
        Block_* block

    if offset and Rack_Bool(blocks):
        Memory_PreboundEndex_(that, ADDR_MIN, offset)
        blocks = that.blocks

        for block_index in range(Rack_Length(blocks)):
            block = Rack_Get__(blocks, block_index)
            block.address += offset


cdef vint Memory_Shift(Memory_* that, object offset) except -1:
    if offset:
        if offset < 0:
            Memory_ShiftLeft_(that, <addr_t>-offset)
        else:
            Memory_ShiftRight_(that, <addr_t>offset)


cdef vint Memory_Reserve_(Memory_* that, addr_t address, addr_t size) except -1:
    cdef:
        addr_t offset
        Rack_* blocks = that.blocks
        size_t block_count
        size_t block_index
        Block_* block
        addr_t block_start
        Block_* block2

    if size and Rack_Bool(blocks):
        Memory_PreboundEndex_(that, address, size)

        block_index = Rack_IndexStart(blocks, address)
        block_count = Rack_Length(blocks)

        if block_index < block_count:
            block = Rack_Get_(blocks, block_index)
            block_start = Block_Start(block)

            if address > block_start:
                # Split into two blocks, reserving emptiness
                CheckAddSizeU(block_count, 1)  # ensure free slot
                offset = address - block_start
                block2 = Block_GetSlice_(block, offset, SIZE_HMAX)
                try:
                    block = Block_DelSlice_(block, offset, SIZE_HMAX)

                    Rack_Set__(blocks, block_index, block)  # update pointer
                    block_index += 1

                    CheckAddAddrU(address, size)
                    block2.address = address + size
                    that.blocks = blocks = Rack_Insert(blocks, block_index, block2)
                except:
                    block2 = Block_Free(block2)  # orphan
                    raise
                block_index += 1

            for block_index in range(block_index, Rack_Length(blocks)):
                block = Rack_Get_(blocks, block_index)
                block.address += size


cdef vint Memory_Reserve(Memory_* that, object address, object size) except -1:
    Memory_Reserve_(that, <addr_t>address, <addr_t>size)


cdef vint Memory_Place__(Memory_* that, addr_t address, size_t size, const byte_t* buffer,
                         bint shift_after) except -1:
    cdef:
        Rack_* blocks
        size_t block_index
        Block_* block
        addr_t block_start
        addr_t block_endex
        Block_* block2
        addr_t block_start2
        size_t offset

    if size:
        blocks = that.blocks
        block_index = Rack_IndexStart(blocks, address)

        if block_index:
            block = Rack_Get_(blocks, block_index - 1)
            block_start = Block_Start(block)
            block_endex = Block_Endex(block)

            if block_endex == address:
                # Extend previous block
                block = Block_Extend_(block, size, buffer)
                Rack_Set__(blocks, block_index - 1, block)  # update pointer

                # Shift blocks after
                if shift_after:
                    for block_index in range(block_index, Rack_Length(blocks)):
                        block = Rack_Get_(blocks, block_index)
                        CheckAddAddrU(block.address, size)
                        block.address += size
                else:
                    if block_index < Rack_Length(blocks):
                        CheckAddAddrU(block_endex, size)
                        block_endex += size

                        block2 = Rack_Get_(blocks, block_index)
                        block_start2 = Block_Start(block2)

                        # Merge with next block
                        if block_endex == block_start2:
                            block = Block_Extend(block, block2)
                            Rack_Set__(blocks, block_index - 1, block)  # update pointer
                            that.blocks = blocks = Rack_Pop_(blocks, block_index, NULL)
                return 0

        if block_index < Rack_Length(blocks):
            block = Rack_Get_(blocks, block_index)
            block_start = Block_Start(block)

            if address < block_start:
                if shift_after:
                    # Insert a standalone block before
                    block = Block_Create(address, size, buffer)
                    try:
                        that.blocks = blocks = Rack_Insert(blocks, block_index, block)
                    except:
                        Block_Free(block)  # orphan
                        raise
                else:
                    CheckAddAddrU(address, size)
                    if address + size == block_start:
                        # Merge with next block
                        block = Rack_Get_(blocks, block_index)
                        block.address = address
                        block = Block_ExtendLeft_(block, size, buffer)
                        Rack_Set__(blocks, block_index, block)  # update pointer
                    else:
                        # Insert a standalone block before
                        block = Block_Create(address, size, buffer)
                        try:
                            that.blocks = blocks = Rack_Insert(blocks, block_index, block)
                        except:
                            Block_Free(block)  # orphan
                            raise
            else:
                # Insert buffer into the current block
                CheckSubAddrU(address, block_start)
                CheckAddrToSizeU(address - block_start)
                offset = <size_t>(address - block_start)
                block = Block_Reserve_(block, offset, size, False)
                block = Block_Write_(block, offset, size, buffer)
                Rack_Set__(blocks, block_index, block)  # update pointer

            # Shift blocks after
            if shift_after:
                for block_index in range(block_index + 1, Rack_Length(blocks)):
                    block = Rack_Get__(blocks, block_index)
                    CheckAddAddrU(block.address, size)
                    block.address += size

        else:
            # Append a standalone block after
            block = Block_Create(address, size, buffer)
            try:
                that.blocks = blocks = Rack_Append(blocks, block)
            except:
                Block_Free(block)  # orphan
                raise


cdef vint Memory_Erase__(Memory_* that, addr_t start, addr_t endex, bint shift_after) except -1:
    cdef:
        addr_t size
        addr_t offset

        Rack_* blocks = that.blocks
        size_t block_index
        size_t inner_start
        size_t inner_endex

        Block_* block = NULL
        addr_t block_start
        addr_t block_endex

        Block_* block2 = NULL
        addr_t block_start2

    if Rack_Bool(blocks) and endex > start:
        size = endex - start
        block_index = Rack_IndexStart(blocks, start)

        # Delete final/inner part of deletion start block
        if block_index < Rack_Length(blocks):
            block = Rack_Get__(blocks, block_index)
            block_start = Block_Start(block)
            if start > block_start:
                if shift_after:
                    CheckAddrToSizeU(start - block_start)
                    CheckAddrToSizeU(endex - block_start)
                    block = Block_DelSlice_(block, start - block_start, endex - block_start)
                    Rack_Set__(blocks, block_index, block)  # update pointer
                else:
                    try:
                        CheckAddrToSizeU(start - block_start)
                        block = Block_GetSlice_(block, 0, start - block_start)
                        block.address = block_start
                        that.blocks = blocks = Rack_Insert_(blocks, block_index, block)
                    except:
                        block = Block_Free(block)  # orphan
                        raise
                block_index += 1  # skip this from inner part

        # Delete initial part of deletion end block
        inner_start = block_index
        for block_index in range(block_index, Rack_Length(blocks)):
            block = Rack_Get__(blocks, block_index)

            block_start = Block_Start(block)
            if endex <= block_start:
                break  # inner ends before here

            block_endex = Block_Endex(block)
            if endex < block_endex:
                offset = endex - block_start
                CheckAddrToSizeU(offset)
                CheckAddAddrU(block.address, offset)
                block = Block_DelSlice_(block, 0, <size_t>offset)
                block.address += offset  # update address
                Rack_Set__(blocks, block_index, block)  # update pointer
                break  # inner ends before here
        else:
            block_index = Rack_Length(blocks)
        inner_endex = block_index

        if shift_after:
            # Check if inner deletion can be merged
            if inner_start and inner_endex < Rack_Length(blocks):
                block = Rack_Get__(blocks, inner_start - 1)
                block_endex = Block_Endex(block)

                block2 = Rack_Get__(blocks, inner_endex)
                block_start2 = Block_Start(block2)

                if block_endex + size == block_start2:
                    block = Block_Extend(block, block2)  # merge deletion boundaries
                    Rack_Set__(blocks, inner_start - 1, block)  # update pointer
                    inner_endex += 1  # add to inner deletion
                    block_index += 1  # skip address update

            # Shift blocks after deletion
            for block_index in range(block_index, Rack_Length(blocks)):
                block = Rack_Get__(blocks, block_index)
                CheckSubAddrU(block.address, size)
                block.address -= size  # update address

        # Delete inner full blocks
        if inner_start < inner_endex:
            that.blocks = blocks = Rack_DelSlice_(blocks, inner_start, inner_endex)


cdef vint Memory_InsertSame_(Memory_* that, addr_t address, Memory_* data) except -1:
    cdef:
        addr_t data_start = Memory_Start(data)
        addr_t data_endex = Memory_Endex(data)
        addr_t data_size = data_endex - data_start

    if data_size:
        Memory_Reserve_(that, address, data_size)
        Memory_WriteSame_(that, address, data, True)


cdef vint Memory_InsertRaw_(Memory_* that, addr_t address, size_t data_size, const byte_t* data_ptr) except -1:
    if data_size:
        Memory_Reserve_(that, address, data_size)
        Memory_WriteRaw_(that, address, data_size, data_ptr)


cdef vint Memory_Insert(Memory_* that, object address, object data) except -1:
    cdef:
        addr_t address_ = <addr_t>address
        const byte_t[:] data_view
        byte_t data_value
        size_t data_size
        const byte_t* data_ptr

    if isinstance(data, Memory):
        Memory_InsertSame_(that, address_, (<Memory>data)._)

    else:
        if isinstance(data, int):
            data_value = <byte_t>data
            data_size = 1
            data_ptr = &data_value
        else:
            data_view = data
            data_size = len(data_view)
            with cython.boundscheck(False):
                data_ptr = &data_view[0]

        Memory_InsertRaw_(that, address_, data_size, data_ptr)


cdef vint Memory_Delete_(Memory_* that, addr_t start, addr_t endex) except -1:
    if start < endex:
        Memory_Erase__(that, start, endex, True)  # delete


cdef vint Memory_Delete(Memory_* that, object start, object endex) except -1:
    cdef:
        addr_t start_ = Memory_Start(that) if start is None else <addr_t> start
        addr_t endex_ = Memory_Endex(that) if endex is None else <addr_t> endex

    Memory_Delete_(that, start_, endex_)


cdef vint Memory_Clear_(Memory_* that, addr_t start, addr_t endex) except -1:
    if start < endex:
        Memory_Erase__(that, start, endex, False)  # clear


cdef vint Memory_Clear(Memory_* that, object start, object endex) except -1:
    cdef:
        addr_t start_ = Memory_Start(that) if start is None else <addr_t> start
        addr_t endex_ = Memory_Endex(that) if endex is None else <addr_t> endex

    Memory_Clear_(that, start_, endex_)


cdef vint Memory_PreboundStart_(Memory_* that, addr_t endex_max, addr_t size) except -1:
    cdef:
        addr_t content_start
        addr_t bound_start
        addr_t endex

    if size:
        bound_start = that.bound_start if that.bound_start_ else ADDR_MIN
        if CannotAddAddrU(bound_start, size):
            endex = ADDR_MAX
        else:
            endex = bound_start + size

        if endex > endex_max:
            endex = endex_max

        content_start = Memory_ContentStart(that)
        Memory_Erase__(that, content_start, endex, False)  # clear


cdef vint Memory_PreboundStart(Memory_* that, object endex_max, object size) except -1:
        cdef:
            addr_t endex_max_ = ADDR_MAX if endex_max is None else <addr_t>endex_max

        Memory_PreboundStart_(that, endex_max_, <addr_t>size)


cdef vint Memory_PreboundEndex_(Memory_* that, addr_t start_min, addr_t size) except -1:
    cdef:
        addr_t content_endex
        addr_t bound_endex
        addr_t start

    if size:
        bound_endex = that.bound_endex if that.bound_endex_ else ADDR_MAX
        if CannotSubAddrU(bound_endex, size):
            start = ADDR_MIN
        else:
            start = bound_endex - size

        if start < start_min:
            start = start_min

        content_endex = Memory_ContentEndex(that)
        Memory_Erase__(that, start, content_endex, False)  # clear


cdef vint Memory_PreboundEndex(Memory_* that, object start_min, object size) except -1:
        cdef:
            addr_t start_min_ = ADDR_MIN if start_min is None else <addr_t>start_min

        Memory_PreboundEndex_(that, start_min_, <addr_t>size)


cdef vint Memory_Crop_(Memory_* that, addr_t start, addr_t endex) except -1:
    cdef:
        addr_t block_start
        addr_t block_endex

    # Bound blocks exceeding before memory start
    if Rack_Bool(that.blocks):
        block_start = Block_Start(Rack_First_(that.blocks))

        if block_start < start:
            Memory_Erase__(that, block_start, start, False)  # clear

    # Bound blocks exceeding after memory end
    if Rack_Bool(that.blocks):
        block_endex = Block_Endex(Rack_Last_(that.blocks))

        if endex < block_endex:
            Memory_Erase__(that, endex, block_endex, False)  # clear


cdef vint Memory_Crop(Memory_* that, object start, object endex) except -1:
    cdef:
        addr_t start_
        addr_t endex_

    start_, endex_ = Memory_Bound(that, start, endex)
    Memory_Crop_(that, start_, endex_)


cdef vint Memory_WriteSame_(Memory_* that, addr_t address, const Memory_* data, bint clear) except -1:
    cdef:
        addr_t start = Memory_Start(data)
        addr_t endex = Memory_Endex(data)
        addr_t size = endex - start
        addr_t delta

        addr_t bound_start
        addr_t bound_endex
        bint bound_start_
        bint bound_endex_

        const Rack_* blocks
        size_t block_count
        size_t block_index
        const Block_* block
        addr_t block_start
        addr_t block_endex
        size_t block_size
        size_t block_offset

    if not size:
        return 0

    blocks = data.blocks
    block_count = Rack_Length(blocks)
    if block_count:
        CheckAddAddrU(Block_Endex(Rack_Last__(blocks)), address)

    CheckAddAddrU(endex, address)
    endex += address
    bound_start_ = that.bound_start_
    bound_start = that.bound_start

    if bound_start_ and endex <= bound_start:
        return 0

    CheckAddAddrU(start, address)
    start += address
    bound_endex_ = that.bound_endex_
    bound_endex = that.bound_endex

    if bound_endex_ and bound_endex <= start:
        return 0

    if clear:
        # Clear anything between source data boundaries
        Memory_Erase__(that, start, endex, False)  # clear
    else:
        # Clear only overwritten ranges
        for block_index in range(block_count):
            block = Rack_Get__(blocks, block_index)
            block_start = Block_Start(block) + address
            block_endex = Block_Endex(block) + address
            Memory_Erase__(that, block_start, block_endex, False)  # clear

    for block_index in range(block_count):
        block = Rack_Get__(blocks, block_index)

        block_endex = Block_Endex(block) + address
        if bound_start_ and block_endex <= bound_start:
            continue

        block_start = Block_Start(block) + address
        if bound_endex_ and bound_endex <= block_start:
            break

        block_size = block_endex - block_start
        block_offset = 0

        # Bound before memory
        if bound_start_ and block_start < bound_start:
            delta = bound_start - block_start
            CheckAddrToSizeU(delta)
            block_start += <size_t>delta
            block_size  -= <size_t>delta
            block_offset = <size_t>delta

        # Bound after memory
        if bound_endex_ and bound_endex < block_endex:
            delta = block_endex - bound_endex
            CheckAddrToSizeU(delta)
            block_endex -= <size_t>delta
            block_size  -= <size_t>delta

        Memory_Place__(that, block_start, block_size, Block_At__(block, block_offset), False)  # write


cdef vint Memory_WriteMemory_(Memory_* that, addr_t address, object data, bint clear) except -1:
    cdef:
        addr_t data_start = <addr_t>data.start
        addr_t data_endex = <addr_t>data.endex
        addr_t start
        addr_t endex
        addr_t size
        addr_t offset
        object block_start
        object block_data
        object block_size
        addr_t block_start_
        addr_t block_endex_
        addr_t block_size_
        const byte_t[:] block_view
        size_t block_offset

    CheckAddAddrU(data_start, address)
    CheckAddAddrU(data_endex, address)
    start = data_start + address
    endex = data_endex + address
    size = endex - start

    if not size:
        return 0

    if that.bound_start_ and endex <= that.bound_start:
        return 0

    if that.bound_endex_ and that.bound_endex <= start:
        return 0

    # Check shifted block bounds
    for block_start, block_data in data.blocks():
        block_start_ = <addr_t>block_start
        CheckAddAddrU(block_start_, address)
        block_start_ += address

        block_size = len(block_data)
        block_size_ = <addr_t>block_size
        CheckAddAddrU(block_start_, block_size_)

    if clear:
        # Clear anything between source data boundaries
        Memory_Erase__(that, start, endex, False)  # clear
    else:
        # Clear only overwritten ranges
        for block_start, block_data in data.blocks():
            block_start_ = <addr_t>block_start
            block_start_ += address

            block_size = len(block_data)
            block_size_ = <addr_t>block_size
            block_endex_ = block_start_ + block_size_

            Memory_Erase__(that, block_start_, block_endex_, False)  # clear

    for block_start, block_data in data.blocks():
        block_start_ = <addr_t>block_start
        block_start_ += address

        block_size = len(block_data)
        block_size_ = <addr_t>block_size
        block_endex_ = block_start_ + block_size_

        if that.bound_start_ and block_endex_ <= that.bound_start:
            continue
        if that.bound_endex_ and that.bound_endex <= block_start_:
            break

        block_view = block_data
        block_offset = 0

        # Bound before memory
        if that.bound_start_ and block_start_ < that.bound_start:
            offset = that.bound_start - block_start_
            block_start_ += offset
            CheckAddrToSizeU(offset)
            block_offset = <size_t>offset

        # Bound after memory
        if that.bound_endex_ and that.bound_endex < block_endex_:
            offset = block_endex_ - that.bound_endex
            block_endex_ -= offset

        block_size_ = block_endex_ - block_start_
        with cython.boundscheck(False):
            Memory_Place__(that, block_start_, block_size_, &block_view[block_offset], False)  # write


cdef vint Memory_WriteRaw_(Memory_* that, addr_t address, size_t data_size, const byte_t* data_ptr) except -1:
    cdef:
        addr_t size = data_size
        addr_t start
        addr_t endex
        addr_t offset

        addr_t bound_start
        addr_t bound_endex
        bint bound_start_
        bint bound_endex_

        Rack_* blocks
        size_t block_count
        Block_* block

    if not size:
        return 0
    elif size == 1:
        Memory_Poke(that, address, data_ptr[0])  # faster
        return 0

    CheckAddAddrU(address, size)
    start = address
    endex = start + size

    bound_start_ = that.bound_start_
    bound_start = that.bound_start
    if bound_start_ and endex <= bound_start:
        return 0

    bound_endex_ = that.bound_endex_
    bound_endex = that.bound_endex
    if bound_endex_ and bound_endex <= start:
        return 0

    # Bound before memory
    if bound_start_ and start < bound_start:
        offset = bound_start - start
        CheckAddrToSizeU(offset)
        start += offset
        size -= <size_t>offset
        data_ptr += <size_t>offset

    # Bound after memory
    if bound_endex_ and bound_endex < endex:
        offset = endex - bound_endex
        CheckAddrToSizeU(offset)
        endex -= offset
        size -= <size_t>offset

    # Check if extending the actual content
    CheckAddrToSizeU(size)
    blocks = that.blocks
    block_count = Rack_Length(blocks)
    if block_count:
        block = Rack_Last_(blocks)
        if start == Block_Endex(block):
            block = Block_Extend_(block, <size_t>size, data_ptr)  # might be faster
            Rack_Set__(blocks, block_count - 1, block)  # update pointer
            return 0

    # Standard write method
    Memory_Erase__(that, start, endex, False)  # clear
    Memory_Place__(that, start, <size_t>size, data_ptr, False)  # write
    return 0


cdef vint Memory_Write(Memory_* that, object address, object data, bint clear) except -1:
    cdef:
        addr_t address_ = <addr_t>address
        const byte_t[:] data_view
        byte_t data_value
        size_t data_size
        const byte_t* data_ptr

    if isinstance(data, Memory):
        Memory_WriteSame_(that, address_, (<Memory>data)._, clear)

    elif isinstance(data, ImmutableMemory):
        Memory_WriteMemory_(that, address_, data, clear)

    else:
        if isinstance(data, int):
            data_value = <byte_t>data
            data_size = 1
            data_ptr = &data_value
        else:
            data_view = data
            data_size = <size_t>len(data_view)
            with cython.boundscheck(False):
                data_ptr = &data_view[0]

        Memory_WriteRaw_(that, address_, data_size, data_ptr)


cdef vint Memory_Fill_(Memory_* that, addr_t start, addr_t endex, Block_** pattern, addr_t start_) except -1:
    cdef:
        size_t offset
        size_t size

    if start < endex:
        CheckAddrToSizeU(endex - start)
        if not Block_Bool(pattern[0]):
            raise ValueError('non-empty pattern required')

        if start > start_:
            offset = start - start_
            CheckAddrToSizeU(offset)
            Block_RotateLeft_(pattern[0], <size_t>offset)

        # Resize the pattern to the target range
        size = <size_t>(endex - start)
        pattern[0] = Block_RepeatToSize(pattern[0], size)

        # Standard write method
        Memory_Erase__(that, start, endex, False)  # clear
        Memory_Place__(that, start, size, Block_At__(pattern[0], 0), False)  # write


cdef vint Memory_Fill(Memory_* that, object start, object endex, object pattern) except -1:
        cdef:
            addr_t start__
            addr_t start_
            addr_t endex_
            Block_* pattern_ = NULL

        start_, endex_ = Memory_Bound(that, start, endex)
        if start_ < endex_:
            pattern_ = Block_FromObject(0, pattern, False)  # size checked later on
            try:
                start__ = Memory_Start(that) if start is None else <addr_t>start
                Memory_Fill_(that, start_, endex_, &pattern_, start__)
            finally:
                Block_Free(pattern_)  # orphan


cdef vint Memory_Flood_(Memory_* that, addr_t start, addr_t endex, Block_** pattern) except -1:
    cdef:
        Rack_* blocks
        const Block_* block
        addr_t block_start
        addr_t block_endex
        size_t block_index_start
        size_t block_index_endex
        addr_t offset

    if start < endex:
        blocks = that.blocks
        block_index_start = Rack_IndexStart(blocks, start)

        # Check if touching previous block
        if block_index_start:
            block = Rack_Get__(blocks, block_index_start - 1)
            block_start = Block_Start(block)
            block_endex = Block_Endex(block)
            if block_endex == start:
                block_index_start -= 1

        # Manage block near start
        if block_index_start < Rack_Length(blocks):
            block = Rack_Get__(blocks, block_index_start)
            block_start = Block_Start(block)
            block_endex = Block_Endex(block)

            if block_start <= start and endex <= block_endex:
                return 0  # no emptiness to flood

            if block_start < start:
                offset = start - block_start
                CheckAddrToSizeU(offset)
                Block_RotateRight_(pattern[0], <size_t>offset)
                start = block_start

        # Manage block near end
        block_index_endex = Rack_IndexEndex(blocks, endex)
        if block_index_start < block_index_endex:
            block = Rack_Get__(blocks, block_index_endex - 1)
            block_start = Block_Start(block)
            block_endex = Block_Endex(block)
            if endex < block_endex:
                endex = block_endex

        CheckAddrToSizeU(endex - start)
        if not Block_Bool(pattern[0]):
            raise ValueError('non-empty pattern required')

        size = <size_t>(endex - start)
        pattern[0] = Block_RepeatToSize(pattern[0], size)
        pattern[0].address = start

        for block_index in range(block_index_start, block_index_endex):
            block = Rack_Get__(blocks, block_index)
            offset = Block_Start(block) - start
            # CheckAddrToSizeU(offset)  # implied
            pattern[0] = Block_Write_(pattern[0], <size_t>offset, Block_Length(block), Block_At__(block, 0))

        that.blocks = blocks = Rack_DelSlice_(blocks, block_index_start, block_index_endex)
        that.blocks = blocks = Rack_Insert_(blocks, block_index_start, pattern[0])


cdef vint Memory_Flood(Memory_* that, object start, object endex, object pattern) except -1:
        cdef:
            addr_t start_
            addr_t endex_
            Block_* pattern_ = NULL

        start_, endex_ = Memory_Bound(that, start, endex)
        if start_ < endex_:
            pattern_ = Block_FromObject(0, pattern, False)  # size checked later on
            try:
                Memory_Flood_(that, start_, endex_, &pattern_)
            except:
                Block_Free(pattern_)  # orphan
                raise


# =====================================================================================================================

cdef Rover_* Rover_Alloc() except NULL:
    cdef:
        Rover_* that = <Rover_*>PyMem_Calloc(Rover_HEADING, 1)

    if that == NULL:
        raise MemoryError()
    return that


cdef Rover_* Rover_Free(Rover_* that) except? NULL:
    if that:
        Rover_Release(that)
        PyMem_Free(that)
    return NULL


cdef size_t Rover_Sizeof(const Rover_* that):
    if that:
        return Rover_HEADING
    return 0


cdef Rover_* Rover_Create(
    const Memory_* memory,
    addr_t start,
    addr_t endex,
    size_t pattern_size,
    const byte_t* pattern_data,
    bint forward,
    bint infinite,
) except NULL:
    cdef:
        Block_* block = NULL
        addr_t offset
        size_t pattern_offset

    if forward:
        if endex < start:
            endex = start
    else:
        if start > endex:
            start = endex

    if (not pattern_data) != (not pattern_size):
        raise ValueError('non-empty pattern required')

    if pattern_size and not forward:
        with cython.cdivision(True):
            pattern_offset = <size_t>((endex - start) % pattern_size)
    else:
        pattern_offset = 0

    that = Rover_Alloc()

    that.forward = forward
    that.infinite = infinite
    that.start = start
    that.endex = endex
    that.address = start if forward else endex

    that.pattern_size = pattern_size
    that.pattern_data = pattern_data
    that.pattern_offset = pattern_offset

    that.memory = memory
    that.block_count = Rack_Length(memory.blocks)

    try:
        if that.block_count:
            if forward:
                that.block_index = Rack_IndexStart(memory.blocks, start)
                if that.block_index < that.block_count:
                    block = Rack_Get_(memory.blocks, that.block_index)
                    that.block_start = Block_Start(block)
                    that.block_endex = Block_Endex(block)

                    offset = start if start >= that.block_start else that.block_start
                    if offset > that.block_endex:
                        offset = that.block_endex
                    offset -= that.block_start
                    CheckAddrToSizeU(offset)

                    block = Block_Acquire(block)
                    that.block = block
                    that.block_ptr = Block_At__(block, <size_t>offset)
            else:
                that.block_index = Rack_IndexEndex(memory.blocks, endex)
                if that.block_index:
                    block = Rack_Get_(memory.blocks, that.block_index - 1)
                    that.block_start = Block_Start(block)
                    that.block_endex = Block_Endex(block)

                    offset = endex if endex >= that.block_start else that.block_start
                    if offset > that.block_endex:
                        offset = that.block_endex
                    offset -= that.block_start
                    CheckAddrToSizeU(offset)

                    block = Block_Acquire(block)
                    that.block = block
                    that.block_ptr = Block_At__(block, <size_t>offset)
    except:
        that = Rover_Free(that)
        raise

    return that


cdef addr_t Rover_Length(const Rover_* that) nogil:
    return that.endex - that.start


cdef bint Rover_HasNext(const Rover_* that) nogil:
    if that.forward:
        return that.address < that.endex
    else:
        return that.address > that.start


cdef int Rover_Next_(Rover_* that) except -2:
    cdef:
        Block_* block = NULL
        int value = -1

    try:
        if that.forward:
            while True:  # loop to move to the next block when necessary
                if that.address < that.endex:
                    if that.block_index < that.block_count:
                        if that.address < that.block_start:
                            that.address += 1
                            if that.pattern_size:
                                value = <int><unsigned>that.pattern_data[that.pattern_offset]
                            else:
                                value = -1
                            break

                        elif that.address < that.block_endex:
                            that.address += 1
                            value = that.block_ptr[0]
                            that.block_ptr += 1
                            break

                        else:
                            that.block_index += 1
                            if that.block_index < that.block_count:
                                that.block = Block_Release(that.block)
                                that.block = NULL
                                block = Rack_Get_(that.memory.blocks, that.block_index)
                                block = Block_Acquire(block)
                                that.block = block
                                that.block_start = Block_Start(block)
                                that.block_endex = Block_Endex(block)
                                that.block_ptr = Block_At_(block, 0)
                            continue
                    else:
                        that.address += 1
                        if that.pattern_size:
                            value = <int><unsigned>that.pattern_data[that.pattern_offset]
                        else:
                            value = -1
                        break

                elif that.infinite:
                    if that.pattern_size:
                        value = <int><unsigned>that.pattern_data[that.pattern_offset]
                    else:
                        value = -1

                else:
                    raise StopIteration()

            if that.pattern_size:
                if that.pattern_offset < that.pattern_size - 1:
                    that.pattern_offset += 1
                else:
                    that.pattern_offset = 0
        else:
            if that.pattern_size:
                if that.pattern_offset > 0:
                    that.pattern_offset -= 1
                else:
                    that.pattern_offset = that.pattern_size - 1

            while True:  # loop to move to the next block when necessary
                if that.address > that.start:
                    if that.block_index:
                        if that.address > that.block_endex:
                            that.address -= 1
                            if that.pattern_size:
                                value = <int><unsigned>that.pattern_data[that.pattern_offset]
                            else:
                                value = -1
                            break

                        elif that.address > that.block_start:
                            that.address -= 1
                            that.block_ptr -= 1
                            value = that.block_ptr[0]
                            break

                        else:
                            that.block_index -= 1
                            if that.block_index:
                                that.block = Block_Release(that.block)
                                that.block = NULL
                                block = Rack_Get_(that.memory.blocks, that.block_index - 1)
                                block = Block_Acquire(block)
                                that.block = block
                                that.block_start = Block_Start(block)
                                that.block_endex = Block_Endex(block)
                                that.block_ptr = Block_At__(block, Block_Length(block))
                            value = -1
                            continue
                    else:
                        that.address -= 1
                        if that.pattern_size:
                            value = <int><unsigned>that.pattern_data[that.pattern_offset]
                        else:
                            value = -1
                        break

                elif that.infinite:
                    if that.pattern_size:
                        value = <int><unsigned>that.pattern_data[that.pattern_offset]
                    else:
                        value = -1

                else:
                    raise StopIteration()

        return value

    except:
        that.block = Block_Release(that.block)  # preempt
        raise


cdef object Rover_Next(Rover_* that):
    cdef:
        int value = Rover_Next_(that)

    return None if value < 0 else <object>value


cdef vint Rover_Release(Rover_* that) except -1:
    that.address = that.endex if that.forward else that.start
    that.block = Block_Release(that.block)
    that.memory = NULL


cdef bint Rover_Forward(const Rover_* that) nogil:
    return that.forward


cdef bint Rover_Infinite(const Rover_* that) nogil:
    return that.infinite


cdef addr_t Rover_Address(const Rover_* that) nogil:
    return that.address


cdef addr_t Rover_Start(const Rover_* that) nogil:
    return that.start


cdef addr_t Rover_Endex(const Rover_* that) nogil:
    return that.endex


# =====================================================================================================================

cdef class Memory:

    def __add__(
        self: Memory,
        value: Union[AnyBytes, ImmutableMemory],
    ) -> _MemorySelf:
        cdef:
            Memory_* memory_ = Memory_Add(self._, value)
            Memory memory = Memory_AsObject(memory_)

        return memory

    def __bool__(
        self: Memory,
    ) -> bool:

        return Memory_Bool(self._)

    def __bytes__(
        self: Memory,
    ) -> bytes:
        cdef:
            const Memory_* memory = self._
            addr_t start = Memory_Start(memory)
            addr_t endex = Memory_Endex(memory)
            BlockView view = Memory_View_(memory, start, endex)
            bytes data

        try:
            data = view.__bytes__()
        finally:
            view.release_()
        return data

    def __cinit__(self):
        r"""Cython constructor."""
        self._ = NULL

    def __contains__(
        self: Memory,
        item: Union[AnyBytes, Value],
    ) -> bool:

        return Memory_Contains(self._, item)

    def __copy__(
        self: Memory,
    ) -> _MemorySelf:
        cdef:
            Memory_* memory_ = Memory_Copy(self._)
            Memory memory = Memory_AsObject(memory_)

        return memory

    def __dealloc__(self):
        r"""Cython deallocation method."""
        self._ = Memory_Free(self._)

    def __deepcopy__(
        self: Memory,
    ) -> _MemorySelf:
        cdef:
            Memory_* memory_ = Memory_Copy(self._)
            Memory memory = Memory_AsObject(memory_)

        return memory

    def __delitem__(
        self: Memory,
        key: Union[Address, slice],
    ) -> None:

        Memory_DelItem(self._, key)

    def __eq__(
        self: Memory,
        other: Any,
    ) -> bool:

        return Memory_Eq(self._, other)

    def __getitem__(
        self: Memory,
        key: Union[Address, slice],
    ) -> Any:

        return Memory_GetItem(self._, key)

    def __iadd__(
        self: Memory,
        value: Union[AnyBytes, ImmutableMemory],
    ) -> _MemorySelf:

        Memory_IAdd(self._, value)
        return self

    def __imul__(
        self: Memory,
        times: int,
    ) -> _MemorySelf:
        cdef:
            addr_t times_ = 0 if times < 0 else <addr_t>times

        Memory_IMul(self._, times_)
        return self

    def __init__(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ):

        self._ = Memory_Create(start, endex)

    def __iter__(
        self: Memory,
    ) -> Iterator[Optional[Value]]:

        yield from self.values()

    def __len__(
        self: Memory,
    ) -> Address:

        return Memory_Length(self._)

    def __mul__(
        self: Memory,
        times: int,
    ) -> _MemorySelf:
        cdef:
            addr_t times_ = 0 if times < 0 else <addr_t>times
            Memory_* memory_ = Memory_Mul(self._, times_)
            Memory memory = Memory_AsObject(memory_)

        return memory

    def __repr__(
        self: Memory,
    ) -> str:

        return f'<{type(self).__name__}[0x{self.start:X}:0x{self.endex:X}]@0x{id(self):X}>'

    def __reversed__(
        self: Memory,
    ) -> Iterator[Optional[Value]]:

        yield from self.rvalues()

    def __setitem__(
        self: Memory,
        key: Union[Address, slice],
        value: Optional[Union[AnyBytes, Value, ImmutableMemory]],
    ) -> None:

        Memory_SetItem(self._, key, value)

    def __sizeof__(
        self: Memory,
    ) -> int:

        return sizeof(Memory) + Memory_Sizeof(self._)

    def __str__(
        self: Memory,
    ) -> str:
        cdef:
            const Memory_* memory = self._
            addr_t size = Memory_ContentSize(memory)
            addr_t start
            addr_t endex
            const Rack_* blocks
            size_t block_index
            const Block_* block
            list inner_list

        if size < STR_MAX_CONTENT_SIZE:
            bound_start = f'{memory.bound_start}, ' if memory.bound_start_ else ''
            bound_endex = f', {memory.bound_endex}' if memory.bound_endex_ else ''

            inner_list = []
            blocks = memory.blocks

            for block_index in range(Rack_Length(blocks)):
                block = Rack_Get__(blocks, block_index)
                inner_list.append(f'[{Block_Start(block)}, {Block_Bytes(block)!r}]')

            inner = ', '.join(inner_list)

            return f'<{bound_start}[{inner}]{bound_endex}>'
        else:
            return repr(self)

    def _block_index_at(
        self: Memory,
        address: Address,
    ) -> Optional[BlockIndex]:
        cdef:
            ssize_t block_index

        block_index = Rack_IndexAt(self._.blocks, address)
        return None if block_index < 0 else block_index

    def _block_index_endex(
        self: Memory,
        address: Address,
    ) -> BlockIndex:

        return Rack_IndexEndex(self._.blocks, address)

    def _block_index_start(
        self: Memory,
        address: Address,
    ) -> BlockIndex:

        return Rack_IndexStart(self._.blocks, address)

    def _prebound_endex(
        self: Memory,
        start_min: Optional[Address],
        size: Address,
    ) -> None:

        Memory_PreboundEndex(self._, start_min, size)

    def _prebound_endex_backup(
        self: Memory,
        start_min: Optional[Address],
        size: Address,
    ) -> _MemorySelf:
        cdef:
            addr_t start_min_
            addr_t size_ = <addr_t>size
            const Memory_* memory = self._
            addr_t start

        if memory.bound_endex_ and size_ > 0:
            start = memory.bound_endex
            CheckSubAddrU(start, size)
            start -= size
            if start_min is not None:
                start_min_ = <addr_t>start_min
                if start < start_min_:
                    start = start_min_
            return Memory_Extract_(memory, start, Memory_Endex(memory), 0, NULL, 1, True)
        else:
            return Memory()

    def _prebound_start(
        self: Memory,
        endex_max: Optional[Address],
        size: Address,
    ) -> None:

        Memory_PreboundStart(self._, endex_max, size)

    def _prebound_start_backup(
        self: Memory,
        endex_max: Optional[Address],
        size: Address,
    ) -> _MemorySelf:
        cdef:
            addr_t endex_max_
            addr_t size_ = <addr_t>size
            const Memory_* memory = self._
            addr_t endex

        if memory.bound_start_ and size_ > 0:
            endex = memory.bound_start
            CheckAddAddrU(endex, size)
            endex += size
            if endex_max is not None:
                endex_max_ = <addr_t>endex_max
                if endex > endex_max_:
                    endex = endex_max_
            return Memory_Extract_(memory, Memory_Start(memory), endex, 0, NULL, 1, True)
        else:
            return Memory()

    def append(
        self: Memory,
        item: Union[AnyBytes, Value],
    ) -> None:

        return Memory_Append(self._, item)

    # noinspection PyMethodMayBeStatic
    def append_backup(
        self: Memory,
    ) -> None:

        return None

    def append_restore(
        self: Memory,
    ) -> None:

        Memory_PopLast_(self._)

    def block_span(
        self: Memory,
        address: Address,
    ) -> Tuple[Optional[Address], Optional[Address], Optional[Value]]:
        cdef:
            addr_t address_ = <addr_t>address
            const Rack_* blocks = self._.blocks
            size_t block_count = Rack_Length(blocks)
            size_t block_index
            const Block_* block
            addr_t block_start
            addr_t block_endex
            byte_t value

        block_index = Rack_IndexStart(blocks, address_)

        if block_index < block_count:
            block = Rack_Get__(blocks, block_index)
            block_start = Block_Start(block)
            block_endex = Block_Endex(block)

            if block_start <= address_ < block_endex:
                # Address within a block
                CheckSubAddrU(address_, block_start)
                CheckAddrToSizeU(address_ - block_start)
                value = Block_Get__(block, <size_t>(address_ - block_start))
                return block_start, block_endex, value  # block span

            elif block_index:
                # Address within a gap
                block_endex = block_start  # end gap before next block
                block = Rack_Get__(blocks, block_index - 1)
                block_start = Block_Endex(block)  # start gap after previous block
                return block_start, block_endex, None  # gap span

            else:
                # Address before content
                return None, block_start, None  # open left

        else:
            # Address after content
            if block_count:
                block = Rack_Last__(blocks)
                block_start = Block_Start(block)
                block_endex = Block_Endex(block)
                return block_endex, None, None  # open right

            else:
                return None, None, None  # fully open
    def blocks(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Iterator[Tuple[Address, memoryview]]:
        cdef:
            addr_t start_
            addr_t endex_
            const Rack_* blocks = self._.blocks
            size_t block_count = Rack_Length(blocks)
            size_t block_index
            size_t block_index_start
            size_t block_index_endex
            Block_* block
            addr_t block_start
            addr_t block_endex
            addr_t slice_start
            addr_t slice_endex
            BlockView slice_view

        if block_count:
            if start is None and endex is None:  # faster
                for block_index in range(block_count):
                    block = Rack_Get__(blocks, block_index)
                    yield Block_Start(block), Block_View(block)
            else:
                block_index_start = 0 if start is None else Rack_IndexStart(blocks, start)
                block_index_endex = block_count if endex is None else Rack_IndexEndex(blocks, endex)
                start_, endex_ = Memory_Bound(self._, start, endex)

                for block_index in range(block_index_start, block_index_endex):
                    block = Rack_Get__(blocks, block_index)
                    block_start = Block_Start(block)
                    block_endex = Block_Endex(block)
                    slice_start = block_start if start_ < block_start else start_
                    slice_endex = endex_ if endex_ < block_endex else block_endex
                    if slice_start < slice_endex:
                        slice_start -= block_start
                        slice_endex -= block_start
                        slice_view = Block_ViewSlice_(block, <size_t>slice_start, <size_t>slice_endex)
                        yield (block_start + slice_start), slice_view

    def bound(
        self: Memory,
        start: Optional[Address],
        endex: Optional[Address],
    ) -> ClosedInterval:

        return Memory_Bound(self._, start, endex)

    @property
    def bound_endex(
        self: Memory,
    ) -> Optional[Address]:

        return Memory_GetBoundEndex(self._)

    @bound_endex.setter
    def bound_endex(
        self: Memory,
        bound_endex: Address,
    ) -> None:

        Memory_SetBoundEndex(self._, bound_endex)

    @property
    def bound_span(
        self: Memory,
    ) -> OpenInterval:

        return Memory_GetBoundSpan(self._)

    @bound_span.setter
    def bound_span(
        self: Memory,
        bound_span: Optional[OpenInterval],
    ) -> None:

        Memory_SetBoundSpan(self._, bound_span)

    @property
    def bound_start(
        self: Memory,
    ) -> Optional[Address]:

        return Memory_GetBoundStart(self._)

    @bound_start.setter
    def bound_start(
        self: Memory,
        bound_start: Address,
    ) -> None:

        Memory_SetBoundStart(self._, bound_start)

    def clear(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> None:

        Memory_Clear(self._, start, endex)

    def clear_backup(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> _MemorySelf:
        cdef:
            const Memory_* memory = self._
            addr_t start_ = Memory_Start(memory) if start is None else <addr_t>start
            addr_t endex_ = Memory_Endex(memory) if endex is None else <addr_t>endex

        return Memory_Extract_(memory, start_, endex_, 0, NULL, 1, True)

    def clear_restore(
        self: Memory,
        backup: ImmutableMemory,
    ) -> None:

        Memory_Write(self._, 0, backup, True)

    @classmethod
    def collapse_blocks(
        cls,
        blocks: BlockIterable,
    ) -> BlockList:
        cdef:
            Memory_* memory = Memory_Alloc()
            list collapsed = []
            size_t block_index
            const Rack_* blocks2
            const Block_* block

        try:
            for block_start, block_data in blocks:
                Memory_Write(memory, block_start, block_data, True)
            blocks2 = memory.blocks

            for block_index in range(Rack_Length(blocks2)):
                block = Rack_Get__(blocks2, block_index)
                collapsed.append([Block_Start(block), Block_Bytes(block)])
        finally:
            Memory_Free(memory)

        return collapsed

    def content_blocks(
        self,
        block_index_start: Optional[BlockIndex] = None,
        block_index_endex: Optional[BlockIndex] = None,
        block_index_step: Optional[BlockIndex] = None,
    ) -> Iterator[Union[Tuple[Address, Union[memoryview, bytearray]], Block]]:
        cdef:
            const Rack_* blocks = self._.blocks
            ssize_t block_count = <ssize_t>Rack_Length(blocks)
            ssize_t block_index
            ssize_t block_index_start_
            ssize_t block_index_endex_
            ssize_t block_index_step_
            Block_* block

        if block_count:
            if block_index_start is None:
                block_index_start_ = 0
            else:
                if block_index_start < 0:
                    block_index_start += block_count
                    if block_index_start < 0:
                        block_index_start = 0
                block_index_start_ = <ssize_t>block_index_start
                if block_index_start_ > block_count:
                    block_index_start_ = block_count

            if block_index_endex is None:
                block_index_endex_ = block_count
            else:
                if block_index_endex < 0:
                    block_index_endex += block_count
                    if block_index_endex < 0:
                        block_index_endex = 0
                block_index_endex_ = <ssize_t>block_index_endex
                if block_index_endex_ > block_count:
                    block_index_endex_ = block_count

            if block_index_step is None:
                block_index_step_ = 1
            else:
                block_index_step_ = <ssize_t>block_index_step

            for block_index in range(block_index_start_, block_index_endex_, block_index_step_):
                block = Rack_Get__(blocks, <size_t>block_index)
                yield Block_Start(block), Block_View(block)

    @property
    def content_endex(
        self: Memory,
    ) -> Address:

        return Memory_ContentEndex(self._)

    @property
    def content_endin(
        self: Memory,
    ) -> Address:

        return Memory_ContentEndin(self._)

    def content_items(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Iterator[Tuple[Address, Value]]:
        cdef:
            addr_t start_
            addr_t endex_
            const Rack_* blocks = self._.blocks
            size_t block_count = Rack_Length(blocks)
            size_t block_index
            size_t block_index_start
            size_t block_index_endex
            const Block_* block
            addr_t block_start
            addr_t block_endex
            addr_t slice_start
            addr_t slice_endex
            addr_t address
            size_t offset

        if block_count:
            if start is None and endex is None:  # faster
                for block_index in range(block_count):
                    block = Rack_Get__(blocks, block_index)
                    block_start = Block_Start(block)
                    for offset in range(Block_Length(block)):
                        yield (block_start + offset), Block_Get__(block, offset)
            else:
                block_index_start = 0 if start is None else Rack_IndexStart(blocks, start)
                block_index_endex = block_count if endex is None else Rack_IndexEndex(blocks, endex)
                start_, endex_ = Memory_Bound(self._, start, endex)

                for block_index in range(block_index_start, block_index_endex):
                    block = Rack_Get__(blocks, block_index)
                    block_start = Block_Start(block)
                    block_endex = Block_Endex(block)
                    slice_start = block_start if start_ < block_start else start_
                    slice_endex = endex_ if endex_ < block_endex else block_endex
                    for address in range(slice_start, slice_endex):
                        offset = <size_t>(address - block_start)
                        yield address, Block_Get__(block, offset)

    def content_keys(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Iterator[Address]:
        cdef:
            addr_t start_
            addr_t endex_
            const Rack_* blocks = self._.blocks
            size_t block_count = Rack_Length(blocks)
            size_t block_index
            size_t block_index_start
            size_t block_index_endex
            const Block_* block
            addr_t block_start
            addr_t block_endex
            addr_t slice_start
            addr_t slice_endex
            addr_t address

        if block_count:
            if start is None and endex is None:  # faster
                for block_index in range(block_count):
                    block = Rack_Get__(blocks, block_index)
                    for address in range(Block_Start(block), Block_Endex(block)):
                        yield address
            else:
                block_index_start = 0 if start is None else Rack_IndexStart(blocks, start)
                block_index_endex = block_count if endex is None else Rack_IndexEndex(blocks, endex)
                start_, endex_ = Memory_Bound(self._, start, endex)

                for block_index in range(block_index_start, block_index_endex):
                    block = Rack_Get__(blocks, block_index)
                    block_start = Block_Start(block)
                    block_endex = Block_Endex(block)
                    slice_start = block_start if start_ < block_start else start_
                    slice_endex = endex_ if endex_ < block_endex else block_endex
                    for address in range(slice_start, slice_endex):
                        yield address

    @property
    def content_parts(
        self: Memory,
    ) -> int:

        return Memory_ContentParts(self._)

    @property
    def content_size(
        self: Memory,
    ) -> Address:

        return Memory_ContentSize(self._)

    @property
    def content_span(
        self: Memory,
    ) -> ClosedInterval:

        return Memory_ContentSpan(self._)

    @property
    def content_start(
        self: Memory,
    ) -> Address:

        return Memory_ContentStart(self._)

    def content_values(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Iterator[Value]:
        cdef:
            addr_t start_
            addr_t endex_
            const Rack_* blocks = self._.blocks
            size_t block_count = Rack_Length(blocks)
            size_t block_index
            size_t block_index_start
            size_t block_index_endex
            const Block_* block
            addr_t block_start
            addr_t block_endex
            addr_t slice_start
            addr_t slice_endex
            addr_t address
            size_t offset

        if block_count:
            if start is None and endex is None:  # faster
                for block_index in range(block_count):
                    block = Rack_Get__(blocks, block_index)
                    block_start = Block_Start(block)
                    for offset in range(Block_Length(block)):
                        yield Block_Get__(block, offset)
            else:
                block_index_start = 0 if start is None else Rack_IndexStart(blocks, start)
                block_index_endex = block_count if endex is None else Rack_IndexEndex(blocks, endex)
                start_, endex_ = Memory_Bound(self._, start, endex)

                for block_index in range(block_index_start, block_index_endex):
                    block = Rack_Get__(blocks, block_index)
                    block_start = Block_Start(block)
                    block_endex = Block_Endex(block)
                    slice_start = block_start if start_ < block_start else start_
                    slice_endex = endex_ if endex_ < block_endex else block_endex
                    for address in range(slice_start, slice_endex):
                        offset = <size_t>(address - block_start)
                        yield Block_Get__(block, offset)

    @property
    def contiguous(
        self: Memory,
    ) -> bool:

        return Memory_Contiguous(self._)

    def copy(
        self: Memory,
    ) -> _MemorySelf:

        return self.__deepcopy__()

    def count(
        self: Memory,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> int:

        return Memory_Count(self._, item, start, endex)

    def crop(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> None:

        Memory_Crop(self._, start, endex)

    def crop_backup(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Tuple[Optional[ImmutableMemory], Optional[ImmutableMemory]]:
        cdef:
            addr_t start_
            addr_t endex_
            const Memory_* memory = self._
            const Rack_* blocks = memory.blocks
            addr_t block_start
            addr_t block_endex
            Memory backup_start = None
            Memory backup_endex = None

        if Rack_Bool(blocks):
            if start is not None:
                start_ = <addr_t>start
                block_start = Block_Start(Rack_First__(blocks))
                if block_start < start_:
                    backup_start = Memory_Extract_(memory, block_start, start_, 0, NULL, 1, True)

            if endex is not None:
                endex_ = <addr_t>endex
                block_endex = Block_Endex(Rack_Last__(blocks))
                if endex_ < block_endex:
                    backup_endex = Memory_Extract_(memory, endex_, block_endex, 0, NULL, 1, True)

        return backup_start, backup_endex

    def crop_restore(
        self: Memory,
        backup_start: Optional[ImmutableMemory],
        backup_endex: Optional[ImmutableMemory],
    ) -> None:

        if backup_start is not None:
            Memory_Write(self._, 0, backup_start, True)
        if backup_endex is not None:
            Memory_Write(self._, 0, backup_endex, True)

    def cut(
        self,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        bound: bool = True,
    ) -> _MemorySelf:

        return Memory_Cut(self._, start, endex, bound)

    def delete(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> None:

        Memory_Delete(self._, start, endex)

    def delete_backup(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> _MemorySelf:
        cdef:
            const Memory_* memory = self._
            addr_t start_ = Memory_Start(memory) if start is None else <addr_t>start
            addr_t endex_ = Memory_Endex(memory) if endex is None else <addr_t>endex

        return Memory_Extract_(memory, start_, endex_, 0, NULL, 1, True)

    def delete_restore(
        self: Memory,
        backup: ImmutableMemory,
    ) -> None:
        cdef:
            Memory_* memory = self._
            const Memory_* backup_

        if isinstance(backup, Memory):
            backup_ = (<Memory>backup)._
            Memory_Reserve_(memory, Memory_Start(backup_), Memory_Length(backup_))
            Memory_WriteSame_(memory, 0, backup_, True)
        else:
            Memory_Reserve(memory, backup.start, len(backup))
            Memory_Write(memory, 0, backup, True)

    @property
    def endex(
        self: Memory,
    ) -> Address:

        return Memory_Endex(self._)

    @property
    def endin(
        self: Memory,
    ) -> Address:

        return Memory_Endin(self._)

    def equal_span(
        self: Memory,
        address: Address,
    ) -> Tuple[Optional[Address], Optional[Address], Optional[Value]]:
        cdef:
            const Rack_* blocks = self._.blocks
            size_t block_count = Rack_Length(blocks)
            size_t block_index
            size_t block_index_start
            size_t block_index_endex
            const Block_* block
            addr_t block_start
            addr_t block_endex
            addr_t address_ = <addr_t>address
            addr_t start
            addr_t endex
            size_t offset
            byte_t value

        block_index = Rack_IndexStart(blocks, address_)

        if block_index < block_count:
            block = Rack_Get__(blocks, block_index)
            block_start = Block_Start(block)
            block_endex = Block_Endex(block)

            if block_start <= address_ < block_endex:
                # Address within a block
                CheckSubAddrU(address_, block_start)
                CheckAddrToSizeU(address - block_start)
                offset = <size_t>(address_ - block_start)
                start = offset
                CheckAddAddrU(offset, 1)
                endex = offset + 1
                value = Block_Get__(block, offset)

                for start in range(start + 1, 0, -1):
                    if Block_Get__(block, start - 1) != value:
                        break
                else:
                    start = 0

                for endex in range(endex, Block_Length(block)):
                    if Block_Get__(block, endex) != value:
                        break
                else:
                    endex = Block_Length(block)

                block_endex = block_start + endex
                block_start = block_start + start
                return block_start, block_endex, value  # equal data span

            elif block_index:
                # Address within a gap
                block_endex = block_start  # end gap before next block
                block = Rack_Get__(blocks, block_index - 1)
                block_start = Block_Endex(block)  # start gap after previous block
                return block_start, block_endex, None  # gap span

            else:
                # Address before content
                return None, block_start, None  # open left

        else:
            # Address after content
            if block_count:
                block = Rack_Last__(blocks)
                block_start = Block_Start(block)
                block_endex = Block_Endex(block)
                return block_endex, None, None  # open right

            else:
                return None, None, None  # fully open

    def extend(
        self: Memory,
        items: Union[AnyBytes, ImmutableMemory],
        offset: Address = 0,
    ) -> None:

        return Memory_Extend(self._, items, offset)

    def extend_backup(
        self: Memory,
        offset: Address = 0,
    ) -> Address:

        if offset < 0:
            raise ValueError('negative extension offset')
        return Memory_ContentEndex(self._) + <addr_t>offset

    def extend_restore(
        self: Memory,
        content_endex: Address,
    ) -> None:

        Memory_Clear_(self._, <addr_t>content_endex, ADDR_MAX)

    def extract(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        pattern: Optional[Union[AnyBytes, Value]] = None,
        step: Optional[Address] = None,
        bound: bool = True,
    ) -> _MemorySelf:

        return Memory_Extract(self._, start, endex, pattern, step, bound)

    def fill(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        pattern: Union[AnyBytes, Value] = 0,
    ) -> None:

        Memory_Fill(self._, start, endex, pattern)

    def fill_backup(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> _MemorySelf:
        cdef:
            const Memory_* memory = self._
            addr_t start_ = Memory_Start(memory) if start is None else <addr_t>start
            addr_t endex_ = Memory_Endex(memory) if endex is None else <addr_t>endex

        return Memory_Extract_(memory, start_, endex_, 0, NULL, 1, True)

    def fill_restore(
        self: Memory,
        backup: ImmutableMemory,
    ) -> None:

        Memory_Write(self._, 0, backup, True)

    def find(
        self: Memory,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Address:

        return Memory_Find(self._, item, start, endex)

    def flood(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        pattern: Union[AnyBytes, Value] = 0,
    ) -> None:

        Memory_Flood(self._, start, endex, pattern)

    def flood_backup(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> List[OpenInterval]:

        return list(self.gaps(start, endex))

    def flood_restore(
        self: Memory,
        gaps: List[OpenInterval],
    ) -> None:
        cdef:
            Memory_* memory = self._

        for gap_start, gap_endex in gaps:
            Memory_Clear(memory, gap_start, gap_endex)

    @classmethod
    def from_blocks(
        cls: Type[Memory],
        blocks: BlockList,
        offset: Address = 0,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        copy: bool = True,
        validate: bool = True,
    ) -> _MemorySelf:
        cdef:
            Memory_* memory_ = Memory_FromBlocks(blocks, offset, start, endex, validate)

        return Memory_AsObject(memory_)

    @classmethod
    def from_bytes(
        cls: Type[Memory],
        data: AnyBytes,
        offset: Address = 0,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        copy: bool = True,
        validate: bool = True,
    ) -> _MemorySelf:
        cdef:
            Memory_* memory_ = Memory_FromBytes(data, offset, start, endex)

        return Memory_AsObject(memory_)

    @classmethod
    def from_items(
        cls: Type[Memory],
        items: Union[AddressValueMapping,
                     Iterable[Tuple[Address, Optional[Value]]],
                     Mapping[Address, Optional[Union[Value, AnyBytes]]],
                     ImmutableMemory],
        offset: Address = 0,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        validate: bool = True,
    ) -> _MemorySelf:
        cdef:
            Memory_* memory_ = Memory_FromItems(items, offset, start, endex, validate)

        return Memory_AsObject(memory_)

    @classmethod
    def from_memory(
        cls: Type[Memory],
        memory: ImmutableMemory,
        offset: Address = 0,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        copy: bool = True,
        validate: bool = True,
    ) -> _MemorySelf:
        cdef:
            Memory_* memory_ = Memory_FromMemory(memory, offset, start, endex, validate)

        return Memory_AsObject(memory_)

    @classmethod
    def from_values(
        cls: Type[Memory],
        values: Iterable[Optional[Value]],
        offset: Address = 0,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        validate: bool = True,
    ) -> _MemorySelf:
        cdef:
            Memory_* memory_ = Memory_FromValues(values, offset, start, endex, validate)

        return Memory_AsObject(memory_)

    @classmethod
    def fromhex(
        cls,
        string: str,
    ) -> _MemorySelf:
        cdef:
            Memory_* memory_ = Memory_FromBytes(bytes.fromhex(string), 0, None, None)

        return Memory_AsObject(memory_)

    def gaps(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Iterator[OpenInterval]:
        cdef:
            addr_t start_
            addr_t endex_
            const Rack_* blocks = self._.blocks
            size_t block_count = Rack_Length(blocks)
            size_t block_index
            size_t block_index_start
            size_t block_index_endex
            const Block_* block
            addr_t block_start
            addr_t block_endex

        if block_count:
            start__ = start
            endex__ = endex
            start_, endex_ = Memory_Bound(self._, start, endex)

            if start__ is None:
                block = Rack_First__(blocks)
                start_ = Block_Start(block)  # override bound start
                yield None, start_
                block_index_start = 0
            else:
                block_index_start = Rack_IndexStart(blocks, start_)

            if endex__ is None:
                block_index_endex = block_count
            else:
                block_index_endex = Rack_IndexEndex(blocks, endex_)

            for block_index in range(block_index_start, block_index_endex):
                block = Rack_Get__(blocks, block_index)
                block_start = Block_Start(block)
                if start_ < block_start:
                    yield start_, block_start
                start_ = Block_Endex(block)

            if endex__ is None:
                yield start_, None
            elif start_ < endex_:
                yield start_, endex_

        else:
            yield None, None

    def get(
        self: Memory,
        address: Address,
        default: Optional[Value] = None,
    ) -> Optional[Value]:
        cdef:
            addr_t address_ = <addr_t>address
            const Memory_* memory = self._
            const Rack_* blocks = memory.blocks
            ssize_t block_index = Rack_IndexAt(blocks, address_)
            const Block_* block

        if block_index < 0:
            return default
        else:
            block = Rack_Get__(blocks, <size_t>block_index)
            return Block_Get__(block, <size_t>(address_ - Block_Start(block)))

    def hex(
        self: Memory,
        *args: Any,  # see docstring
    ) -> str:
        cdef:
            const Memory_* memory = self._
            bytes data

        if not Rack_Bool(memory.blocks):
            return ''

        data = self.__bytes__()
        return data.hex(*args)

    def index(
        self: Memory,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Address:

        return Memory_Index(self._, item, start, endex)

    def insert(
        self: Memory,
        address: Address,
        data: Union[AnyBytes, Value, ImmutableMemory],
    ) -> None:

        Memory_Insert(self._, address, data)

    def insert_backup(
        self: Memory,
        address: Address,
        data: Union[AnyBytes, Value, ImmutableMemory],
    ) -> Tuple[Address, ImmutableMemory]:

        size = 1 if isinstance(data, int) else len(data)
        backup = self._prebound_endex_backup(address, size)
        return address, backup

    def insert_restore(
        self: Memory,
        address: Address,
        backup: ImmutableMemory,
    ) -> None:
        cdef:
            Memory_* memory = self._
            const Memory_* backup_
            addr_t address_ = <addr_t>address
            addr_t size

        if isinstance(backup, Memory):
            backup_ = (<Memory>backup)._
            size = Memory_Length(backup_)
            CheckAddAddrU(address_, size)
            Memory_Delete_(memory, address_, address_ + size)
            Memory_WriteSame_(memory, 0, backup_, True)
        else:
            size = <addr_t>len(backup)
            CheckAddAddrU(address_, size)
            Memory_Delete_(memory, address_, address_ + size)
            Memory_Write(memory, 0, backup, True)

    def intervals(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Iterator[ClosedInterval]:
        cdef:
            addr_t start_
            addr_t endex_
            const Rack_* blocks = self._.blocks
            size_t block_count = Rack_Length(blocks)
            size_t block_index
            size_t block_index_start
            size_t block_index_endex
            const Block_* block
            addr_t block_start
            addr_t block_endex
            size_t slice_start
            size_t slice_endex

        if block_count:
            block_index_start = 0 if start is None else Rack_IndexStart(blocks, <addr_t>start)
            block_index_endex = block_count if endex is None else Rack_IndexEndex(blocks, <addr_t>endex)
            start_, endex_ = Memory_Bound(self._, start, endex)

            for block_index in range(block_index_start, block_index_endex):
                block = Rack_Get__(blocks, block_index)
                block_start = Block_Start(block)
                block_endex = Block_Endex(block)
                slice_start = block_start if start_ < block_start else start_
                slice_endex = endex_ if endex_ < block_endex else block_endex
                if slice_start < slice_endex:
                    yield slice_start, slice_endex

    def items(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Union[Address, EllipsisType]] = None,
        pattern: Optional[Union[AnyBytes, Value]] = None,
    ) -> Iterator[Tuple[Address, Optional[Value]]]:
        cdef:
            addr_t start_
            addr_t endex_
            Rover_* rover = NULL
            byte_t pattern_value
            const byte_t[:] pattern_view
            size_t pattern_size = 0
            const byte_t* pattern_data = NULL
            addr_t address
            int value

        if start is None:
            start_ = Memory_Start(self._)
        else:
            start_ = <addr_t>start

        if endex is None:
            endex_ = Memory_Endex(self._)
        elif endex is Ellipsis:
            endex_ = ADDR_MAX
        else:
            endex_ = <addr_t>endex

        if pattern is not None:
            if isinstance(pattern, int):
                pattern_value = <byte_t>pattern
                pattern_size = 1
                pattern_data = &pattern_value
            else:
                try:
                    pattern_view = pattern
                except TypeError:
                    pattern_view = bytes(pattern)
                with cython.boundscheck(False):
                    pattern_size = len(pattern_view)
                    pattern_data = &pattern_view[0]

        try:
            rover = Rover_Create(self._, start_, endex_, pattern_size, pattern_data, True, endex is Ellipsis)
            while Rover_HasNext(rover):
                address = Rover_Address(rover)
                value = Rover_Next_(rover)
                yield address, (None if value < 0 else value)
        finally:
            rover = Rover_Free(rover)

    def keys(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Union[Address, EllipsisType]] = None,
    ) -> Iterator[Address]:
        cdef:
            addr_t start_
            addr_t endex_

        if start is None:
            start_ = Memory_Start(self._)
        else:
            start_ = <addr_t>start

        if endex is None:
            endex_ = Memory_Endex(self._)
        elif endex is Ellipsis:
            endex_ = ADDR_MAX
        else:
            endex_ = <addr_t>endex

        while start_ < endex_:
            yield start_
            start_ += 1

    def peek(
        self: Memory,
        address: Address,
    ) -> Optional[Value]:

        return Memory_Peek(self._, address)

    def poke(
        self: Memory,
        address: Address,
        item: Optional[Union[AnyBytes, Value]],
    ) -> None:

        Memory_Poke(self._, address, item)

    def poke_backup(
        self: Memory,
        address: Address,
    ) -> Tuple[Address, Optional[Value]]:

        return address, Memory_Peek(self._, address)

    def poke_restore(
        self: Memory,
        address: Address,
        item: Optional[Value],
    ) -> None:

        if item is None:
            Memory_PokeNone_(self._, <addr_t>address)
        else:
            Memory_Poke_(self._, <addr_t>address, <byte_t>item)

    def pop(
        self: Memory,
        address: Optional[Address] = None,
        default: Optional[Value] = None,
    ) -> Optional[Value]:

        return Memory_Pop(self._, address, default)

    def pop_backup(
        self: Memory,
        address: Optional[Address] = None,
    ) -> Tuple[Address, Optional[Value]]:

        if address is None:
            address = self.endex - 1
        return address, Memory_Peek(self._, address)

    def pop_restore(
        self: Memory,
        address: Address,
        item: Optional[Value],
    ) -> None:
        cdef:
            byte_t value

        if item is None:
            Memory_Reserve_(self._, <addr_t>address, 1)
        else:
            value = <byte_t>item
            Memory_InsertRaw_(self._, address, 1, &value)

    def popitem(
        self: Memory,
    ) -> Tuple[Address, Value]:
        cdef:
            addr_t address
            int value

        address, value = Memory_PopItem(self._)
        return address, value

    def popitem_backup(
        self: Memory,
    ) -> Tuple[Address, Value]:
        cdef:
            const Memory_* memory = self._
            const Rack_* blocks = memory.blocks
            const Block_* block
            size_t offset
            byte_t backup

        if Rack_Bool(blocks):
            block = Rack_Last__(blocks)
            offset = Block_Length(block)
            if offset:
                offset -= 1
                address = Block_Start(block) + offset
                backup = Block_Get__(block, offset)
                return address, backup
            else:
                raise RuntimeError('empty block')
        else:
            raise KeyError('empty')

    def popitem_restore(
        self: Memory,
        address: Address,
        item: Value,
    ) -> None:
        cdef:
            addr_t address_ = <addr_t>address
            byte_t item_ = <byte_t>item
            Memory_* memory = self._

        if address_ == Memory_ContentEndex(memory):
            Memory_Append_(memory, item_)
        else:
            Memory_InsertRaw_(memory, address_, 1, &item_)

    def read(
        self: Memory,
        address: Address,
        size: Address,
    ) -> memoryview:
        cdef:
            const Memory_* memory = self._
            BlockView view = Memory_Read(memory, address, size)

        return _cast(memoryview, view)

    def remove(
        self: Memory,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> None:
        cdef:
            Memory_* memory = self._
            size_t size = 1 if isinstance(item, int) else <size_t>len(item)
            addr_t address = <addr_t>Memory_Index(memory, item, start, endex)

        CheckAddAddrU(address, size)
        Memory_Erase__(memory, address, address + size, True)  # delete

    def remove_backup(
        self: Memory,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> _MemorySelf:
        cdef:
            Memory_* memory = self._
            size_t size = 1 if isinstance(item, int) else <size_t>len(item)
            addr_t address = <addr_t>Memory_Index(memory, item, start, endex)

        CheckAddAddrU(address, size)
        memory = Memory_Extract__(memory, address, address + size, 0, NULL, 1, True)
        return Memory_AsObject(memory)

    def remove_restore(
        self: Memory,
        backup: ImmutableMemory,
    ) -> None:
        cdef:
            Memory_* memory = self._
            const Memory_* backup_

        if isinstance(backup, Memory):
            backup_ = (<Memory>backup)._
            Memory_Reserve_(memory, Memory_Start(backup_), Memory_Length(backup_))
            Memory_WriteSame_(memory, 0, backup_, True)
        else:
            Memory_Reserve(memory, backup.start, len(backup))
            Memory_Write(memory, 0, backup, True)

    def reserve(
        self: Memory,
        address: Address,
        size: Address,
    ) -> None:

        Memory_Reserve(self._, address, size)

    def reserve_backup(
        self: Memory,
        address: Address,
        size: Address,
    ) -> Tuple[Address, ImmutableMemory]:

        backup = self._prebound_endex_backup(address, size)
        return address, backup

    def reserve_restore(
        self: Memory,
        address: Address,
        backup: ImmutableMemory,
    ) -> None:
        cdef:
            addr_t address_ = <addr_t>address
            addr_t size
            Memory_* memory = self._
            const Memory_* backup_

        if isinstance(backup, Memory):
            backup_ = (<Memory>backup)._
            size = Memory_Length(backup_)
            CheckAddAddrU(address_, size)
            Memory_Delete_(memory, address_, address_ + size)
            Memory_WriteSame_(memory, 0, backup_, True)
        else:
            size = <addr_t>len(backup)
            CheckAddAddrU(address_, size)
            Memory_Delete_(memory, address_, address_ + size)
            Memory_Write(memory, 0, backup, True)

    def reverse(
        self: Memory,
    ) -> None:

        Memory_Reverse(self._)

    def rfind(
        self: Memory,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Address:

        return Memory_RevFind(self._, item, start, endex)

    def rindex(
        self: Memory,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Address:

        return Memory_RevIndex(self._, item, start, endex)

    def rvalues(
        self: Memory,
        start: Optional[Union[Address, EllipsisType]] = None,
        endex: Optional[Address] = None,
        pattern: Optional[Union[AnyBytes, Value]] = None,
    ) -> Iterator[Optional[Value]]:
        cdef:
            addr_t start_
            addr_t endex_
            Rover_* rover = NULL
            byte_t pattern_value
            const byte_t[:] pattern_view
            size_t pattern_size = 0
            const byte_t* pattern_data = NULL

        if start is None:
            start_ = Memory_Start(self._)
        elif start is Ellipsis:
            start_ = ADDR_MIN
        else:
            start_ = <addr_t>start

        if endex is None:
            endex_ = Memory_Endex(self._)
        else:
            endex_ = <addr_t>endex

        if pattern is not None:
            if isinstance(pattern, int):
                pattern_value = <byte_t>pattern
                pattern_size = 1
                pattern_data = &pattern_value
            else:
                try:
                    pattern_view = pattern
                except TypeError:
                    pattern_view = bytes(pattern)
                with cython.boundscheck(False):
                    pattern_size = len(pattern_view)
                    pattern_data = &pattern_view[0]

        rover = Rover_Create(self._, start_, endex_, pattern_size, pattern_data, False, start is Ellipsis)
        try:
            while True:
                yield Rover_Next(rover)
        except StopIteration:
            pass
        finally:
            Rover_Free(rover)
            if pattern is not None:  # keep
                pattern = None  # release

    def setdefault(
        self: Memory,
        address: Address,
        default: Optional[Union[AnyBytes, Value]] = None,
    ) -> Optional[Value]:
        cdef:
            addr_t address_ = <addr_t>address
            Memory_* memory = self._
            int backup = Memory_Peek_(memory, address_)
            const byte_t[:] view
            byte_t value

        if backup < 0:
            if default is not None:
                if isinstance(default, int):
                    value = <byte_t>default
                else:
                    view = default
                    if len(view) != 1:
                        raise ValueError('expecting single item')
                    with cython.boundscheck(False):
                        value = view[0]
                Memory_Poke_(memory, address_, value)
                return value
            else:
                return None
        else:
            return backup

    def setdefault_backup(
        self: Memory,
        address: Address,
    ) -> Tuple[Address, Optional[Value]]:

        return address, Memory_Peek(self._, address)

    def setdefault_restore(
        self: Memory,
        address: Address,
        item: Optional[Value],
    ) -> None:

        Memory_Poke(self._, address, item)

    def shift(
        self: Memory,
        offset: Address,
    ) -> None:

        Memory_Shift(self._, offset)

    def shift_backup(
        self: Memory,
        offset: Address,
    ) -> Tuple[Address, ImmutableMemory]:
        cdef:
            Memory backup

        if offset < 0:
            backup = self._prebound_start_backup(None, -offset)
        else:
            backup = self._prebound_endex_backup(None, +offset)
        return offset, backup

    def shift_restore(
        self: Memory,
        offset: Address,
        backup: ImmutableMemory,
    ) -> None:
        cdef:
            Memory_* memory = self._

        Memory_Shift(memory, -offset)
        Memory_Write(memory, 0, backup, True)

    @property
    def span(
        self: Memory,
    ) -> ClosedInterval:

        return Memory_Span(self._)

    @property
    def start(
        self: Memory,
    ) -> Address:

        return Memory_Start(self._)

    def to_blocks(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> BlockList:
        cdef:
            addr_t start_
            addr_t endex_
            const Rack_* blocks = self._.blocks
            size_t block_count = Rack_Length(blocks)
            size_t block_index
            size_t block_index_start
            size_t block_index_endex
            const Block_* block
            addr_t block_start
            addr_t block_endex
            addr_t slice_start
            addr_t slice_endex
            bytes slice_data
            list result = []

        if block_count:
            if start is None and endex is None:  # faster
                for block_index in range(block_count):
                    block = Rack_Get__(blocks, block_index)
                    result.append([Block_Start(block), Block_Bytes(block)])
            else:
                block_index_start = 0 if start is None else Rack_IndexStart(blocks, start)
                block_index_endex = block_count if endex is None else Rack_IndexEndex(blocks, endex)
                start_, endex_ = Memory_Bound(self._, start, endex)

                for block_index in range(block_index_start, block_index_endex):
                    block = Rack_Get__(blocks, block_index)
                    block_start = Block_Start(block)
                    block_endex = Block_Endex(block)
                    slice_start = block_start if start_ < block_start else start_
                    slice_endex = endex_ if endex_ < block_endex else block_endex
                    if slice_start < slice_endex:
                        slice_start -= block_start
                        slice_endex -= block_start
                        slice_data = PyBytes_FromStringAndSize(<char*><void*>Block_At__(block, <size_t>slice_start),
                                                               <ssize_t>(slice_endex - slice_start))
                        result.append([block_start + slice_start, slice_data])
        return result

    def to_bytes(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> bytes:
        cdef:
            const Memory_* memory = self._
            BlockView view = Memory_View(memory, start, endex)
            bytes data

        try:
            data = view.__bytes__()
        finally:
            view.release_()
        return data

    def update(
        self: Memory,
        data: Union[AddressValueMapping,
                    Iterable[Tuple[Address, Value]],
                    Mapping[Address, Union[Value, AnyBytes]],
                    ImmutableMemory],
        clear: bool = False,
        **kwargs: Any,  # string keys cannot become addresses
    ) -> None:
        cdef:
            Memory_* memory = self._

        if kwargs:
            raise KeyError('cannot convert kwargs.keys() into addresses')

        if isinstance(data, ImmutableMemory):
            Memory_Write(memory, 0, data, clear)
        else:
            if isinstance(data, Mapping):
                data = data.items()
            for address, value in data:
                Memory_Poke(memory, address, value)

    def update_backup(
        self: Memory,
        data: Union[AddressValueMapping, Iterable[Tuple[Address, Value]], ImmutableMemory],
        clear: bool = False,
        **kwargs: Any,  # string keys cannot become addresses
    ) -> Union[AddressValueMapping, ImmutableMemory]:
        cdef:
            Memory_* memory = self._

        if kwargs:
            raise KeyError('cannot convert kwargs.keys() into addresses')

        if isinstance(data, ImmutableMemory):
            return self.write_backup(0, data, clear=clear)
        else:
            if isinstance(data, Mapping):
                backups = {address: Memory_Peek(memory, address) for address in data.keys()}
            else:
                backups = {address: Memory_Peek(memory, address) for address, _ in data}
            return backups

    def update_restore(
        self: Memory,
        backups: Union[AddressValueMapping, List[ImmutableMemory]],
    ) -> None:
        cdef:
            Memory_* memory = self._

        if isinstance(backups, list):
            for backup in backups:
                Memory_Write(memory, 0, backup, True)
        else:
            self.update(backups)

    def validate(
        self: Memory,
    ) -> None:

        Memory_Validate(self._)

    def values(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Union[Address, EllipsisType]] = None,
        pattern: Optional[Union[AnyBytes, Value]] = None,
    ) -> Iterator[Optional[Value]]:
        cdef:
            addr_t start_
            addr_t endex_
            Rover_* rover = NULL
            byte_t pattern_value
            const byte_t[:] pattern_view
            size_t pattern_size = 0
            const byte_t* pattern_data = NULL

        if start is None:
            start_ = Memory_Start(self._)
        else:
            start_ = <addr_t>start

        if endex is None:
            endex_ = Memory_Endex(self._)
        elif endex is Ellipsis:
            endex_ = ADDR_MAX
        else:
            endex_ = <addr_t>endex

        if pattern is not None:
            if isinstance(pattern, int):
                pattern_value = <byte_t>pattern
                pattern_size = 1
                pattern_data = &pattern_value
            else:
                try:
                    pattern_view = pattern
                except TypeError:
                    pattern_view = bytes(pattern)
                with cython.boundscheck(False):
                    pattern_size = len(pattern_view)
                    pattern_data = &pattern_view[0]

        try:
            rover = Rover_Create(self._, start_, endex_, pattern_size, pattern_data, True, endex is Ellipsis)
            while Rover_HasNext(rover):
                yield Rover_Next(rover)
        finally:
            rover = Rover_Free(rover)

    def view(
        self: Memory,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> memoryview:
        cdef:
            const Memory_* memory = self._
            addr_t start_ = Memory_Start(memory) if start is None else <addr_t>start
            addr_t endex_ = Memory_Endex(memory) if endex is None else <addr_t>endex
            BlockView view = Memory_View_(memory, start_, endex_)

        return _cast(memoryview, view)

    def write(
        self: Memory,
        address: Address,
        data: Union[AnyBytes, Value, ImmutableMemory],
        clear: bool = False,
    ) -> None:

        Memory_Write(self._, address, data, clear)

    def write_backup(
        self: Memory,
        address: Address,
        data: Union[AnyBytes, Value, ImmutableMemory],
        clear: bool = False,
    ) -> List[ImmutableMemory]:
        cdef:
            addr_t address_ = <addr_t>address
            Memory memory
            addr_t start
            addr_t endex
            list backups

        if isinstance(data, Memory):
            memory = <Memory>data
            start = Memory_Start(memory._)
            endex = Memory_Endex(memory._)
            CheckAddAddrU(start, address_)
            CheckAddAddrU(endex, address_)
            start += address
            endex += address
            if endex <= start:
                backups = []
            elif clear:
                backups = [Memory_Extract_(self._, start, endex, 0, NULL, 1, True)]
            else:
                backups = [Memory_Extract_(self._, <addr_t>block_start, <addr_t>block_endex, 0, NULL, 1, True)
                           for block_start, block_endex in memory.intervals(start=start, endex=endex)]

        elif isinstance(data, ImmutableMemory):
            start = <addr_t>data.start
            endex = <addr_t>data.endex
            CheckAddAddrU(start, address_)
            CheckAddAddrU(endex, address_)
            start += address
            endex += address
            if endex <= start:
                backups = []
            elif clear:
                backups = [Memory_Extract_(self._, start, endex, 0, NULL, 1, True)]
            else:
                backups = [Memory_Extract_(self._, <addr_t>block_start, <addr_t>block_endex, 0, NULL, 1, True)
                           for block_start, block_endex in data.intervals(start=start, endex=endex)]

        else:
            if isinstance(data, int):
                start = address_
                endex = start + 1
                backups = [Memory_Extract_(self._, start, endex, 0, NULL, 1, True)]
            else:
                start = address_
                endex = start + <size_t>len(data)
                if start < endex:
                    backups = [Memory_Extract_(self._, start, endex, 0, NULL, 1, True)]
                else:
                    backups = []

        return backups

    def write_restore(
        self: Memory,
        backups: Sequence[ImmutableMemory],
    ) -> None:
        cdef:
            Memory_* memory = self._

        for backup in backups:
            Memory_Write(memory, 0, backup, True)


ImmutableMemory.register(Memory)
MutableMemory.register(Memory)


# =====================================================================================================================

cdef class bytesparse(Memory):

    def __init__(
        self: bytesparse,
        *args: Any,  # see bytearray.__init__()
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ):
        cdef:
            const byte_t[:] view
            addr_t address
            size_t size
            const byte_t* ptr

        super().__init__(start, endex)

        data = bytearray(*args)
        if data:
            if start is None:
                start = 0

            if endex is not None:
                if endex <= start:
                    return

                del data[(endex - start):]

            view = data
            address = <addr_t>start
            with cython.boundscheck(False):
                size = <size_t>len(view)
                ptr = &view[0]
            Memory_Place__(self._, address, size, ptr, False)

    def __delitem__(
        self: bytesparse,
        key: Union[Address, slice],
    ) -> None:

        if isinstance(key, slice):
            start, endex = self._rectify_span(key.start, key.stop)
            key = slice(start, endex, key.step)
        else:
            key = self._rectify_address(key)

        super().__delitem__(key)

    def __getitem__(
        self: bytesparse,
        key: Union[Address, slice],
    ) -> Any:

        if isinstance(key, slice):
            start, endex = self._rectify_span(key.start, key.stop)
            key = slice(start, endex, key.step)
        else:
            key = self._rectify_address(key)

        return super().__getitem__(key)

    def __setitem__(
        self: bytesparse,
        key: Union[Address, slice],
        value: Optional[Union[AnyBytes, Value]],
    ) -> None:

        if isinstance(key, slice):
            start, endex = self._rectify_span(key.start, key.stop)
            key = slice(start, endex, key.step)
        else:
            key = self._rectify_address(key)

        super().__setitem__(key, value)

    def _rectify_address(
        self: bytesparse,
        address: Address,
    ) -> Address:

        try:
            try:
                return <addr_t>address

            except OverflowError:
                return <addr_t>(<object>Memory_Endex(self._) + address)

        except OverflowError:
            raise IndexError('index out of range')

    def _rectify_span(
        self: bytesparse,
        start: Optional[Address],
        endex: Optional[Address],
    ) -> OpenInterval:

        endex_ = None

        if start is not None and start < 0:
            endex_ = Memory_Endex(self._)
            start = endex_ + start
            if start < 0:
                start = 0

        if endex is not None and endex < 0:
            if endex_ is None:
                endex_ = Memory_Endex(self._)
            endex = endex_ + endex
            if endex < 0:
                endex = 0

        return start, endex

    def block_span(
        self: bytesparse,
        address: Address,
    ) -> Tuple[Optional[Address], Optional[Address], Optional[Value]]:

        address = self._rectify_address(address)
        return super().block_span(address)

    def blocks(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Iterator[Tuple[Address, memoryview]]:

        start, endex = self._rectify_span(start, endex)
        yield from super().blocks(start=start, endex=endex)

    def bound(
        self: bytesparse,
        start: Optional[Address],
        endex: Optional[Address],
    ) -> ClosedInterval:

        start, endex = self._rectify_span(start, endex)
        return super().bound(start, endex)

    @property
    def bound_endex(
        self: bytesparse,
    ) -> Optional[Address]:

        # Copy-pasted from Memory, because I cannot figure out how to override properties
        return Memory_GetBoundEndex(self._)

    @bound_endex.setter
    def bound_endex(
        self: bytesparse,
        bound_endex: Optional[Address],
    ) -> None:

        if bound_endex is not None and bound_endex < 0:
            raise ValueError('negative endex')

        # Copy-pasted from Memory, because I cannot figure out how to override properties
        Memory_SetBoundEndex(self._, bound_endex)

    @property
    def bound_span(
        self: bytesparse,
    ) -> OpenInterval:

        # Copy-pasted from Memory, because I cannot figure out how to override properties
        return Memory_GetBoundSpan(self._)

    @bound_span.setter
    def bound_span(
        self: bytesparse,
        bound_span: Optional[OpenInterval],
    ) -> None:

        if bound_span is None:
            bound_span = (None, None)
        bound_start, bound_endex = bound_span
        if bound_start is not None and bound_start < 0:
            raise ValueError('negative start')
        if bound_endex is not None and bound_endex < 0:
            raise ValueError('negative endex')

        # Copy-pasted from Memory, because I cannot figure out how to override properties
        Memory_SetBoundSpan(self._, bound_span)

    @property
    def bound_start(
        self: bytesparse,
    ) -> Optional[Address]:

        # Copy-pasted from Memory, because I cannot figure out how to override properties
        return Memory_GetBoundStart(self._)

    @bound_start.setter
    def bound_start(
        self: bytesparse,
        bound_start: Optional[Address],
    ) -> None:

        if bound_start is not None and bound_start < 0:
            raise ValueError('negative start')

        # Copy-pasted from Memory, because I cannot figure out how to override properties
        Memory_SetBoundStart(self._, bound_start)

    def clear(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> None:

        start, endex = self._rectify_span(start=start, endex=endex)
        super().clear(start, endex)

    def clear_backup(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> _BytesparseSelf:

        start, endex = self._rectify_span(start, endex)
        return super().clear_backup(start=start, endex=endex)

    def count(
        self: bytesparse,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> int:

        start, endex = self._rectify_span(start, endex)
        return super().count(item, start=start, endex=endex)

    def crop(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> None:

        start, endex = self._rectify_span(start, endex)
        super().crop(start=start, endex=endex)

    def crop_backup(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Tuple[Optional[ImmutableMemory], Optional[ImmutableMemory]]:

        start, endex = self._rectify_span(start, endex)
        return super().crop_backup(start=start, endex=endex)

    def cut(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        bound: bool = True,
    ) -> _BytesparseSelf:

        start, endex = self._rectify_span(start, endex)
        return super().cut(start=start, endex=endex)

    def delete(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> None:

        start, endex = self._rectify_span(start, endex)
        super().delete(start=start, endex=endex)

    def delete_backup(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> _BytesparseSelf:

        start, endex = self._rectify_span(start, endex)
        return super().delete_backup(start=start, endex=endex)

    def equal_span(
        self: bytesparse,
        address: Address,
    ) -> Tuple[Optional[Address], Optional[Address], Optional[Value]]:

        address = self._rectify_address(address)
        return super().equal_span(address)

    def extract(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        pattern: Optional[Union[AnyBytes, Value]] = None,
        step: Optional[Address] = None,
        bound: bool = True,
    ) -> _BytesparseSelf:

        start, endex = self._rectify_span(start, endex)
        return super().extract(start=start, endex=endex, pattern=pattern, step=step, bound=bound)

    def fill(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        pattern: Union[AnyBytes, Value] = 0,
    ) -> None:

        start, endex = self._rectify_span(start, endex)
        super().fill(start=start, endex=endex, pattern=pattern)

    def fill_backup(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> _BytesparseSelf:

        start, endex = self._rectify_span(start, endex)
        return super().fill_backup(start=start, endex=endex)

    def find(
        self: bytesparse,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Address:

        start, endex = self._rectify_span(start, endex)
        return super().find(item, start=start, endex=endex)

    def flood(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        pattern: Union[AnyBytes, Value] = 0,
    ) -> None:

        start, endex = self._rectify_span(start, endex)
        super().flood(start=start, endex=endex, pattern=pattern)

    def flood_backup(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> List[OpenInterval]:

        start, endex = self._rectify_span(start, endex)
        return super().flood_backup(start=start, endex=endex)

    @classmethod
    def from_blocks(
        cls,
        blocks: BlockSequence,
        offset: Address = 0,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        copy: bool = True,
        validate: bool = True,
    ) -> _BytesparseSelf:
        cdef:
            Memory memory1
            bytesparse memory2
            Memory_* memory1_
            Memory_* memory2_

        if blocks:
            block_start = blocks[0][0]
            if block_start + offset < 0:
                raise ValueError('negative offseted start')

        if start is not None and start < 0:
            raise ValueError('negative start')
        if endex is not None and endex < 0:
            raise ValueError('negative endex')

        memory1 = super().from_blocks(blocks, offset=offset, start=start, endex=endex, copy=copy, validate=validate)
        memory2 = cls()
        memory1_ = memory1._
        memory2_ = memory2._

        memory2_.blocks = Rack_Free(memory2_.blocks)
        memory2_.blocks = memory1_.blocks
        memory1_.blocks = NULL

        memory2_.bound_start = memory1_.bound_start
        memory2_.bound_endex = memory1_.bound_endex
        memory2_.bound_start_ = memory1_.bound_start_
        memory2_.bound_endex_ = memory1_.bound_endex_
        return memory2

    @classmethod
    def from_bytes(
        cls,
        data: AnyBytes,
        offset: Address = 0,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        copy: bool = True,
        validate: bool = True,
    ) -> _BytesparseSelf:
        cdef:
            Memory memory1
            bytesparse memory2
            Memory_* memory1_
            Memory_* memory2_

        if offset < 0:
            raise ValueError('negative offset')
        if start is not None and start < 0:
            raise ValueError('negative start')
        if endex is not None and endex < 0:
            raise ValueError('negative endex')

        memory1 = super().from_bytes(data, offset=offset, start=start, endex=endex, copy=copy, validate=validate)
        memory2 = cls()
        memory1_ = memory1._
        memory2_ = memory2._

        memory2_.blocks = Rack_Free(memory2_.blocks)
        memory2_.blocks = memory1_.blocks
        memory1_.blocks = NULL

        memory2_.bound_start = memory1_.bound_start
        memory2_.bound_endex = memory1_.bound_endex
        memory2_.bound_start_ = memory1_.bound_start_
        memory2_.bound_endex_ = memory1_.bound_endex_
        return memory2

    @classmethod
    def from_memory(
        cls,
        memory: ImmutableMemory,
        offset: Address = 0,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
        copy: bool = True,
        validate: bool = True,
    ) -> _BytesparseSelf:
        cdef:
            const Memory_* memory_
            Memory memory1
            bytesparse memory2
            Memory_* memory1_
            Memory_* memory2_
            addr_t block_start

        if isinstance(memory, Memory):
            memory_ = (<Memory>memory)._
            if Memory_Bool(memory_):
                if Memory_Start(memory_) + offset < 0:
                    raise ValueError('negative offseted start')
        else:
            if memory:
                if memory.start + offset < 0:
                    raise ValueError('negative offseted start')

        if start is not None and start < 0:
            raise ValueError('negative start')
        if endex is not None and endex < 0:
            raise ValueError('negative endex')

        memory1 = super().from_memory(memory, offset=offset, start=start, endex=endex, copy=copy, validate=validate)
        memory2 = cls()
        memory1_ = memory1._
        memory2_ = memory2._

        memory2_.blocks = Rack_Free(memory2_.blocks)
        memory2_.blocks = memory1_.blocks
        memory1_.blocks = NULL

        memory2_.bound_start = memory1_.bound_start
        memory2_.bound_endex = memory1_.bound_endex
        memory2_.bound_start_ = memory1_.bound_start_
        memory2_.bound_endex_ = memory1_.bound_endex_
        return memory2

    def gaps(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Iterator[OpenInterval]:

        start, endex = self._rectify_span(start, endex)
        yield from super().gaps(start=start, endex=endex)

    def get(
        self: bytesparse,
        address: Address,
        default: Optional[Value] = None,
    ) -> Optional[Value]:

        address = self._rectify_address(address)
        return super().get(address, default=default)

    def index(
        self: bytesparse,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Address:

        start, endex = self._rectify_span(start, endex)
        return super().index(item, start=start, endex=endex)

    def insert(
        self: bytesparse,
        address: Address,
        data: Union[AnyBytes, Value, ImmutableMemory],
    ) -> None:

        address = self._rectify_address(address)
        super().insert(address, data)

    def insert_backup(
        self: bytesparse,
        address: Address,
        data: Union[AnyBytes, Value, ImmutableMemory],
    ) -> Tuple[Address, ImmutableMemory]:

        address = self._rectify_address(address)
        return super().insert_backup(address, data)

    def intervals(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Iterator[ClosedInterval]:

        start, endex = self._rectify_span(start, endex)
        yield from super().intervals(start=start, endex=endex)

    def items(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Union[Address, EllipsisType]] = None,
        pattern: Optional[Union[AnyBytes, Value]] = None,
    ) -> Iterator[Tuple[Address, Optional[Value]]]:

        endex_ = endex  # backup
        if endex is Ellipsis:
            endex = None
        start, endex = self._rectify_span(start, endex)
        if endex_ is Ellipsis:
            endex = endex_  # restore
        yield from super().items(start=start, endex=endex, pattern=pattern)

    def keys(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Union[Address, EllipsisType]] = None,
    ) -> Iterator[Address]:

        endex_ = endex  # backup
        if endex is Ellipsis:
            endex = None
        start, endex = self._rectify_span(start, endex)
        if endex_ is Ellipsis:
            endex = endex_  # restore
        yield from super().keys(start=start, endex=endex)

    def peek(
        self: bytesparse,
        address: Address,
    ) -> Optional[Value]:

        address = self._rectify_address(address)
        return super().peek(address)

    def poke(
        self: bytesparse,
        address: Address,
        item: Optional[Union[AnyBytes, Value]],
    ) -> None:

        address = self._rectify_address(address)
        super().poke(address, item)

    def poke_backup(
        self: bytesparse,
        address: Address,
    ) -> Tuple[Address, Optional[Value]]:

        address = self._rectify_address(address)
        return super().poke_backup(address)

    def pop(
        self: bytesparse,
        address: Optional[Address] = None,
        default: Optional[Value] = None,
    ) -> Optional[Value]:

        if address is not None:
            address = self._rectify_address(address)
        return super().pop(address=address, default=default)

    def pop_backup(
        self: bytesparse,
        address: Optional[Address] = None,
    ) -> Tuple[Address, Optional[Value]]:

        if address is not None:
            address = self._rectify_address(address)
        return super().pop_backup(address=address)

    def read(
        self: bytesparse,
        address: Address,
        size: Address,
    ) -> memoryview:

        address = self._rectify_address(address)
        return super().read(address, size)

    def remove(
        self: bytesparse,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> None:

        start, endex = self._rectify_span(start, endex)
        super().remove(item, start=start, endex=endex)

    def remove_backup(
        self: bytesparse,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> _BytesparseSelf:

        start, endex = self._rectify_span(start, endex)
        return super().remove_backup(item, start=start, endex=endex)

    def reserve(
        self: bytesparse,
        address: Address,
        size: Address,
    ) -> None:

        address = self._rectify_address(address)
        super().reserve(address, size)

    def reserve_backup(
        self: bytesparse,
        address: Address,
        size: Address,
    ) -> Tuple[Address, ImmutableMemory]:

        address = self._rectify_address(address)
        return super().reserve_backup(address, size)

    def rfind(
        self: bytesparse,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Address:

        start, endex = self._rectify_span(start, endex)
        return super().rfind(item, start=start, endex=endex)

    def rindex(
        self: bytesparse,
        item: Union[AnyBytes, Value],
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> Address:

        start, endex = self._rectify_span(start, endex)
        return super().rindex(item, start=start, endex=endex)

    def rvalues(
        self: bytesparse,
        start: Optional[Union[Address, EllipsisType]] = None,
        endex: Optional[Address] = None,
        pattern: Optional[Union[AnyBytes, Value]] = None,
    ) -> Iterator[Optional[Value]]:

        start_ = start  # backup
        if start is Ellipsis:
            start = None
        start, endex = self._rectify_span(start, endex)
        if start_ is Ellipsis:
            start = start_  # restore
        yield from super().rvalues(start=start, endex=endex, pattern=pattern)

    def setdefault(
        self: bytesparse,
        address: Address,
        default: Optional[Value] = None,
    ) -> Optional[Value]:

        address = self._rectify_address(address)
        return super().setdefault(address, default=default)

    def setdefault_backup(
        self: bytesparse,
        address: Address,
    ) -> Tuple[Address, Optional[Value]]:

        address = self._rectify_address(address)
        return super().setdefault_backup(address)

    def shift(
        self: bytesparse,
        offset: Address,
    ) -> None:
        cdef:
            const Memory_* memory = self._

        if not memory.bound_start_ and offset < 0:
            if Memory_Bool(memory):
                if Memory_Start(memory) + offset < 0:
                    raise ValueError('negative offseted start')

        super().shift(offset)

    def shift_backup(
        self: bytesparse,
        offset: Address,
    ) -> Tuple[Address, ImmutableMemory]:
        cdef:
            const Memory_* memory = self._

        if not memory.bound_start_ and offset < 0:
            if Memory_Bool(memory):
                if Memory_Start(memory) + offset < 0:
                    raise ValueError('negative offseted start')

        return super().shift_backup(offset)

    def values(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Union[Address, EllipsisType]] = None,
        pattern: Optional[Union[AnyBytes, Value]] = None,
    ) -> Iterator[Optional[Value]]:

        endex_ = endex  # backup
        if endex is Ellipsis:
            endex = None
        start, endex = self._rectify_span(start, endex)
        if endex_ is Ellipsis:
            endex = endex_  # restore
        yield from super().values(start=start, endex=endex, pattern=pattern)

    def view(
        self: bytesparse,
        start: Optional[Address] = None,
        endex: Optional[Address] = None,
    ) -> memoryview:

        start, endex = self._rectify_span(start, endex)
        return super().view(start=start, endex=endex)

    def write(
        self: bytesparse,
        address: Address,
        data: Union[AnyBytes, Value, ImmutableMemory],
        clear: bool = False,
    ) -> None:

        address = self._rectify_address(address)
        super().write(address, data, clear=clear)

    def write_backup(
        self: bytesparse,
        address: Address,
        data: Union[AnyBytes, Value, ImmutableMemory],
        clear: bool = False,
    ) -> List[ImmutableMemory]:

        address = self._rectify_address(address)
        return super().write_backup(address, data, clear=clear)


ImmutableMemory.register(bytesparse)
MutableMemory.register(bytesparse)
MutableBytesparse.register(bytesparse)
